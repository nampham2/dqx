{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DQX - Data Quality Excellence","text":"<p>Data quality as code. Works with your warehouse, scales with your needs.</p> <p> </p>"},{"location":"#why-dqx","title":"Why DQX?","text":"<ul> <li>Write validation logic as testable Python functions - No more complex SQL scripts scattered across your codebase</li> <li>Execute efficiently on any SQL backend - DuckDB, BigQuery, Snowflake, or your existing data warehouse</li> <li>No clusters or complex infrastructure needed - Runs wherever your data lives</li> <li>Integrates seamlessly with existing workflows - Drop it into your current pipeline</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install dqlib\n</code></pre> <p>Define your data quality checks as Python functions:</p> <pre><code>import pyarrow as pa\nfrom dqx.api import check, VerificationSuite, MetricProvider, Context\nfrom dqx.common import ResultKey\nfrom dqx.datasource import DuckRelationDataSource\nfrom dqx.orm.repositories import InMemoryMetricDB\n\n\n# Define your validation rules\n@check(name=\"Revenue integrity\")\ndef validate_revenue(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Verify reported revenue is positive\n    reported = mp.sum(\"revenue\")\n    ctx.assert_that(reported).config(\n        name=\"Revenue is positive\", severity=\"P0\"\n    ).is_positive()\n\n    # Check average transaction size is reasonable\n    avg_revenue = mp.average(\"revenue\")\n    ctx.assert_that(avg_revenue).config(\n        name=\"Average transaction size\", severity=\"P1\"\n    ).is_between(10, 100)\n\n\n# Your own metric store\ndb = InMemoryMetricDB()\nsuite = VerificationSuite([validate_revenue], db, \"Daily validation\")\n\n# Data comes from your warehouse\ndata = pa.Table.from_pydict(\n    {\"price\": [10.5, 20.0, 15.5], \"quantity\": [2, 1, 3], \"revenue\": [21.0, 20.0, 46.5]}\n)\ndatasource = DuckRelationDataSource.from_arrow(data)\n\n# Validate your data\nsuite.run([datasource], ResultKey())\n# \u2713 Revenue integrity: OK\n</code></pre>"},{"location":"#real-world-examples","title":"Real-World Examples","text":""},{"location":"#1-data-completeness","title":"1. Data Completeness","text":""},{"location":"#monitor-critical-fields-arent-missing","title":"Monitor critical fields aren't missing","text":"<pre><code>@check(name=\"Customer data quality\")\ndef check_completeness(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Flag if more than 5% of emails are missing\n    null_rate = mp.null_count(\"email\") / mp.num_rows()\n    ctx.assert_that(null_rate).config(name=\"Email completeness\", severity=\"P0\").is_lt(\n        0.05\n    )\n\n    # Ensure all orders have customer IDs\n    ctx.assert_that(mp.null_count(\"customer_id\")).config(\n        name=\"Customer ID required\", severity=\"P0\"\n    ).is_eq(0)\n</code></pre>"},{"location":"#2-revenue-integrity","title":"2. Revenue Integrity","text":""},{"location":"#catch-calculation-errors-in-financial-data","title":"Catch calculation errors in financial data","text":"<pre><code>@check(name=\"Financial accuracy\")\ndef validate_financials(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Verify totals match across systems\n    total_revenue = mp.sum(\"revenue\")\n    total_collected = mp.sum(\"payments\")\n\n    ctx.assert_that(total_collected / total_revenue).config(\n        name=\"Payment collection rate\", severity=\"P1\"\n    ).is_between(\n        0.95, 1.05\n    )  # 5% tolerance\n\n    # Check for negative prices\n    ctx.assert_that(mp.minimum(\"price\")).config(\n        name=\"No negative prices\", severity=\"P0\"\n    ).is_geq(0)\n</code></pre>"},{"location":"#3-trend-monitoring","title":"3. Trend Monitoring","text":""},{"location":"#alert-on-unexpected-metric-changes","title":"Alert on unexpected metric changes","text":"<pre><code>@check(name=\"Business metrics stability\")\ndef monitor_trends(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Alert on significant daily changes\n    daily_change = mp.sum(\"revenue\") / mp.sum(\"revenue\", lag=1)\n    ctx.assert_that(daily_change).config(\n        name=\"Daily revenue stability\", severity=\"P0\"\n    ).is_between(\n        0.8, 1.2\n    )  # \u00b120% change\n\n    # Track week-over-week growth\n    wow_change = mp.sum(\"revenue\") / mp.sum(\"revenue\", lag=7)\n    ctx.assert_that(wow_change).config(\n        name=\"Weekly revenue trend\", severity=\"P1\"\n    ).is_geq(\n        0.95\n    )  # Allow 5% decline\n</code></pre>"},{"location":"#4-cross-dataset-validation","title":"4. Cross-Dataset Validation","text":""},{"location":"#ensure-consistency-across-environments","title":"Ensure consistency across environments","text":"<pre><code>@check(name=\"Production vs Staging\", datasets=[\"production\", \"staging\"])\ndef validate_environments(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Compare row counts\n    prod_count = mp.num_rows(dataset=\"production\")\n    staging_count = mp.num_rows(dataset=\"staging\")\n\n    ctx.assert_that(prod_count).config(\n        name=\"Row count match\", severity=\"P1\"\n    ).is_between(\n        staging_count - 100, staging_count + 100\n    )  # Allow 100 row difference\n\n    # Verify key metrics align\n    prod_revenue = mp.sum(\"revenue\", dataset=\"production\")\n    staging_revenue = mp.sum(\"revenue\", dataset=\"staging\")\n\n    ctx.assert_that((prod_revenue - staging_revenue) / prod_revenue).config(\n        name=\"Revenue consistency\", severity=\"P0\"\n    ).is_lt(\n        0.01\n    )  # Less than 1% difference\n</code></pre>"},{"location":"#5-data-quality-slas","title":"5. Data Quality SLAs","text":""},{"location":"#track-quality-metrics-with-severity-levels","title":"Track quality metrics with severity levels","text":"<pre><code>@check(name=\"Data quality SLAs\")\ndef enforce_slas(mp: MetricProvider, ctx: Context) -&gt; None:\n    # P0: Critical - No duplicate transactions\n    ctx.assert_that(mp.duplicate_count([\"transaction_id\"])).config(\n        name=\"Transaction uniqueness\", severity=\"P0\"\n    ).is_eq(0)\n\n    # P1: High - Recent activity\n    recent_count = mp.count_values(\"status\", \"active\")\n    total_count = mp.num_rows()\n    active_rate = recent_count / total_count\n\n    ctx.assert_that(active_rate).config(\n        name=\"Active record percentage\", severity=\"P1\"\n    ).is_gt(\n        0.5\n    )  # At least 50% active\n\n    # P2: Medium - Cardinality checks\n    unique_users = mp.unique_count(\"user_id\")\n    ctx.assert_that(unique_users).config(\n        name=\"Active user threshold\", severity=\"P2\"\n    ).is_gt(1000)\n</code></pre>"},{"location":"#quick-reference","title":"Quick Reference","text":""},{"location":"#available-metrics","title":"Available Metrics","text":"Metric Description Example <code>num_rows()</code> Total row count <code>mp.num_rows()</code> <code>sum(col)</code> Sum of values <code>mp.sum(\"revenue\")</code> <code>average(col)</code> Mean value <code>mp.average(\"price\")</code> <code>minimum(col)</code> / <code>maximum(col)</code> Min/max values <code>mp.minimum(\"age\")</code> <code>first(col)</code> First value in column <code>mp.first(\"timestamp\")</code> <code>variance(col)</code> Statistical variance <code>mp.variance(\"score\")</code> <code>null_count(col)</code> Count of null values <code>mp.null_count(\"email\")</code> <code>duplicate_count([cols])</code> Count of duplicate rows <code>mp.duplicate_count([\"id\"])</code> <code>count_values(col, val)</code> Count specific values <code>mp.count_values(\"status\", \"active\")</code> <code>unique_count(col)</code> Distinct value count <code>mp.unique_count(\"user_id\")</code>"},{"location":"#extended-metrics","title":"Extended Metrics","text":"Metric Description Example <code>ext.day_over_day(metric)</code> Day-over-day change <code>mp.ext.day_over_day(mp.sum(\"revenue\"))</code> <code>ext.week_over_week(metric)</code> Week-over-week change <code>mp.ext.week_over_week(mp.average(\"price\"))</code> <code>ext.stddev(metric, offset, n)</code> Standard deviation over window <code>mp.ext.stddev(mp.sum(\"sales\"), offset=0, n=7)</code>"},{"location":"#available-assertions","title":"Available Assertions","text":"Assertion Description Example <code>is_eq(value, tol)</code> Equals with tolerance <code>.is_eq(100, tol=0.01)</code> <code>is_neq(value, tol)</code> Not equals with tolerance <code>.is_neq(100, tol=0.01)</code> <code>is_between(min, max)</code> In range (inclusive) <code>.is_between(0, 100)</code> <code>is_positive()</code> Greater than zero <code>.is_positive()</code> <code>is_zero()</code> Equals zero <code>.is_zero()</code> <code>is_negative()</code> Less than zero <code>.is_negative()</code> <code>is_none()</code> Equals None <code>.is_none()</code> <code>is_not_none()</code> Not equals None <code>.is_not_none()</code> <code>is_gt(val)</code> / <code>is_geq(val)</code> Greater than (or equal) <code>.is_gt(0.95)</code> <code>is_lt(val)</code> / <code>is_leq(val)</code> Less than (or equal) <code>.is_lt(0.05)</code> <code>noop()</code> No validation (collect only) <code>.noop()</code>"},{"location":"#license","title":"License","text":"<p>MIT License. See LICENSE for details.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API documentation for DQX (Data Quality Excellence).</p>"},{"location":"api-reference/#core-api","title":"Core API","text":""},{"location":"api-reference/#dataqualityvalidator","title":"DataQualityValidator","text":"<p>The main entry point for data validation.</p> <pre><code>from dqx import DataQualityValidator\n\nvalidator = DataQualityValidator(\n    name=\"MyValidator\",\n    description=\"Validates customer data\",\n    fail_fast=False,\n    parallel=True,\n)\n</code></pre>"},{"location":"api-reference/#parameters","title":"Parameters","text":"<ul> <li><code>name</code> (str, optional): Name of the validator instance</li> <li><code>description</code> (str, optional): Description of the validator's purpose</li> <li><code>fail_fast</code> (bool, default=False): Stop validation on first failure</li> <li><code>parallel</code> (bool, default=True): Enable parallel processing</li> </ul>"},{"location":"api-reference/#methods","title":"Methods","text":""},{"location":"api-reference/#validate","title":"validate()","text":"<p>Run validation checks on data.</p> <pre><code>results = validator.validate(data, checks, sample_size=None, context=None)\n</code></pre> <p>Parameters: - <code>data</code>: DataFrame, file path, or data source to validate - <code>checks</code>: List of Check objects or CheckGroup - <code>sample_size</code> (int, optional): Number of rows to sample - <code>context</code> (dict, optional): Additional context for validation</p> <p>Returns: <code>ValidationResults</code> object</p>"},{"location":"api-reference/#create_checks","title":"create_checks()","text":"<p>Create a check builder for fluent API.</p> <pre><code>checks = (\n    validator.create_checks(data).is_not_null(\"column1\").is_unique(\"column2\").build()\n)\n</code></pre>"},{"location":"api-reference/#check-classes","title":"Check Classes","text":""},{"location":"api-reference/#basecheck","title":"BaseCheck","text":"<p>Abstract base class for all checks.</p> <pre><code>class BaseCheck:\n    def __init__(self, name, description=None, severity=\"error\"):\n        self.name = name\n        self.description = description\n        self.severity = severity\n</code></pre>"},{"location":"api-reference/#built-in-checks","title":"Built-in Checks","text":""},{"location":"api-reference/#notnullcheck","title":"NotNullCheck","text":"<pre><code>from dqx.checks import NotNullCheck\n\ncheck = NotNullCheck(column=\"user_id\", name=\"User ID Required\", severity=\"critical\")\n</code></pre>"},{"location":"api-reference/#rangecheck","title":"RangeCheck","text":"<pre><code>from dqx.checks import RangeCheck\n\ncheck = RangeCheck(\n    column=\"age\", min_value=0, max_value=120, inclusive=True, name=\"Valid Age Range\"\n)\n</code></pre>"},{"location":"api-reference/#patterncheck","title":"PatternCheck","text":"<pre><code>from dqx.checks import PatternCheck\n\ncheck = PatternCheck(\n    column=\"email\", pattern=r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\", name=\"Valid Email Format\"\n)\n</code></pre>"},{"location":"api-reference/#uniquecheck","title":"UniqueCheck","text":"<pre><code>from dqx.checks import UniqueCheck\n\ncheck = UniqueCheck(\n    columns=[\"user_id\"], name=\"Unique User ID\"  # Can be single column or list\n)\n</code></pre>"},{"location":"api-reference/#checkbuilder-api","title":"CheckBuilder API","text":"<p>Fluent interface for building checks.</p> <pre><code>checks = (\n    CheckBuilder(df)\n    # Null checks\n    .is_not_null(\"column\")\n    .are_not_null([\"col1\", \"col2\"])\n    .has_no_nulls()\n    # Range checks\n    .is_between(\"age\", 0, 120)\n    .is_positive(\"amount\")\n    .is_negative(\"loss\")\n    .is_greater_than(\"score\", 50)\n    .is_less_than(\"cost\", 1000)\n    # Pattern checks\n    .matches_pattern(\"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n    .matches_date_format(\"date\", \"%Y-%m-%d\")\n    .has_length(\"zip_code\", 5)\n    .starts_with(\"product_code\", \"PRD\")\n    .ends_with(\"filename\", \".csv\")\n    # Uniqueness checks\n    .is_unique(\"id\")\n    .has_unique_combination([\"first_name\", \"last_name\"])\n    .has_no_duplicates()\n    # Statistical checks\n    .mean_between(\"score\", 70, 90)\n    .std_dev_less_than(\"variance\", 10)\n    .percentile_between(\"income\", 0.25, 10000, 50000)\n    # Build final check list\n    .build()\n)\n</code></pre>"},{"location":"api-reference/#validationresults","title":"ValidationResults","text":"<p>Results container with analysis methods.</p> <pre><code>class ValidationResults:\n    @property\n    def passed(self) -&gt; bool:\n        \"\"\"Whether all checks passed\"\"\"\n\n    @property\n    def failed_count(self) -&gt; int:\n        \"\"\"Number of failed checks\"\"\"\n\n    @property\n    def pass_rate(self) -&gt; float:\n        \"\"\"Percentage of passed checks\"\"\"\n\n    def summary(self) -&gt; dict:\n        \"\"\"Get summary statistics\"\"\"\n\n    def failed_checks(self) -&gt; List[CheckResult]:\n        \"\"\"Get only failed check results\"\"\"\n\n    def to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Convert results to DataFrame\"\"\"\n\n    def to_json(self, filepath: str = None) -&gt; str:\n        \"\"\"Export results as JSON\"\"\"\n\n    def to_html(self, filepath: str) -&gt; None:\n        \"\"\"Generate HTML report\"\"\"\n</code></pre>"},{"location":"api-reference/#data-sources","title":"Data Sources","text":""},{"location":"api-reference/#pandasdatasource","title":"PandasDataSource","text":"<pre><code>from dqx.sources import PandasDataSource\n\nsource = PandasDataSource(df)\n</code></pre>"},{"location":"api-reference/#sqldatasource","title":"SQLDataSource","text":"<pre><code>from dqx.sources import SQLDataSource\n\nsource = SQLDataSource(\n    connection_string=\"postgresql://user:pass@host/db\", query=\"SELECT * FROM table\"\n)\n</code></pre>"},{"location":"api-reference/#filedatasource","title":"FileDataSource","text":"<pre><code>from dqx.sources import FileDataSource\n\nsource = FileDataSource(filepath=\"data.csv\", format=\"csv\", **read_options)\n</code></pre>"},{"location":"api-reference/#clouddatasource","title":"CloudDataSource","text":"<pre><code>from dqx.sources import CloudDataSource\n\nsource = CloudDataSource(\n    uri=\"s3://bucket/path/data.parquet\", credentials=aws_credentials\n)\n</code></pre>"},{"location":"api-reference/#advanced-features","title":"Advanced Features","text":""},{"location":"api-reference/#custom-checks","title":"Custom Checks","text":"<p>Create custom validation logic.</p> <pre><code>from dqx import custom_check\n\n\n@custom_check\ndef business_rule_check(df):\n    \"\"\"Custom validation function\"\"\"\n    return (df[\"status\"] == \"active\") &amp; (df[\"balance\"] &gt; 0)\n\n\n# Or as a class\nclass CustomBusinessCheck(BaseCheck):\n    def validate(self, df):\n        valid_mask = self._apply_business_logic(df)\n        return CheckResult(\n            check_name=self.name,\n            passed=valid_mask.all(),\n            failed_rows=df[~valid_mask].index.tolist(),\n        )\n</code></pre>"},{"location":"api-reference/#conditional-validation","title":"Conditional Validation","text":"<p>Apply checks conditionally.</p> <pre><code>from dqx import ConditionalCheck\n\ncheck = ConditionalCheck(\n    condition=lambda df: df[\"region\"] == \"US\",\n    check=PatternCheck(\"phone\", r\"^\\d{3}-\\d{3}-\\d{4}$\"),\n)\n</code></pre>"},{"location":"api-reference/#check-groups","title":"Check Groups","text":"<p>Organize related checks.</p> <pre><code>from dqx import CheckGroup\n\ncustomer_checks = CheckGroup(\"Customer Validation\")\ncustomer_checks.add_checks(\n    [\n        NotNullCheck(\"customer_id\"),\n        UniqueCheck(\"customer_id\"),\n        PatternCheck(\"email\", email_regex),\n    ]\n)\n\norder_checks = CheckGroup(\"Order Validation\")\norder_checks.add_checks([NotNullCheck(\"order_id\"), RangeCheck(\"amount\", min_value=0)])\n</code></pre>"},{"location":"api-reference/#validation-pipelines","title":"Validation Pipelines","text":"<p>Chain validation stages.</p> <pre><code>from dqx import ValidationPipeline\n\npipeline = ValidationPipeline()\n\n# Add stages\npipeline.add_stage(\"basic\", basic_checks, fail_fast=True)\npipeline.add_stage(\"business\", business_checks)\npipeline.add_stage(\"statistical\", stats_checks)\n\n# Run pipeline\nresults = pipeline.run(data)\n</code></pre>"},{"location":"api-reference/#configuration","title":"Configuration","text":""},{"location":"api-reference/#global-configuration","title":"Global Configuration","text":"<pre><code>from dqx import config\n\n# Set global defaults\nconfig.set_defaults(fail_fast=False, parallel=True, max_workers=4, sample_size=100000)\n\n# Configure logging\nconfig.set_logging(\n    level=\"INFO\", format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\n</code></pre>"},{"location":"api-reference/#validator-configuration","title":"Validator Configuration","text":"<pre><code># From file\nvalidator = DataQualityValidator.from_config(\"config.yaml\")\n\n# Or programmatically\nvalidator.configure(parallel=True, max_workers=8, memory_limit=\"4GB\")\n</code></pre>"},{"location":"api-reference/#metrics-and-monitoring","title":"Metrics and Monitoring","text":""},{"location":"api-reference/#metrics-collection","title":"Metrics Collection","text":"<pre><code>from dqx.metrics import MetricsCollector\n\ncollector = MetricsCollector()\nvalidator.add_metrics_collector(collector)\n\n# After validation\nmetrics = collector.get_metrics()\nprint(f\"Validation time: {metrics['duration_ms']}ms\")\nprint(f\"Rows processed: {metrics['rows_processed']}\")\n</code></pre>"},{"location":"api-reference/#export-formats","title":"Export Formats","text":"<pre><code># Prometheus format\nprometheus_metrics = results.to_prometheus()\n\n# StatsD format\nstatsd_metrics = results.to_statsd()\n\n# Custom format\ncustom_metrics = results.export_metrics(formatter=lambda m: f\"{m['name']}:{m['value']}\")\n</code></pre>"},{"location":"api-reference/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/#exception-types","title":"Exception Types","text":"<pre><code>from dqx.exceptions import (\n    ValidationError,\n    DataSourceError,\n    CheckConfigurationError,\n    ConnectionError,\n)\n\ntry:\n    results = validator.validate(data, checks)\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\nexcept DataSourceError as e:\n    print(f\"Data source error: {e}\")\n</code></pre>"},{"location":"api-reference/#error-recovery","title":"Error Recovery","text":"<pre><code># Retry logic\nvalidator.validate_with_retry(data, checks, max_retries=3, retry_delay=1.0)\n\n# Fallback handling\nresults = validator.validate_with_fallback(\n    primary_source=sql_source, fallback_source=file_source, checks=checks\n)\n</code></pre>"},{"location":"api-reference/#utilities","title":"Utilities","text":""},{"location":"api-reference/#data-profiling","title":"Data Profiling","text":"<pre><code>from dqx.utils import DataProfiler\n\nprofiler = DataProfiler()\nprofile = profiler.analyze(df)\n\nprint(profile.summary())\n# Shows: column types, null counts, unique values, etc.\n</code></pre>"},{"location":"api-reference/#check-generator","title":"Check Generator","text":"<pre><code>from dqx.utils import CheckGenerator\n\ngenerator = CheckGenerator()\nsuggested_checks = generator.suggest_checks(\n    df, include_statistical=True, confidence_level=0.95\n)\n</code></pre>"},{"location":"api-reference/#migration-tools","title":"Migration Tools","text":"<pre><code>from dqx.utils import migrate_rules\n\n# Migrate from other formats\ndqx_checks = migrate_rules(source=\"great_expectations\", rules_file=\"expectations.json\")\n</code></pre>"},{"location":"api-reference/#integration-apis","title":"Integration APIs","text":""},{"location":"api-reference/#rest-api-client","title":"REST API Client","text":"<pre><code>from dqx.api import DQXClient\n\nclient = DQXClient(base_url=\"https://dqx-api.company.com\", api_key=\"your-api-key\")\n\n# Submit validation job\njob_id = client.submit_validation(\n    dataset_id=\"customers\", check_suite_id=\"customer_checks\"\n)\n\n# Get results\nresults = client.get_results(job_id)\n</code></pre>"},{"location":"api-reference/#webhook-integration","title":"Webhook Integration","text":"<pre><code>from dqx.integrations import WebhookNotifier\n\nnotifier = WebhookNotifier(\n    url=\"https://hooks.company.com/dqx\", headers={\"Authorization\": \"Bearer token\"}\n)\n\nvalidator.add_notifier(notifier)\n</code></pre>"},{"location":"api-reference/#type-definitions","title":"Type Definitions","text":"<pre><code>from typing import TypedDict, List, Optional, Union\n\n\nclass CheckResult(TypedDict):\n    check_name: str\n    passed: bool\n    failed_count: int\n    failed_rows: List[int]\n    error_message: Optional[str]\n\n\nclass ValidationSummary(TypedDict):\n    total_checks: int\n    passed_checks: int\n    failed_checks: int\n    pass_rate: float\n    duration_ms: float\n\n\nDataSource = Union[pd.DataFrame, str, SQLDataSource, FileDataSource]\n</code></pre>"},{"location":"api-reference/#constants-and-enums","title":"Constants and Enums","text":"<pre><code>from dqx.constants import Severity, CheckType\n\n\nclass Severity(Enum):\n    INFO = \"info\"\n    WARNING = \"warning\"\n    ERROR = \"error\"\n    CRITICAL = \"critical\"\n\n\nclass CheckType(Enum):\n    COMPLETENESS = \"completeness\"\n    CONSISTENCY = \"consistency\"\n    ACCURACY = \"accuracy\"\n    UNIQUENESS = \"uniqueness\"\n    CUSTOM = \"custom\"\n</code></pre> <p>For more examples and detailed usage, see the User Guide and examples directory.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to DQX are documented here. This changelog is automatically included from the project's root CHANGELOG.md.</p>"},{"location":"changelog/#changelog_1","title":"Changelog","text":"<p>Note: DQL (Data Quality Language) was removed in v0.5.18. The Python API remains the sole supported interface. Historical DQL-related entries remain below for reference.</p>"},{"location":"changelog/#v0517-2026-01-29","title":"v0.5.17 (2026-01-29)","text":""},{"location":"changelog/#breaking-change","title":"BREAKING CHANGE","text":"<ul> <li>api: <code>AssertionDraft.where()</code> renamed to <code>.config()</code> for better API clarity (#75)</li> <li> <p>Migration: Replace all <code>.where(name=..., severity=...)</code> calls with <code>.config(name=..., severity=...)</code></p> </li> <li> <p>commands: Remove convenience commands <code>uv run coverage</code>, <code>uv run hooks</code>, <code>uv run cleanup</code> (#74)</p> </li> <li>Migration: Use direct commands - <code>uv run pytest --cov=src/dqx</code> for coverage, <code>uv run pre-commit run</code> for hooks</li> </ul>"},{"location":"changelog/#refactor","title":"Refactor","text":"<ul> <li>api: Update 333 test occurrences and 50 documentation examples to use <code>.config()</code> method (#75)</li> <li>structure: Relocate check_commit_msg.py from src/scripts/ to bin/ (#74)</li> <li>tests: Fix flaky boundary condition test in metric expiration (#75)</li> </ul>"},{"location":"changelog/#docs","title":"Docs","text":"<ul> <li>structure: Restructure design docs - technical specs to docs/design/, implementation plans to docs/.plans/ (#73)</li> <li>cleanup: Remove 206 historical planning documents (3.3MB reduction) (#73)</li> </ul>"},{"location":"changelog/#v0516-2026-01-28","title":"v0.5.16 (2026-01-28)","text":""},{"location":"changelog/#feat","title":"Feat","text":"<ul> <li>plugins: Register multiple plugins at once using <code>register(*plugins)</code> syntax (#71)</li> <li>profiles: Add PermanentProfile that remains active across all verification runs (#70)</li> </ul>"},{"location":"changelog/#v0515-2026-01-21","title":"v0.5.15 (2026-01-21)","text":""},{"location":"changelog/#features","title":"Features","text":"<ul> <li>dql: Add tolerance modifier support for all comparison operators (<code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>!=</code>, <code>between</code>) (#66)</li> <li>functions: Add <code>pct()</code> helper for percentage notation (e.g., <code>pct(5)</code> \u2192 <code>0.05</code>)</li> <li>dql: Restrict tunables to numeric literals only (simplifies DQL parsing)</li> <li>api: Log tunable values during evaluation phase for visibility (#64)</li> </ul>"},{"location":"changelog/#fixes","title":"Fixes","text":"<ul> <li>api: Make TunableChoice logging robust to non-string choices</li> </ul>"},{"location":"changelog/#tests","title":"Tests","text":"<ul> <li>coverage: Achieve 100% test coverage (5,118/5,118 statements, 1,737 tests) (#68)</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Fix linting issues across documentation (MD036, MD040, MD034 violations)</li> <li>Clarify 100% coverage requirement and SKIP=mypy usage in development workflow</li> <li>Improve documentation structure and consistency</li> </ul>"},{"location":"changelog/#chore","title":"Chore","text":"<ul> <li>opencode: Add OpenCode configuration and documentation</li> </ul>"},{"location":"changelog/#v0514-2026-01-19","title":"v0.5.14 (2026-01-19)","text":""},{"location":"changelog/#build-system","title":"Build System","text":"<ul> <li>ci: Correct package name in release drafter template (GitHub releases will now show correct installation command: <code>pip install dqlib</code>)</li> </ul>"},{"location":"changelog/#v0513-2026-01-19","title":"v0.5.13 (2026-01-19)","text":""},{"location":"changelog/#breaking-change_1","title":"BREAKING CHANGE","text":""},{"location":"changelog/#dql-profiles-removed","title":"DQL Profiles Removed","text":"<p>Profile definitions (<code>profile \"Name\" { ... }</code>) are no longer supported in DQL syntax. Profiles must now be defined in YAML configuration files or passed programmatically via the Python API.</p> <ul> <li>Migration required for any DQL files containing <code>profile</code> blocks</li> <li>Rationale: Separates validation logic (DQL) from runtime behavior (profiles), enabling environment-specific configuration</li> </ul> <p>Before (DQL with profiles): <pre><code>suite \"Orders\" {\n    profile \"Holiday\" {\n        from 2024-12-20 to 2025-01-05\n        disable check \"Volume\"\n    }\n}\n</code></pre></p> <p>After (YAML config): <pre><code>profiles:\n  - name: \"Holiday\"\n    type: \"seasonal\"\n    start_date: \"2024-12-20\"\n    end_date: \"2025-01-05\"\n    rules:\n      - action: \"disable\"\n        target: \"check\"\n        name: \"Volume\"\n</code></pre></p>"},{"location":"changelog/#holidayprofile-renamed-to-seasonalprofile","title":"HolidayProfile Renamed to SeasonalProfile","text":"<p>The <code>HolidayProfile</code> class has been renamed to <code>SeasonalProfile</code> for better semantic clarity.</p> <ul> <li>All imports of <code>HolidayProfile</code> must be updated to <code>SeasonalProfile</code></li> <li>Behavior remains unchanged - this is a naming-only change</li> <li>The new name better reflects its purpose: seasonal date-range-based profiles</li> </ul> <p>Migration: <pre><code># Before (v0.5.x)\nfrom dqx import HolidayProfile\n\nholiday = HolidayProfile(\n    name=\"Holiday\",\n    start_date=date(2024, 12, 20),\n    end_date=date(2025, 1, 5),\n    rules=[...],\n)\n\n# After (v0.5.13)\nfrom dqx import SeasonalProfile\n\nholiday = SeasonalProfile(\n    name=\"Holiday\",\n    start_date=date(2024, 12, 20),\n    end_date=date(2025, 1, 5),\n    rules=[...],\n)\n</code></pre></p>"},{"location":"changelog/#interpreter-class-removed","title":"Interpreter Class Removed","text":"<p>The <code>dqx.dql.Interpreter</code> class has been removed. Use <code>VerificationSuite(dql=...)</code> instead.</p> <ul> <li><code>Interpreter.run()</code> \u2192 <code>VerificationSuite(dql=...).run()</code></li> <li><code>SuiteResults</code> and <code>AssertionResult</code> types removed from <code>dqx.dql</code></li> <li>All DQL execution logic now integrated directly into <code>VerificationSuite</code></li> </ul> <p>Before (Interpreter): <pre><code>from dqx.dql import Interpreter\n\ninterp = Interpreter(db=db)\nresults = interp.run(Path(\"suite.dql\"), datasources, date.today())\n</code></pre></p> <p>After (VerificationSuite): <pre><code>from dqx.api import VerificationSuite\nfrom dqx.common import ResultKey\n\nsuite = VerificationSuite(\n    dql=Path(\"suite.dql\"),\n    db=db,\n    config=Path(\"config.yaml\"),\n)\nsuite.run(datasources, ResultKey(date.today(), {}))\nresults = suite.collect_results()\n</code></pre></p>"},{"location":"changelog/#feat_1","title":"Feat","text":"<ul> <li>dql: integrate DQL directly into VerificationSuite via <code>dql</code> parameter (#60)</li> <li>api: add <code>dql</code> parameter accepting <code>Path</code> to VerificationSuite constructor</li> <li>api: implement mutual exclusion validation between <code>checks</code> and <code>dql</code> parameters</li> <li>api: enforce that <code>name</code> parameter must not be specified when using <code>dql</code></li> <li>api: enforce that <code>name</code> parameter is required when using <code>checks</code></li> <li>config: profiles now load from YAML configuration files alongside tunables</li> <li>config: add YAML profile loading with comprehensive validation</li> <li>dql: make DQL tunables fully discoverable and configurable via YAML and <code>set_param()</code></li> <li>dql: support tunables in assertion thresholds, metric expressions, and between conditions</li> <li>dql: support sequential tunable evaluation (tunables can reference other tunables)</li> <li>dql: add automatic type inference for tunables (TunableInt vs TunableFloat)</li> <li>api: accept decimal parameters in stddev functions, validate as integers</li> </ul>"},{"location":"changelog/#fix","title":"Fix","text":"<ul> <li>api: fix <code>reset()</code> to preserve DQL tunables by merging with graph tunables</li> <li>api: fix cost annotation to preserve fractional costs (e.g., 0.5)</li> <li>dql: add validation to prevent tunable names from shadowing metric functions</li> <li>graph: use DQXError instead of ValueError for name validation</li> </ul>"},{"location":"changelog/#refactor_1","title":"Refactor","text":"<ul> <li>dql: remove profile syntax from DQL grammar, AST, and parser (1039 lines removed)</li> <li>dql: move all DQL execution logic from Interpreter into VerificationSuite</li> <li>dql: simplify DQL language to focus exclusively on validation logic</li> <li>api: unify Python and DQL APIs under single VerificationSuite class</li> <li>config: rename HolidayProfile to SeasonalProfile for broader applicability</li> </ul>"},{"location":"changelog/#docs_1","title":"Docs","text":"<ul> <li>migration: add comprehensive DQL profiles to YAML migration guide</li> <li>dql: update DQL language documentation to reflect VerificationSuite integration</li> <li>dql: remove all Interpreter references from documentation</li> </ul>"},{"location":"changelog/#v0512-2026-01-19","title":"v0.5.12 (2026-01-19)","text":""},{"location":"changelog/#breaking-change_2","title":"BREAKING CHANGE","text":"<ul> <li>Graph is now built during VerificationSuite initialization</li> <li>DQL grammar syntax has been significantly simplified</li> </ul>"},{"location":"changelog/#feat_2","title":"Feat","text":"<ul> <li>config: add YAML configuration file support for tunable values (#58)</li> <li>display: substitute tunable values in assertion result expressions (#57)</li> <li>api: add tunable support to comparison methods (#56)</li> <li>dql: simplify profiles by removing recurring type and date functions (#54)</li> <li>dql: support dict tags in interpreter for key-value tag pairs (#52)</li> <li>dql: Add collect keyword for noop assertions (#51)</li> <li>dql: add interpreter with profile support and date functions (#48)</li> <li>dql: replace const with tunable keyword and remove import/export (#46)</li> <li>add reset() method to VerificationSuite for AI agent tuning (#43)</li> <li>dql: add complex DQL scenarios and comprehensive tests (#41)</li> <li>add DQL prerequisites - is_neq, is_none, is_not_none, order_by, coalesce (#39)</li> <li>add DQL prerequisites for RL agent integration</li> </ul>"},{"location":"changelog/#fix_1","title":"Fix","text":"<ul> <li>tunables: resolve SymPy caching issue causing test isolation failures (#55)</li> <li>resolve README-code discrepancies and achieve 100% coverage (#44)</li> </ul>"},{"location":"changelog/#refactor_2","title":"Refactor","text":"<ul> <li>dql: unify run_file and run_string into single run method (#49)</li> <li>api: remove is_none and is_not_none methods (#45)</li> </ul>"},{"location":"changelog/#v0511-2025-12-26","title":"v0.5.11 (2025-12-26)","text":""},{"location":"changelog/#feat_3","title":"Feat","text":"<ul> <li>api: add tags support to assertions (#34)</li> <li>profiles: add metric_multiplier support for assertion overrides (#35)</li> <li>add YAML/JSON configuration support for verification suites (#36)</li> </ul>"},{"location":"changelog/#docs_2","title":"Docs","text":"<ul> <li>add DQL language design specification (#37)</li> </ul>"},{"location":"changelog/#refactor_3","title":"Refactor","text":"<ul> <li>remove BigQuery e2e test and ERROR assertion status (#33)</li> </ul>"},{"location":"changelog/#v0510-2025-11-11","title":"v0.5.10 (2025-11-11)","text":""},{"location":"changelog/#feat_4","title":"Feat","text":"<ul> <li>ops: add CustomSQL operation with universal parameter support (#29)</li> <li>date-exclusion: implement comprehensive date exclusion with data availability tracking (#28)</li> <li>bkng-integration: refactor logger API and enhance type safety for integration (#27)</li> </ul>"},{"location":"changelog/#v059-2025-11-04","title":"v0.5.9 (2025-11-04)","text":""},{"location":"changelog/#fix_2","title":"Fix","text":"<ul> <li>tests: remove format_string parameter from logger tests</li> <li>plugins: enhance audit plugin display formatting and add logging support</li> <li>correct DoD/WoW calculations to use percentage change (#26)</li> <li>enforce string-only values in Tags type</li> <li>tests: consolidate logger tests and update to use setup_logger</li> </ul>"},{"location":"changelog/#v058-2025-11-03","title":"v0.5.8 (2025-11-03)","text":""},{"location":"changelog/#fix_3","title":"Fix","text":"<ul> <li>correct DoD/WoW calculations to use percentage change</li> <li>BigQuery SQL generation compatibility</li> <li>BigQuery SQL generation compatibility fixes</li> </ul>"},{"location":"changelog/#v057-2025-11-03","title":"v0.5.7 (2025-11-03)","text":""},{"location":"changelog/#perf","title":"Perf","text":"<ul> <li>analyzer: optimize SQL logging and formatting</li> </ul>"},{"location":"changelog/#v057a4-2025-11-03","title":"v0.5.7a4 (2025-11-03)","text":""},{"location":"changelog/#fix_4","title":"Fix","text":"<ul> <li>analyzer: ensure correct date alignment in analyze_sql_ops</li> <li>analyzer: handle BigQuery dict format in batch query results</li> </ul>"},{"location":"changelog/#v057a1-2025-11-03","title":"v0.5.7a1 (2025-11-03)","text":""},{"location":"changelog/#fix_5","title":"Fix","text":"<ul> <li>analyzer: handle BigQuery uppercase KEY in batch query results</li> </ul>"},{"location":"changelog/#refactor_4","title":"Refactor","text":"<ul> <li>analyzer: consolidate SQL ops analysis into single batch function</li> </ul>"},{"location":"changelog/#v057a0-2025-11-03","title":"v0.5.7a0 (2025-11-03)","text":""},{"location":"changelog/#fix_6","title":"Fix","text":"<ul> <li>correct package name in version import</li> <li>resolve BigQuery UNION ALL incompatibility in batch optimization</li> </ul>"},{"location":"changelog/#refactor_5","title":"Refactor","text":"<ul> <li>remove backward compatibility in analyzer</li> <li>remove numpy dependency and cleanup project structure (#24)</li> </ul>"},{"location":"changelog/#v056-2025-11-03","title":"v0.5.6 (2025-11-03)","text":""},{"location":"changelog/#fix_7","title":"Fix","text":"<ul> <li>improve metric handling and analyzer architecture (#19)</li> </ul>"},{"location":"changelog/#refactor_6","title":"Refactor","text":"<ul> <li>remove numpy dependency from analyzer</li> <li>cache: enhance metric storage and add performance tracking (#23)</li> <li>cache: enhance metric storage and add performance tracking</li> </ul>"},{"location":"changelog/#perf_1","title":"Perf","text":"<ul> <li>optimize metric cache and improve code quality (#20)</li> </ul>"},{"location":"changelog/#v055-2025-10-30","title":"v0.5.5 (2025-10-30)","text":""},{"location":"changelog/#feat_5","title":"Feat","text":"<ul> <li>Add CommercialDataSource with date filtering support (#17)</li> <li>add metric expiration methods to MetricDB (#15)</li> <li>ci: standardize workflows and add GitHub settings (#9)</li> </ul>"},{"location":"changelog/#fix_8","title":"Fix","text":"<ul> <li>resolve deprecation warning for invalid escape sequence (#16)</li> <li>orm: remove unnecessary lambda from uuid default value (#14)</li> <li>address Python special method protocol violation in test (#11)</li> <li>resolve GitHub release character limit issue (#8)</li> </ul>"},{"location":"changelog/#v054-2025-10-29","title":"v0.5.4 (2025-10-29)","text":""},{"location":"changelog/#fix_9","title":"Fix","text":"<ul> <li>resolve GitHub release character limit issue</li> <li>resolve release workflow issues and update dqlib documentation (#7)</li> </ul>"},{"location":"changelog/#v053-2025-10-29","title":"v0.5.3 (2025-10-29)","text":""},{"location":"changelog/#fix_10","title":"Fix","text":"<ul> <li>resolve release workflow issues and update dqlib documentation</li> </ul>"},{"location":"changelog/#v052-2025-10-29","title":"v0.5.2 (2025-10-29)","text":""},{"location":"changelog/#fix_11","title":"Fix","text":"<ul> <li>ci: remove docker-publish job from release workflow (#5)</li> </ul>"},{"location":"changelog/#v051-2025-10-29","title":"v0.5.1 (2025-10-29)","text":""},{"location":"changelog/#fix_12","title":"Fix","text":"<ul> <li>ci: remove docker-publish job from release workflow</li> </ul>"},{"location":"changelog/#v050-2025-10-29","title":"v0.5.0 (2025-10-29)","text":""},{"location":"changelog/#feat_6","title":"Feat","text":"<ul> <li>add version attribute to dqx module</li> </ul>"},{"location":"changelog/#fix_13","title":"Fix","text":"<ul> <li>ci: fix test-release job to handle PEP 668 system Python protection</li> <li>ci: remove redundant pull_request_target from release-drafter workflow</li> <li>ci: add pull-requests write permission to docs workflow</li> <li>ci: correct codecov action parameter from 'file' to 'files'</li> <li>ci: add --system flag to release workflow test installation</li> </ul> <p>For more detailed release notes, see the GitHub Releases page.</p>"},{"location":"ci-cd-setup/","title":"CI/CD Setup Guide for DQX","text":"<p>This guide documents the complete CI/CD setup for the DQX project, including all required secrets and configurations.</p>"},{"location":"ci-cd-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>GitHub CI/CD Setup Guide - Step-by-step setup instructions</li> <li>GitHub CI/CD Operations Guide - Daily operations and usage</li> </ul> <p>This document provides a technical overview and reference. For practical guides, see the documents above.</p>"},{"location":"ci-cd-setup/#github-actions-workflows","title":"GitHub Actions Workflows","text":""},{"location":"ci-cd-setup/#1-test-coverage-workflow","title":"1. Test &amp; Coverage Workflow","text":"<p>File: <code>.github/workflows/test.yml</code> - Runs on: Push to main/develop, pull requests - Tests multiple Python versions (3.11, 3.12, 3.13) - Generates coverage reports and badges - Includes type coverage reporting</p>"},{"location":"ci-cd-setup/#2-documentation-workflow","title":"2. Documentation Workflow","text":"<p>File: <code>.github/workflows/docs.yml</code> - Builds MkDocs documentation - Tests documentation build - Publishes to GitHub Pages (optional)</p>"},{"location":"ci-cd-setup/#3-release-workflow","title":"3. Release Workflow","text":"<p>File: <code>.github/workflows/release.yml</code> - Triggers on: GitHub releases - Builds Python packages (wheel and sdist) - Publishes to PyPI - Creates GitHub release artifacts</p>"},{"location":"ci-cd-setup/#4-security-scanning","title":"4. Security Scanning","text":"<p>File: <code>.github/workflows/codeql.yml</code> - Runs CodeQL analysis - Performs dependency review on PRs - Runs pip-audit for vulnerability scanning</p>"},{"location":"ci-cd-setup/#5-example-validation","title":"5. Example Validation","text":"<p>File: <code>.github/workflows/examples.yml</code> - Validates all example scripts - Ensures examples stay up-to-date</p>"},{"location":"ci-cd-setup/#required-secrets","title":"Required Secrets","text":""},{"location":"ci-cd-setup/#pypi-publishing","title":"PyPI Publishing","text":"<ul> <li><code>PYPI_API_TOKEN</code>: PyPI API token for package publishing</li> <li>Create at: https://pypi.org/manage/account/token/</li> <li>Scope: Can upload to project \"dqx\"</li> </ul>"},{"location":"ci-cd-setup/#test-pypi-optional","title":"Test PyPI (Optional)","text":"<ul> <li><code>TEST_PYPI_API_TOKEN</code>: Test PyPI API token</li> <li>Create at: https://test.pypi.org/manage/account/token/</li> <li>Use for testing releases before production</li> </ul>"},{"location":"ci-cd-setup/#github-pages-optional","title":"GitHub Pages (Optional)","text":"<ul> <li><code>GITHUB_TOKEN</code>: Automatically provided by GitHub Actions</li> <li>No setup required</li> <li>Used for publishing documentation</li> </ul>"},{"location":"ci-cd-setup/#google-analytics-optional","title":"Google Analytics (Optional)","text":"<ul> <li><code>GOOGLE_ANALYTICS_KEY</code>: Google Analytics tracking ID</li> <li>Format: <code>G-XXXXXXXXXX</code></li> <li>Used in MkDocs for documentation analytics</li> </ul>"},{"location":"ci-cd-setup/#external-services","title":"External Services","text":""},{"location":"ci-cd-setup/#1-readthedocs","title":"1. ReadTheDocs","text":"<p>Configuration: <code>.readthedocs.yml</code> - Sign up at: https://readthedocs.org - Import your GitHub repository - Documentation will be available at: https://dqx.readthedocs.io</p>"},{"location":"ci-cd-setup/#2-coderabbit","title":"2. CodeRabbit","text":"<p>Configuration: <code>.coderabbit.yaml</code> - Install from: https://github.com/marketplace/coderabbit - Provides AI-powered code reviews - No additional configuration needed</p>"},{"location":"ci-cd-setup/#3-dependabot","title":"3. Dependabot","text":"<p>Configuration: <code>.github/dependabot.yml</code> - Automatically enabled for GitHub repositories - Creates PRs for dependency updates - Review and merge security updates promptly</p>"},{"location":"ci-cd-setup/#4-release-drafter","title":"4. Release Drafter","text":"<p>Configuration: <code>.github/release-drafter.yml</code> - Automatically creates draft releases - Categorizes changes based on PR labels - Updates release notes with each merge to main</p>"},{"location":"ci-cd-setup/#setting-up-secrets","title":"Setting Up Secrets","text":""},{"location":"ci-cd-setup/#via-github-web-interface","title":"Via GitHub Web Interface","text":"<ol> <li>Go to Settings \u2192 Secrets and variables \u2192 Actions</li> <li>Click \"New repository secret\"</li> <li>Add each secret with its name and value</li> </ol>"},{"location":"ci-cd-setup/#via-github-cli","title":"Via GitHub CLI","text":"<pre><code># Install GitHub CLI\nbrew install gh  # macOS\n# or visit: https://cli.github.com/\n\n# Authenticate\ngh auth login\n\n# Add secrets\ngh secret set PYPI_API_TOKEN --body=\"pypi-...\"\ngh secret set TEST_PYPI_API_TOKEN --body=\"pypi-...\"\n</code></pre>"},{"location":"ci-cd-setup/#workflow-permissions","title":"Workflow Permissions","text":"<p>Ensure workflows have proper permissions:</p> <ol> <li>Go to Settings \u2192 Actions \u2192 General</li> <li>Under \"Workflow permissions\", select:</li> <li>\"Read and write permissions\"</li> <li>\"Allow GitHub Actions to create and approve pull requests\"</li> </ol>"},{"location":"ci-cd-setup/#branch-protection","title":"Branch Protection","text":"<p>Recommended branch protection rules for <code>main</code>:</p> <ol> <li>Require pull request reviews</li> <li>Require status checks:</li> <li><code>test (3.11)</code> - Main test suite</li> <li><code>analyze</code> - CodeQL security</li> <li><code>docs</code> - Documentation build</li> <li>Include administrators</li> <li>Allow force pushes (only for admins)</li> </ol>"},{"location":"ci-cd-setup/#local-development","title":"Local Development","text":""},{"location":"ci-cd-setup/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># Install pre-commit hooks\npre-commit install\n\n# Run hooks manually\nuv run pre-commit run --all-files\n\n# Skip specific hooks\nSKIP=mypy git commit -m \"...\"\n</code></pre>"},{"location":"ci-cd-setup/#testing-workflows-locally","title":"Testing Workflows Locally","text":"<pre><code># Install act (GitHub Actions local runner)\nbrew install act  # macOS\n\n# Run specific workflow\nact -W .github/workflows/test.yml\n\n# Run with secrets\nact -W .github/workflows/release.yml --secret-file .secrets\n</code></pre>"},{"location":"ci-cd-setup/#monitoring-maintenance","title":"Monitoring &amp; Maintenance","text":""},{"location":"ci-cd-setup/#github-actions-dashboard","title":"GitHub Actions Dashboard","text":"<ul> <li>Monitor at: <code>https://github.com/&lt;owner&gt;/dqx/actions</code></li> <li>Set up notifications for failed workflows</li> <li>Review workflow run times and optimize if needed</li> </ul>"},{"location":"ci-cd-setup/#dependency-updates","title":"Dependency Updates","text":"<ul> <li>Review Dependabot PRs weekly</li> <li>Run security audits: <code>uv run pip-audit</code></li> <li>Keep GitHub Actions versions updated</li> </ul>"},{"location":"ci-cd-setup/#documentation","title":"Documentation","text":"<ul> <li>Verify ReadTheDocs builds after each release</li> <li>Check for broken links: <code>mkdocs serve --strict</code></li> <li>Update screenshots and examples regularly</li> </ul>"},{"location":"ci-cd-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ci-cd-setup/#common-issues","title":"Common Issues","text":"<ol> <li>PyPI Upload Fails</li> <li>Verify API token has upload permissions</li> <li>Check package version isn't already published</li> <li> <p>Ensure package builds locally: <code>uv build</code></p> </li> <li> <p>Documentation Build Fails</p> </li> <li>Check MkDocs configuration: <code>mkdocs build --strict</code></li> <li>Verify all referenced files exist</li> <li> <p>Check for Python version compatibility</p> </li> <li> <p>Tests Fail on CI but Pass Locally</p> </li> <li>Check for environment differences</li> <li>Verify all test dependencies are installed</li> <li> <p>Look for timing-dependent tests</p> </li> <li> <p>Coverage Reports Not Updating</p> </li> <li>Ensure coverage files are generated</li> <li>Check GitHub token permissions</li> <li>Verify badge URLs are correct</li> </ol>"},{"location":"ci-cd-setup/#release-process","title":"Release Process","text":"<ol> <li> <p>Prepare Release <pre><code># Update version in pyproject.toml\n# Update CHANGELOG.md\ngit commit -m \"chore: prepare release v0.4.0\"\ngit tag v0.4.0\ngit push origin main --tags\n</code></pre></p> </li> <li> <p>Create GitHub Release</p> </li> <li>Go to Releases \u2192 Draft a new release</li> <li>Choose tag <code>v0.4.0</code></li> <li>Release notes are auto-generated</li> <li> <p>Publish release</p> </li> <li> <p>Verify Deployment</p> </li> <li>Check PyPI: https://pypi.org/project/dqx/</li> <li>Verify docs: https://dqx.readthedocs.io</li> <li>Test installation: <code>pip install dqx==0.4.0</code></li> </ol>"},{"location":"ci-cd-setup/#security-considerations","title":"Security Considerations","text":"<ul> <li>Rotate API tokens annually</li> <li>Use environment-specific secrets</li> <li>Enable 2FA on PyPI and GitHub accounts</li> <li>Review security alerts promptly</li> <li>Keep workflows up-to-date</li> </ul>"},{"location":"ci-cd-setup/#contact-support","title":"Contact &amp; Support","text":"<p>For CI/CD issues: - Check GitHub Actions logs - Review workflow configuration - Open an issue with the <code>ci</code> label - Tag @phamducnam for urgent issues</p>"},{"location":"design/","title":"DQX Design Document","text":""},{"location":"design/#1-overview","title":"1. Overview","text":""},{"location":"design/#what-is-dqx","title":"What is DQX","text":"<p>DQX is a data quality analysis framework that enables developers to define and run data quality checks using native Python code. It provides a SQL-based backend for efficient computation and supports extensible metrics, validators, and data sources.</p>"},{"location":"design/#core-design-philosophy","title":"Core Design Philosophy","text":"<p>DQX prioritizes simplicity, composability, and performance: - Code over configuration: Define checks in Python, not through configuration - SQL-powered: Execute queries directly on data warehouses - Modular architecture: Extend with custom metrics and validators - Symbolic computation: Express complex business rules naturally</p>"},{"location":"design/#2-native-python-api-vs-configuration","title":"2. Native Python API vs Configuration","text":""},{"location":"design/#design-decision-code-over-config","title":"Design Decision: Code over Config","text":"<p>Unlike configuration-based systems that use YAML or JSON, DQX uses Python code as the primary interface for defining data quality checks. This fundamental design choice drives the entire architecture.</p>"},{"location":"design/#advantages","title":"Advantages","text":"<ul> <li>IDE support: Full autocomplete, type checking, and inline documentation</li> <li>Composable &amp; reusable functions: Build complex checks from simple components</li> <li>Version control friendly: Standard code review processes apply</li> <li>Dynamic check generation: Use loops, conditions, and functions to create checks programmatically</li> </ul>"},{"location":"design/#3-modular-extensible-architecture","title":"3. Modular &amp; Extensible Architecture","text":""},{"location":"design/#plugin-based-design","title":"Plugin-Based Design","text":"<p>DQX uses a protocol-based architecture that allows users to extend the framework without modifying core code.</p>"},{"location":"design/#extension-points","title":"Extension Points","text":"<ul> <li>Custom Metrics: Implement the <code>MetricSpec</code> protocol to create new metrics</li> <li>Custom Validators: Implement validation functions following the standard signature</li> <li>Custom Data Sources: Implement the <code>SqlDataSource</code> protocol for new data backends</li> <li>Custom SQL Dialects: Add support for database-specific SQL syntax</li> </ul>"},{"location":"design/#4-symbolic-metrics","title":"4. Symbolic Metrics","text":""},{"location":"design/#how-symbolic-metrics-work","title":"How Symbolic Metrics Work","text":"<p>Metrics in DQX are symbolic expressions powered by SymPy, Python's symbolic mathematics library. The framework evaluates metrics by collecting symbol values through SQL queries at execution time.</p>"},{"location":"design/#key-advantages","title":"Key Advantages","text":"<ul> <li>Mathematical operations on metrics: Combine metrics using any SymPy functions</li> <li>Cross-datasource validation: Combine metrics from different data sources in a single expression</li> <li>Lazy evaluation: SQL generation happens only when needed</li> <li>Declarative expressions: Write business rules as mathematical formulas</li> </ul>"},{"location":"design/#5-sql-backend-architecture","title":"5. SQL Backend Architecture","text":""},{"location":"design/#why-sql-over-spark","title":"Why SQL over Spark","text":"<p>DQX uses SQL as its computation backend instead of distributed frameworks like Spark:</p> <ul> <li>Faster execution for single-node operations: Direct SQL execution without cluster overhead</li> <li>No Spark cluster required: Simpler infrastructure and lower operational costs</li> <li>Lower operational complexity: No JVM tuning or cluster management</li> <li>Rich analytical functions: Leverage database-native window functions and aggregations</li> </ul>"},{"location":"design/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Single-pass computation for multiple metrics for multiple days.</li> <li>Efficient CTE-based query generation</li> </ul>"},{"location":"design/#6-severity-levels","title":"6. Severity Levels","text":""},{"location":"design/#p0-p3-definitions","title":"P0-P3 Definitions","text":"<ul> <li>P0 (Crisis): Data corruption or complete failure requiring immediate intervention</li> <li>P1 (Major): Significant issues affecting data reliability and business decisions</li> <li>P2 (Degraded): Quality degradation that needs investigation but not immediate action</li> <li>P3 (Minor Noise): Informational alerts for monitoring trends and anomalies</li> </ul>"},{"location":"design/#7-api-reference-supported-operations","title":"7. API Reference &amp; Supported Operations","text":""},{"location":"design/#supported-dialects","title":"Supported Dialects","text":"Dialect Description DuckDB Default dialect, in-memory analytical database BigQuery Google Cloud data warehouse PyArrow Arrow tables via DuckDB integration"},{"location":"design/#supported-metrics","title":"Supported Metrics","text":"Metric Method Description Row Count <code>num_rows</code> Total number of rows First <code>first</code> First value in column Average <code>average</code> Mean value of column Sum <code>sum</code> Sum of column values Minimum <code>minimum</code> Minimum value Maximum <code>maximum</code> Maximum value Variance <code>variance</code> Statistical variance Null Count <code>null_count</code> Count of null values Duplicate Count <code>duplicate_count</code> Count of duplicate rows"},{"location":"design/#assertion-methods","title":"Assertion Methods","text":"Method Description <code>is_eq</code> Assert equals with tolerance <code>is_neq</code> Assert not equal to <code>is_gt</code> Assert greater than <code>is_lt</code> Assert less than <code>is_geq</code> Assert greater than or equal to <code>is_leq</code> Assert less than or equal to <code>is_between</code> Assert in range (inclusive) <code>is_positive</code> Assert value &gt; 0 <code>is_negative</code> Assert value &lt; 0 <code>is_zero</code> Assert value is effectively zero <code>is_none</code> Assert value is None <code>is_not_none</code> Assert value is not None <code>within_tol</code> Assert within relative or absolute tolerance"},{"location":"dqguard-to-dqx-comparison/","title":"DQGuard to DQX: Evolution of Data Quality at Scale","text":""},{"location":"dqguard-to-dqx-comparison/#executive-summary","title":"Executive Summary","text":"<p>DQX represents the next generation of data quality tooling, evolving from DQGuard's configuration-based approach to a code-first framework. While DQGuard pioneered automated quality monitoring through JSON configurations, DQX advances the field with mathematical expressions, type safety, and modern architecture.</p> <p>This document guides teams through understanding the evolution, key improvements, and migration considerations.</p>"},{"location":"dqguard-to-dqx-comparison/#the-evolution-story","title":"The Evolution Story","text":""},{"location":"dqguard-to-dqx-comparison/#where-we-started-dqguard","title":"Where We Started: DQGuard","text":"<p>DQGuard solved critical problems: - High overhead in quality monitoring across teams - Need for long-term reliability measurement - Slow incident response times - Unreliable business-critical data</p> <p>The solution: JSON-based configurations that automated metric collection and validation.</p>"},{"location":"dqguard-to-dqx-comparison/#where-were-going-dqx","title":"Where We're Going: DQX","text":"<p>DQX addresses modern challenges: - Complex validation logic requiring mathematical expressions - Efficient data processing through modern architecture - Developer productivity through type safety and IDE support - Flexible assertions beyond time-series patterns</p>"},{"location":"dqguard-to-dqx-comparison/#key-improvements","title":"Key Improvements","text":""},{"location":"dqguard-to-dqx-comparison/#1-from-configuration-to-code","title":"1. From Configuration to Code","text":"<p>DQGuard: Define checks in JSON <pre><code>{\n    \"name\": \"default.reservation_flatter\",\n    \"type\": \"table\",\n    \"metrics\": [\"num_rows\"],\n    \"validators\": [{\n        \"name\": \"is_geq\",\n        \"threshold\": 1000000\n    }]\n}\n</code></pre></p> <p>DQX: Express checks as Python functions <pre><code>@check(\"Reservations have sufficient volume\")\ndef validate_reservations(mp: MetricProvider, ctx: Context) -&gt; None:\n    ctx.assert_that(mp.num_rows()).config(name=\"Daily volume check\").is_geq(1000000)\n</code></pre></p> <p>Benefits: - Type checking catches errors before runtime - IDE autocompletion speeds development - Version control shows meaningful diffs - Reusable logic through standard Python patterns</p>"},{"location":"dqguard-to-dqx-comparison/#2-mathematical-expressions","title":"2. Mathematical Expressions","text":"<p>DQGuard: Fixed validator patterns <pre><code>{\n    \"validators\": [\"within_2_sd\", \"wow_change\"]\n}\n</code></pre></p> <p>DQX: Arbitrary mathematical assertions <pre><code># Revenue integrity check\ncalculated = mp.sum(\"price\") * mp.sum(\"quantity\")\nreported = mp.sum(\"revenue\")\nerror_rate = sp.Abs(calculated - reported) / reported\n\nctx.assert_that(error_rate).config(name=\"Revenue calculation accuracy\").is_lt(0.001)\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#3-processing-architecture","title":"3. Processing Architecture","text":"<p>DQGuard: - Spark-based processing - Separate metric collection and validation passes - Scales with cluster resources</p> <p>DQX: - DuckDB columnar engine - Single-pass optimization - Efficient query execution</p>"},{"location":"dqguard-to-dqx-comparison/#4-developer-experience","title":"4. Developer Experience","text":"<p>DQGuard: <pre><code># Edit JSON\nvim lib/quality_check.json\n\n# Run in workflow\n&lt;action name=\"quality_check\"&gt;\n    &lt;sub-workflow&gt;\n        &lt;app-path&gt;${workflowsBaseDir}/data-quality-library/production-app&lt;/app-path&gt;\n    &lt;/sub-workflow&gt;\n&lt;/action&gt;\n</code></pre></p> <p>DQX: <pre><code># Write with IDE support\ndef validate_orders(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Autocompletion shows available metrics\n    ctx.assert_that(mp.average(\"price\")).config(name=\"Price validation\").is_positive()\n\n\n# Run directly\nsuite = VerificationSuite([validate_orders], db)\nsuite.run(datasources, key)\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#feature-comparison","title":"Feature Comparison","text":"Feature DQGuard DQX Configuration JSON files Python code Type Safety Runtime validation Compile-time checking Metrics 15 predefined Extensible + custom Validators 12 patterns Unlimited expressions Engine Spark clusters DuckDB Processing Model Multiple passes Single pass Architecture Distributed Columnar engine IDE Support JSON schemas Full Python tooling Testing Manual validation Standard unit tests Debugging Log analysis Interactive debugging Deployment Oozie workflows Any Python environment"},{"location":"dqguard-to-dqx-comparison/#migration-guide","title":"Migration Guide","text":""},{"location":"dqguard-to-dqx-comparison/#assessment-phase","title":"Assessment Phase","text":"<ol> <li>Inventory Current Checks</li> <li>List all DQGuard configurations</li> <li>Identify custom validators</li> <li> <p>Note integration points</p> </li> <li> <p>Complexity Analysis</p> </li> <li>Simple threshold checks \u2192 Direct migration</li> <li>Time-series validators \u2192 May need custom logic</li> <li>Complex preprocessors \u2192 Evaluate alternatives</li> </ol>"},{"location":"dqguard-to-dqx-comparison/#migration-patterns","title":"Migration Patterns","text":""},{"location":"dqguard-to-dqx-comparison/#pattern-1-simple-metrics","title":"Pattern 1: Simple Metrics","text":"<p>DQGuard: <pre><code>{\n    \"metrics\": [\"num_rows\", \"null_count\"],\n    \"validators\": [{\"name\": \"is_geq\", \"threshold\": 0}]\n}\n</code></pre></p> <p>DQX: <pre><code>ctx.assert_that(mp.num_rows()).config(name=\"Has rows\").is_positive()\nctx.assert_that(mp.null_count(\"id\")).config(name=\"No null IDs\").is_zero()\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#pattern-2-time-series-validation","title":"Pattern 2: Time-Series Validation","text":"<p>DQGuard: <pre><code>{\n    \"validators\": [\"within_2_sd\"],\n    \"time_range\": \"7 days\"\n}\n</code></pre></p> <p>DQX: <pre><code># Collect historical metrics\nhistory = [mp.sum(\"revenue\", key=ctx.key.lag(i)) for i in range(1, 8)]\nmean = sum(history) / len(history)\nstd = calculate_std(history)\n\n# Apply validation\ncurrent = mp.sum(\"revenue\")\nz_score = abs(current - mean) / std\nctx.assert_that(z_score).config(name=\"Within 2 SD\").is_lt(2)\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#pattern-3-duplicate-detection","title":"Pattern 3: Duplicate Detection","text":"<p>DQGuard: <pre><code>{\n    \"metrics\": [{\n        \"name\": \"has_duplicate\",\n        \"columns\": [\"transaction_id\"]\n    }]\n}\n</code></pre></p> <p>DQX: <pre><code># Built-in duplicate detection\nduplicate_count = mp.duplicate_count(\"transaction_id\")\nctx.assert_that(duplicate_count).config(name=\"No duplicates\").is_zero()\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#coexistence-strategy","title":"Coexistence Strategy","text":"<p>Teams can run both systems during migration:</p> <ol> <li>Phase 1: Shadow Mode</li> <li>Keep DQGuard running</li> <li>Add DQX checks in parallel</li> <li> <p>Compare results</p> </li> <li> <p>Phase 2: Gradual Cutover</p> </li> <li>Migrate one dataset at a time</li> <li>Maintain critical DQGuard checks</li> <li> <p>Build confidence in DQX</p> </li> <li> <p>Phase 3: Full Migration</p> </li> <li>Retire DQGuard configurations</li> <li>Leverage DQX-only features</li> <li>Optimize for performance</li> </ol>"},{"location":"dqguard-to-dqx-comparison/#advanced-dqx-capabilities","title":"Advanced DQX Capabilities","text":""},{"location":"dqguard-to-dqx-comparison/#1-cross-dataset-validation","title":"1. Cross-Dataset Validation","text":"<pre><code>@check(\"Production matches staging\")\ndef compare_environments(mp: MetricProvider, ctx: Context) -&gt; None:\n    prod = mp.sum(\"revenue\", dataset=\"production\")\n    staging = mp.sum(\"revenue\", dataset=\"staging\")\n\n    ctx.assert_that(prod).config(name=\"Environment parity\").is_eq(staging, tol=0.01)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#2-custom-metric-extensions","title":"2. Custom Metric Extensions","text":"<pre><code># DQX supports custom metrics through extensions\nday_over_day = mp.ext.day_over_day(specs.Average(\"response_time\"))\nctx.assert_that(day_over_day).config(name=\"Response time trend\").is_between(-0.1, 0.1)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#3-symbolic-mathematics","title":"3. Symbolic Mathematics","text":"<pre><code># Complex business rules as mathematical expressions\nmargin = (mp.sum(\"revenue\") - mp.sum(\"cost\")) / mp.sum(\"revenue\")\ntarget_margin = 0.3\n\nctx.assert_that(margin).config(name=\"Profit margin target\", severity=\"P0\").is_geq(\n    target_margin\n)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#best-practices","title":"Best Practices","text":""},{"location":"dqguard-to-dqx-comparison/#1-name-every-assertion","title":"1. Name Every Assertion","text":"<pre><code># Good: Clear, specific names\nctx.assert_that(metric).config(name=\"Daily revenue within 10% of average\")\n\n# Avoid: Generic names\nctx.assert_that(metric).config(name=\"Revenue check\")\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#2-group-related-checks","title":"2. Group Related Checks","text":"<pre><code>@check(\"Payment integrity\", datasets=[\"payments\"])\ndef validate_payments(mp: MetricProvider, ctx: Context) -&gt; None:\n    # All payment validations in one check\n    ctx.assert_that(mp.null_count(\"payment_id\")).config(\n        name=\"Payment ID completeness\"\n    ).is_zero()\n\n    ctx.assert_that(mp.average(\"amount\")).config(\n        name=\"Average payment reasonable\"\n    ).is_between(10, 1000)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#3-use-severity-levels","title":"3. Use Severity Levels","text":"<pre><code>ctx.assert_that(critical_metric).config(\n    name=\"Critical business metric\", severity=\"P0\"  # Pages on-call\n).is_positive()\n\nctx.assert_that(quality_metric).config(\n    name=\"Data quality indicator\", severity=\"P2\"  # Daily review\n).is_within_range()\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#conclusion","title":"Conclusion","text":"<p>DQX builds upon DQGuard's foundation while addressing modern data quality challenges. The evolution from configuration to code enables:</p> <ul> <li>Better expressiveness through mathematical assertions</li> <li>Modern architecture with DuckDB's columnar processing</li> <li>Enhanced productivity with type safety and IDE support</li> <li>Greater flexibility for complex business rules</li> </ul> <p>Teams should evaluate their current DQGuard usage and plan migration based on complexity and criticality. The coexistence strategy allows gradual adoption while maintaining quality coverage.</p> <p>For teams starting fresh, DQX provides a modern, flexible solution for data quality validation.</p>"},{"location":"github-cicd-operations-guide/","title":"GitHub CI/CD Operations Guide","text":"<p>This guide covers daily operations and interactions with the CI/CD system after initial setup.</p>"},{"location":"github-cicd-operations-guide/#daily-development-workflow","title":"Daily Development Workflow","text":""},{"location":"github-cicd-operations-guide/#working-with-pre-commit-hooks","title":"Working with Pre-commit Hooks","text":"<p>Pre-commit hooks run automatically before each commit to catch issues early.</p>"},{"location":"github-cicd-operations-guide/#running-hooks-locally","title":"Running Hooks Locally","text":"<pre><code># Run all hooks on staged files\nuv run pre-commit run\n\n# Run all hooks on all files\nuv run pre-commit run --all-files\n\n# Run specific hook\nuv run pre-commit run mypy\n\n# See available options\nuv run pre-commit run --help\n</code></pre>"},{"location":"github-cicd-operations-guide/#common-hook-failures-and-fixes","title":"Common Hook Failures and Fixes","text":"<p>Ruff formatting issues: <pre><code># Auto-fix formatting\nuv run ruff check --fix .\nuv run ruff format .\n\n# Then stage the fixes\ngit add -u\n</code></pre></p> <p>Mypy type errors: - Add missing type hints - Fix type inconsistencies - Use <code># type: ignore[error-code]</code> sparingly with justification</p> <p>Trailing whitespace: - Most editors can auto-remove on save - The hook will fix automatically</p>"},{"location":"github-cicd-operations-guide/#bypassing-hooks-use-sparingly","title":"Bypassing Hooks (Use Sparingly)","text":"<pre><code># Skip all hooks - use only when necessary\ngit commit --no-verify -m \"emergency: fix critical bug\"\n\n# Skip specific hooks\nSKIP=mypy git commit -m \"wip: debugging in progress\"\n</code></pre>"},{"location":"github-cicd-operations-guide/#commit-standards","title":"Commit Standards","text":"<p>Follow conventional commits for clear history and automatic versioning.</p>"},{"location":"github-cicd-operations-guide/#format","title":"Format","text":"<pre><code>type(scope): subject\n\nbody (optional)\n\nfooter (optional)\n</code></pre>"},{"location":"github-cicd-operations-guide/#common-types","title":"Common Types","text":"<ul> <li><code>feat</code>: New feature (triggers minor version)</li> <li><code>fix</code>: Bug fix (triggers patch version)</li> <li><code>docs</code>: Documentation only</li> <li><code>style</code>: Code style (no logic changes)</li> <li><code>refactor</code>: Code restructure</li> <li><code>perf</code>: Performance improvement</li> <li><code>test</code>: Test additions/fixes</li> <li><code>chore</code>: Maintenance tasks</li> </ul>"},{"location":"github-cicd-operations-guide/#examples","title":"Examples","text":"<pre><code>git commit -m \"feat(analyzer): add batch processing support\"\ngit commit -m \"fix(validator): handle null values correctly\"\ngit commit -m \"docs: update API examples\"\n</code></pre>"},{"location":"github-cicd-operations-guide/#creating-pull-requests","title":"Creating Pull Requests","text":"<ol> <li> <p>Create feature branch: <pre><code>git checkout -b feat/your-feature-name\n</code></pre></p> </li> <li> <p>Push and create PR: <pre><code>git push -u origin feat/your-feature-name\ngh pr create --title \"feat: your feature\" --body \"Description\"\n</code></pre></p> </li> <li> <p>Required elements:</p> </li> <li>Descriptive title following commit conventions</li> <li>Clear description of changes</li> <li>Link to related issue (if any)</li> <li>Screenshots for UI changes</li> </ol>"},{"location":"github-cicd-operations-guide/#code-review-process","title":"Code Review Process","text":""},{"location":"github-cicd-operations-guide/#understanding-coderabbit-ai-reviews","title":"Understanding CodeRabbit AI Reviews","text":"<p>CodeRabbit automatically reviews PRs within 5 minutes.</p>"},{"location":"github-cicd-operations-guide/#review-components","title":"Review Components","text":"<ol> <li>Summary Section</li> <li>High-level overview</li> <li>Key changes identified</li> <li> <p>Potential issues flagged</p> </li> <li> <p>Detailed Comments</p> </li> <li>Line-by-line suggestions</li> <li>Best practice violations</li> <li>Security concerns</li> <li> <p>Performance issues</p> </li> <li> <p>Review Status</p> </li> <li>\u2705 Approved: No critical issues</li> <li>\ud83d\udcac Comments: Suggestions provided</li> <li>\ud83d\udd04 Changes requested: Critical issues found</li> </ol>"},{"location":"github-cicd-operations-guide/#interacting-with-coderabbit","title":"Interacting with CodeRabbit","text":"<p>Common commands in PR comments: <pre><code>@coderabbitai review\n@coderabbitai resolve\n@coderabbitai ignore\n@coderabbitai help\n</code></pre></p> <p>Responding to suggestions: 1. Accept suggestion: Click \"Accept\" on the comment 2. Dismiss: Reply explaining why it's not applicable 3. Ask for clarification: Reply with your question</p>"},{"location":"github-cicd-operations-guide/#customizing-reviews","title":"Customizing Reviews","text":"<p>Edit <code>.coderabbit.yaml</code> to adjust: - Review strictness - Custom patterns - Excluded paths - Project-specific rules</p>"},{"location":"github-cicd-operations-guide/#handling-review-feedback","title":"Handling Review Feedback","text":"<ol> <li>Address all comments - Even if just to explain why not changed</li> <li>Batch fixes - Make all changes before requesting re-review</li> <li>Update PR description - Note what feedback was addressed</li> <li>Request re-review - Use GitHub's re-review feature</li> </ol>"},{"location":"github-cicd-operations-guide/#managing-dependencies","title":"Managing Dependencies","text":""},{"location":"github-cicd-operations-guide/#dependabot-pull-requests","title":"Dependabot Pull Requests","text":"<p>Dependabot creates PRs for dependency updates automatically.</p>"},{"location":"github-cicd-operations-guide/#understanding-update-prs","title":"Understanding Update PRs","text":"<p>PR Title Format: <pre><code>Bump package-name from 1.2.3 to 1.2.4\n</code></pre></p> <p>PR includes: - Changelog excerpts - Commit list - Compatibility score - Release notes link</p>"},{"location":"github-cicd-operations-guide/#review-process","title":"Review Process","text":"<ol> <li>Check CI status - All tests must pass</li> <li>Review changelog - Look for breaking changes</li> <li>Check compatibility - Verify with your Python versions</li> <li>Test locally if needed: <pre><code>gh pr checkout 123\nuv sync\nuv run pytest tests/\n</code></pre></li> </ol>"},{"location":"github-cicd-operations-guide/#dependabot-commands","title":"Dependabot Commands","text":"<p>Use these in PR comments:</p> <pre><code>@dependabot rebase\n@dependabot recreate\n@dependabot merge\n@dependabot squash and merge\n@dependabot cancel merge\n@dependabot reopen\n@dependabot close\n@dependabot ignore this major version\n@dependabot ignore this minor version\n@dependabot ignore this dependency\n</code></pre>"},{"location":"github-cicd-operations-guide/#merge-strategies","title":"Merge Strategies","text":"<p>Security updates: Merge immediately after tests pass</p> <p>Minor updates: - Group weekly - Test together - Merge as batch</p> <p>Major updates: - Test thoroughly - Check migration guides - Consider compatibility</p>"},{"location":"github-cicd-operations-guide/#managing-multiple-updates","title":"Managing Multiple Updates","text":"<pre><code># List all Dependabot PRs\ngh pr list --label dependencies\n\n# Bulk operations with GitHub CLI\ngh pr list --label dependencies --json number --jq '.[].number' | \\\n  xargs -I {} gh pr comment {} --body \"@dependabot rebase\"\n</code></pre>"},{"location":"github-cicd-operations-guide/#release-process","title":"Release Process","text":""},{"location":"github-cicd-operations-guide/#preparing-a-release","title":"Preparing a Release","text":"<ol> <li> <p>Update version in <code>pyproject.toml</code>: <pre><code>version = \"0.4.0\"\n</code></pre></p> </li> <li> <p>Update CHANGELOG.md:</p> </li> <li>Add release date</li> <li>Review all changes</li> <li> <p>Highlight breaking changes</p> </li> <li> <p>Create release PR: <pre><code>git checkout -b release/v0.4.0\ngit add pyproject.toml CHANGELOG.md\ngit commit -m \"chore: prepare release v0.4.0\"\ngit push -u origin release/v0.4.0\ngh pr create --title \"Release v0.4.0\" --label release\n</code></pre></p> </li> </ol>"},{"location":"github-cicd-operations-guide/#using-release-drafter","title":"Using Release Drafter","text":"<p>Release Drafter automatically maintains draft release notes.</p>"},{"location":"github-cicd-operations-guide/#how-it-works","title":"How It Works","text":"<ol> <li>Monitors merged PRs - Collects since last release</li> <li>Categorizes by labels - Groups changes by type</li> <li>Determines version - Based on change types</li> <li>Updates draft - After each PR merge</li> </ol>"},{"location":"github-cicd-operations-guide/#pr-labels-for-versioning","title":"PR Labels for Versioning","text":"<p>Major version (breaking changes): - <code>breaking-change</code> - <code>breaking</code></p> <p>Minor version (features): - <code>feature</code> - <code>enhancement</code> - <code>feat</code></p> <p>Patch version (fixes): - <code>fix</code> - <code>bug</code> - <code>perf</code> - <code>docs</code></p>"},{"location":"github-cicd-operations-guide/#editing-release-notes","title":"Editing Release Notes","text":"<ol> <li>Go to Releases \u2192 Draft release</li> <li>Review auto-generated notes</li> <li>Add highlights section</li> <li>Include migration guide for breaking changes</li> <li>Preview before publishing</li> </ol>"},{"location":"github-cicd-operations-guide/#publishing-a-release","title":"Publishing a Release","text":"<ol> <li>Final checks:</li> <li>All CI passes on main</li> <li>Version updated in code</li> <li> <p>Documentation updated</p> </li> <li> <p>Create and push tag: <pre><code>git checkout main\ngit pull origin main\ngit tag v0.4.0\ngit push origin v0.4.0\n</code></pre></p> </li> <li> <p>Publish GitHub release:</p> </li> <li>Go to draft release</li> <li>Select the tag</li> <li>Review notes one more time</li> <li> <p>Click \"Publish release\"</p> </li> <li> <p>Monitor deployment:</p> </li> <li>Check Actions tab for release workflow</li> <li>Verify PyPI upload</li> <li>Test installation: <code>pip install dqx==0.4.0</code></li> </ol>"},{"location":"github-cicd-operations-guide/#post-release-tasks","title":"Post-Release Tasks","text":"<ol> <li> <p>Verify deployment: <pre><code># Test from PyPI\npip install dqx==0.4.0\npython -c \"import dqx; print(dqx.__version__)\"\n</code></pre></p> </li> <li> <p>Update documentation:</p> </li> <li>Check ReadTheDocs built new version</li> <li>Update version references</li> <li> <p>Announce in relevant channels</p> </li> <li> <p>Create next development cycle: <pre><code># Bump to next dev version\n# Update pyproject.toml to 0.5.0-dev\ngit commit -m \"chore: bump version to 0.5.0-dev\"\n</code></pre></p> </li> </ol>"},{"location":"github-cicd-operations-guide/#monitoring-cicd","title":"Monitoring CI/CD","text":""},{"location":"github-cicd-operations-guide/#github-actions-dashboard","title":"GitHub Actions Dashboard","text":"<p>Access at: <code>https://github.com/&lt;owner&gt;/dqx/actions</code></p>"},{"location":"github-cicd-operations-guide/#key-metrics","title":"Key Metrics","text":"<ul> <li>Success rate by workflow</li> <li>Average run time</li> <li>Recent failures</li> <li>Usage minutes</li> </ul>"},{"location":"github-cicd-operations-guide/#workflow-management","title":"Workflow Management","text":"<p>Re-run failed jobs: 1. Click on failed workflow run 2. Click \"Re-run failed jobs\" 3. Or \"Re-run all jobs\" if needed</p> <p>Cancel stuck workflows: <pre><code>gh run list --status in_progress\ngh run cancel &lt;run-id&gt;\n</code></pre></p> <p>Download artifacts: <pre><code>gh run download &lt;run-id&gt; -n &lt;artifact-name&gt;\n</code></pre></p>"},{"location":"github-cicd-operations-guide/#debugging-ci-failures","title":"Debugging CI Failures","text":"<ol> <li>Check summary - Look for error annotations</li> <li>Expand failed step - Find exact error</li> <li>Download logs - For detailed analysis</li> <li>Run locally - Try to reproduce</li> </ol>"},{"location":"github-cicd-operations-guide/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Test failures on CI only: - Check for environment differences - Look for timing issues - Verify test data availability</p> <p>Timeout errors: - Increase timeout in workflow - Split long-running tests - Add progress output</p> <p>Permission errors: - Check token permissions - Verify secrets are set - Review repository settings</p>"},{"location":"github-cicd-operations-guide/#quick-reference","title":"Quick Reference","text":""},{"location":"github-cicd-operations-guide/#essential-commands","title":"Essential Commands","text":"<pre><code># Pre-commit hooks\nuv run pre-commit run --all-files  # Run all hooks\nuv run pre-commit run --help       # Show options\n\n# GitHub CLI\ngh pr create                 # Create PR\ngh pr list                   # List PRs\ngh pr checks                 # Show CI status\ngh workflow run              # Trigger workflow\n\n# Git\ngit tag v0.4.0              # Create version tag\ngit push origin v0.4.0      # Push tag\n\n# Python/uv\nuv sync                     # Install dependencies\nuv run pytest               # Run tests\nuv build                    # Build package\n</code></pre>"},{"location":"github-cicd-operations-guide/#status-badge-urls","title":"Status Badge URLs","text":"<pre><code>![Tests](https://github.com/&lt;owner&gt;/dqx/workflows/tests/badge.svg)\n![Coverage](https://github.com/&lt;owner&gt;/dqx/coverage.svg)\n![Docs](https://readthedocs.org/projects/dqx/badge/)\n![PyPI](https://badge.fury.io/py/dqx.svg)\n</code></pre>"},{"location":"github-cicd-operations-guide/#useful-links","title":"Useful Links","text":"<ul> <li>GitHub Actions Docs</li> <li>Conventional Commits</li> <li>CodeRabbit Docs</li> <li>Dependabot Docs</li> </ul> <p>For initial setup instructions, see the GitHub CI/CD Setup Guide.</p>"},{"location":"github-cicd-setup-guide/","title":"GitHub CI/CD Setup Guide","text":"<p>This guide walks through setting up GitHub Actions CI/CD for the DQX project.</p>"},{"location":"github-cicd-setup-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>GitHub account with repository access</li> <li>PyPI account for package publishing</li> <li>Basic understanding of GitHub Actions</li> </ul>"},{"location":"github-cicd-setup-guide/#step-1-create-pypi-account-and-api-token","title":"Step 1: Create PyPI Account and API Token","text":""},{"location":"github-cicd-setup-guide/#create-pypi-account","title":"Create PyPI Account","text":"<ol> <li>Visit pypi.org</li> <li>Click \"Register\"</li> <li>Fill the registration form:</li> <li>Username: Choose a unique identifier</li> <li>Email: Use your primary email</li> <li>Password: Create a strong password</li> <li>Verify your email address</li> </ol>"},{"location":"github-cicd-setup-guide/#generate-api-token","title":"Generate API Token","text":"<ol> <li>Log into PyPI</li> <li>Go to Account Settings \u2192 API tokens</li> <li>Click \"Add API token\"</li> <li>Configure the token:</li> <li>Token name: <code>github-actions-dqx</code></li> <li>Scope: \"Project: dqx\" (or \"Entire account\" for first release)</li> <li>Click \"Add token\"</li> <li>Copy the token immediately - it shows only once</li> <li>Format: <code>pypi-AgEIcHlwaS5vcmcCJGE4ZjY5...</code></li> <li>Save it securely</li> </ol>"},{"location":"github-cicd-setup-guide/#set-up-test-pypi-optional-but-recommended","title":"Set Up Test PyPI (Optional but Recommended)","text":"<ol> <li>Visit test.pypi.org</li> <li>Create a separate account (can use same email)</li> <li>Generate API token following same steps</li> <li>Use for testing releases before production</li> </ol>"},{"location":"github-cicd-setup-guide/#step-2-configure-github-repository-secrets","title":"Step 2: Configure GitHub Repository Secrets","text":""},{"location":"github-cicd-setup-guide/#add-pypi-token","title":"Add PyPI Token","text":"<ol> <li>Go to your GitHub repository</li> <li>Navigate to Settings \u2192 Secrets and variables \u2192 Actions</li> <li>Click \"New repository secret\"</li> <li>Add the secret:</li> <li>Name: <code>PYPI_API_TOKEN</code></li> <li>Value: Paste your PyPI token</li> <li>Click \"Add secret\"</li> </ol>"},{"location":"github-cicd-setup-guide/#add-test-pypi-token-optional","title":"Add Test PyPI Token (Optional)","text":"<p>Repeat the above with: - Name: <code>TEST_PYPI_API_TOKEN</code> - Value: Your Test PyPI token</p>"},{"location":"github-cicd-setup-guide/#verify-secrets","title":"Verify Secrets","text":"<p>Your secrets page should show: - <code>PYPI_API_TOKEN</code> (updated just now) - <code>TEST_PYPI_API_TOKEN</code> (updated just now)</p>"},{"location":"github-cicd-setup-guide/#step-3-set-up-readthedocs","title":"Step 3: Set Up ReadTheDocs","text":""},{"location":"github-cicd-setup-guide/#create-account","title":"Create Account","text":"<ol> <li>Visit readthedocs.org</li> <li>Sign up with GitHub OAuth (recommended) or create account</li> <li>Authorize ReadTheDocs to access your repositories</li> </ol>"},{"location":"github-cicd-setup-guide/#import-project","title":"Import Project","text":"<ol> <li>Click \"Import a Project\"</li> <li>Select your repository from the list</li> <li>Or click \"Import Manually\" and enter repo URL</li> <li>Configure project details:</li> <li>Name: <code>dqx</code></li> <li>Repository URL: <code>https://github.com/yourusername/dqx</code></li> <li>Repository type: Git</li> <li>Default branch: <code>main</code></li> <li>Click \"Next\"</li> </ol>"},{"location":"github-cicd-setup-guide/#configure-build","title":"Configure Build","text":"<ol> <li>In project dashboard, go to Admin \u2192 Advanced Settings</li> <li>Set Python configuration:</li> <li>Python interpreter: CPython 3.11</li> <li>Install method: pip</li> <li>Requirements file: Leave empty (using pyproject.toml)</li> <li>Enable these options:</li> <li>Build pull requests</li> <li>Public versions</li> <li>Single version docs (if you want /latest/ only)</li> <li>Save changes</li> </ol>"},{"location":"github-cicd-setup-guide/#first-build","title":"First Build","text":"<ol> <li>Go to Builds tab</li> <li>Click \"Build Version\"</li> <li>Monitor the build log</li> <li>Once successful, view docs at <code>https://dqx.readthedocs.io</code></li> </ol>"},{"location":"github-cicd-setup-guide/#webhook-setup-automatic","title":"Webhook Setup (Automatic)","text":"<p>ReadTheDocs automatically creates a webhook in your GitHub repo. Verify: 1. GitHub repo \u2192 Settings \u2192 Webhooks 2. Look for ReadTheDocs webhook 3. Should trigger on push events</p>"},{"location":"github-cicd-setup-guide/#step-4-install-github-apps","title":"Step 4: Install GitHub Apps","text":""},{"location":"github-cicd-setup-guide/#coderabbit","title":"CodeRabbit","text":"<ol> <li>Visit GitHub Marketplace - CodeRabbit</li> <li>Click \"Set up a plan\"</li> <li>Choose pricing plan (free tier available)</li> <li>Select repositories:</li> <li>Choose \"Only select repositories\"</li> <li>Select your DQX repository</li> <li>Complete installation</li> </ol> <p>CodeRabbit will automatically review PRs once installed.</p>"},{"location":"github-cicd-setup-guide/#dependabot-already-enabled","title":"Dependabot (Already Enabled)","text":"<p>Dependabot is automatically available. Ensure it's active: 1. Go to Settings \u2192 Security &amp; analysis 2. Enable:    - Dependency graph    - Dependabot alerts    - Dependabot security updates</p>"},{"location":"github-cicd-setup-guide/#release-drafter","title":"Release Drafter","text":"<p>The Release Drafter workflow is already configured. It will: - Auto-generate release notes from PRs - Categorize changes by labels - Create draft releases automatically</p>"},{"location":"github-cicd-setup-guide/#step-5-configure-github-actions-permissions","title":"Step 5: Configure GitHub Actions Permissions","text":""},{"location":"github-cicd-setup-guide/#repository-permissions","title":"Repository Permissions","text":"<ol> <li>Go to Settings \u2192 Actions \u2192 General</li> <li>Under \"Actions permissions\":</li> <li>Select \"Allow all actions and reusable workflows\"</li> <li>Under \"Workflow permissions\":</li> <li>Select \"Read and write permissions\"</li> <li>Check \"Allow GitHub Actions to create and approve pull requests\"</li> <li>Click \"Save\"</li> </ol>"},{"location":"github-cicd-setup-guide/#branch-protection","title":"Branch Protection","text":"<ol> <li>Go to Settings \u2192 Branches</li> <li>Click \"Add rule\"</li> <li>Configure protection for <code>main</code>:</li> <li>Branch name pattern: <code>main</code></li> <li>Enable:<ul> <li>Require pull request before merging</li> <li>Require status checks:</li> <li><code>test (3.11)</code></li> <li><code>analyze</code></li> <li><code>docs</code></li> <li>Require branches to be up to date</li> <li>Include administrators (optional)</li> </ul> </li> <li>Click \"Create\"</li> </ol>"},{"location":"github-cicd-setup-guide/#step-6-test-the-setup","title":"Step 6: Test the Setup","text":""},{"location":"github-cicd-setup-guide/#verify-workflows","title":"Verify Workflows","text":"<ol> <li> <p>Create a test branch:    <pre><code>git checkout -b test/ci-setup\n</code></pre></p> </li> <li> <p>Make a small change:    <pre><code>echo \"# Test\" &gt;&gt; test.md\ngit add test.md\ngit commit -m \"test: verify CI setup\"\ngit push origin test/ci-setup\n</code></pre></p> </li> <li> <p>Create a pull request</p> </li> <li>Watch the checks run:</li> <li>Tests should pass</li> <li>CodeRabbit should comment</li> <li>All status checks should be green</li> </ol>"},{"location":"github-cicd-setup-guide/#test-documentation-build","title":"Test Documentation Build","text":"<ol> <li> <p>Make a docs change:    <pre><code>echo \"Test content\" &gt;&gt; docs/test.md\ngit add docs/test.md\ngit commit -m \"docs: test documentation build\"\ngit push\n</code></pre></p> </li> <li> <p>Check ReadTheDocs:</p> </li> <li>Go to your project builds</li> <li>Verify build triggered and passed</li> </ol>"},{"location":"github-cicd-setup-guide/#test-release-process-dry-run","title":"Test Release Process (Dry Run)","text":"<ol> <li>Update version in <code>pyproject.toml</code></li> <li> <p>Create and push a tag:    <pre><code>git tag v0.3.1-rc1\ngit push origin v0.3.1-rc1\n</code></pre></p> </li> <li> <p>Check Actions tab for release workflow</p> </li> <li>Verify it would publish correctly (without creating release)</li> </ol>"},{"location":"github-cicd-setup-guide/#step-7-local-documentation-development","title":"Step 7: Local Documentation Development","text":""},{"location":"github-cicd-setup-guide/#install-mkdocs","title":"Install MkDocs","text":"<pre><code># In your project directory\nuv pip install mkdocs mkdocs-material mkdocstrings[python]\n</code></pre>"},{"location":"github-cicd-setup-guide/#run-documentation-server","title":"Run Documentation Server","text":"<pre><code># Start local server\nmkdocs serve\n\n# Output:\n# INFO - Building documentation...\n# INFO - Cleaning site directory\n# INFO - Documentation built in 2.34 seconds\n# INFO - Serving on http://127.0.0.1:8000\n</code></pre>"},{"location":"github-cicd-setup-guide/#live-development","title":"Live Development","text":"<ol> <li>Open browser to <code>http://localhost:8000</code></li> <li>Edit any markdown file in <code>docs/</code></li> <li>Save the file</li> <li>Browser auto-refreshes with changes</li> </ol>"},{"location":"github-cicd-setup-guide/#build-documentation","title":"Build Documentation","text":"<pre><code># Build static site\nmkdocs build\n\n# Output creates site/ directory\n# Upload site/ contents to any web server\n</code></pre>"},{"location":"github-cicd-setup-guide/#test-strict-mode","title":"Test Strict Mode","text":"<pre><code># Catch broken links and references\nmkdocs build --strict\n\n# Fails on warnings - same as CI\n</code></pre>"},{"location":"github-cicd-setup-guide/#preview-different-themes","title":"Preview Different Themes","text":"<p>Edit <code>mkdocs.yml</code>: <pre><code>theme:\n  name: material\n  palette:\n    scheme: slate  # Try 'default' for light\n</code></pre></p> <p>Save and see instant changes.</p>"},{"location":"github-cicd-setup-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"github-cicd-setup-guide/#pypi-upload-fails","title":"PyPI Upload Fails","text":"<p>Token scope too narrow: - First release needs \"Entire account\" scope - After first release, can limit to project</p> <p>Version already exists: - PyPI never allows reusing versions - Increment version in <code>pyproject.toml</code></p> <p>Authentication failed: - Verify secret name is exactly <code>PYPI_API_TOKEN</code> - Check token starts with <code>pypi-</code> - Regenerate token if needed</p>"},{"location":"github-cicd-setup-guide/#readthedocs-build-fails","title":"ReadTheDocs Build Fails","text":"<p>Import error: - Check <code>.readthedocs.yml</code> syntax - Verify Python version matches project</p> <p>MkDocs not found: - Ensure MkDocs installed in build commands - Check pip install succeeds in logs</p> <p>Theme missing: - Add <code>mkdocs-material</code> to dependencies - Clear build cache and retry</p>"},{"location":"github-cicd-setup-guide/#github-actions-timeout","title":"GitHub Actions Timeout","text":"<p>Long test runs: - Add <code>timeout-minutes: 30</code> to job - Split tests into parallel jobs - Cache dependencies</p> <p>Hanging process: - Check for infinite loops - Add proper test timeouts - Kill subprocess in tests</p>"},{"location":"github-cicd-setup-guide/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Rotate tokens annually</li> <li>Set calendar reminder</li> <li> <p>Update both PyPI and GitHub</p> </li> <li> <p>Use environment protection</p> </li> <li>Limit production deployments</li> <li> <p>Require reviews for releases</p> </li> <li> <p>Enable 2FA everywhere</p> </li> <li>GitHub (required for Actions)</li> <li>PyPI (highly recommended)</li> <li> <p>ReadTheDocs</p> </li> <li> <p>Monitor security alerts</p> </li> <li>Check GitHub Security tab weekly</li> <li>Act on Dependabot alerts quickly</li> <li>Review CodeQL findings</li> </ol>"},{"location":"github-cicd-setup-guide/#next-steps","title":"Next Steps","text":"<p>With CI/CD configured:</p> <ol> <li>Make your first release</li> <li>Update version and changelog</li> <li>Create GitHub release</li> <li> <p>Monitor PyPI publication</p> </li> <li> <p>Customize workflows</p> </li> <li>Add deployment environments</li> <li>Include performance tests</li> <li> <p>Add container builds</p> </li> <li> <p>Enhance documentation</p> </li> <li>Add API references</li> <li>Include tutorials</li> <li> <p>Create video guides</p> </li> <li> <p>Monitor metrics</p> </li> <li>Track build times</li> <li>Review test coverage</li> <li>Analyze deployment frequency</li> </ol> <p>For issues, check workflow logs first, then consult this guide's troubleshooting section.</p>"},{"location":"github-cicd-setup-guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>GitHub CI/CD Operations Guide - Daily operations and interactions</li> <li>CI/CD Overview - Technical reference and file descriptions</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>DQX can be installed using pip from PyPI or directly from source.</p>"},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>pip package manager</li> </ul>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>The simplest way to install DQX:</p> <pre><code>pip install dqx\n</code></pre> <p>For specific version:</p> <pre><code>pip install dqx==0.3.0\n</code></pre>"},{"location":"installation/#install-from-source","title":"Install from Source","text":"<p>To install the latest development version:</p> <pre><code>git clone https://github.com/yourusername/dqx.git\ncd dqx\npip install -e .\n</code></pre>"},{"location":"installation/#install-with-extras","title":"Install with Extras","text":"<p>DQX provides optional dependencies for specific features:</p>"},{"location":"installation/#development-dependencies","title":"Development Dependencies","text":"<p>For contributing to DQX:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This includes: - pytest for testing - ruff for linting - mypy for type checking - pre-commit hooks</p>"},{"location":"installation/#documentation-dependencies","title":"Documentation Dependencies","text":"<p>For building documentation:</p> <pre><code>pip install -e \".[docs]\"\n</code></pre>"},{"location":"installation/#all-dependencies","title":"All Dependencies","text":"<p>To install all optional dependencies:</p> <pre><code>pip install -e \".[dev,docs]\"\n</code></pre>"},{"location":"installation/#using-uv-recommended-for-development","title":"Using UV (Recommended for Development)","text":"<p>DQX uses uv for dependency management:</p> <pre><code># Install uv\npip install uv\n\n# Clone and setup\ngit clone https://github.com/yourusername/dqx.git\ncd dqx\n\n# Install all dependencies\nuv sync\n\n# Run tests\nuv run pytest\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify DQX is working:</p> <pre><code>import dqx\n\nprint(dqx.__version__)\n</code></pre> <p>Or from command line:</p> <pre><code>python -c \"import dqx; print(dqx.__version__)\"\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#python-version","title":"Python Version","text":"<p>DQX requires Python 3.11+. Check your version:</p> <pre><code>python --version\n</code></pre>"},{"location":"installation/#virtual-environment","title":"Virtual Environment","text":"<p>We recommend using a virtual environment:</p> <pre><code># Create virtual environment\npython -m venv venv\n\n# Activate it\nsource venv/bin/activate  # On Unix/macOS\nvenv\\Scripts\\activate     # On Windows\n\n# Install DQX\npip install dqx\n</code></pre>"},{"location":"installation/#permission-issues","title":"Permission Issues","text":"<p>If you encounter permission errors:</p> <pre><code>pip install --user dqx\n</code></pre>"},{"location":"installation/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>If you have dependency conflicts, try installing in a clean environment:</p> <pre><code>python -m venv clean_env\nsource clean_env/bin/activate\npip install dqx\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<ul> <li>Follow the Quick Start Guide to create your first data quality checks</li> <li>Read the User Guide for detailed usage instructions</li> <li>Check out examples for real-world usage</li> </ul>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":"<p>To remove DQX:</p> <pre><code>pip uninstall dqx\n</code></pre> <p>For issues with installation, please open an issue on GitHub.</p>"},{"location":"plugin_system/","title":"DQX Plugin System Documentation","text":"<p>The DQX Plugin System allows extending validation result processing with custom plugins. Plugins can generate reports, send notifications, store metrics, or perform any custom processing after validation completes.</p>"},{"location":"plugin_system/#overview","title":"Overview","text":"<p>The plugin system provides: - Extensibility: Add custom result processors without modifying core DQX code - Isolation: Plugin failures don't affect validation execution - Performance: Built-in timeouts prevent slow plugins from blocking - Rich Context: Access to all validation results, symbols, and metadata</p>"},{"location":"plugin_system/#architecture","title":"Architecture","text":"<pre><code>VerificationSuite\n    \u2502\n    \u251c\u2500\u2500 Executes validations\n    \u2502\n    \u2514\u2500\u2500 PluginManager.process_all()\n            \u2502\n            \u251c\u2500\u2500 AuditPlugin (built-in)\n            \u251c\u2500\u2500 CustomPlugin1\n            \u2514\u2500\u2500 CustomPlugin2\n</code></pre>"},{"location":"plugin_system/#creating-a-plugin","title":"Creating a Plugin","text":"<p>Plugins must implement the <code>PostProcessor</code> protocol:</p> <pre><code>from dqx.common import PluginExecutionContext, PluginMetadata\nfrom dqx.plugins import PostProcessor\n\n\nclass MyPlugin:\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"my_plugin\",\n            version=\"1.0.0\",\n            author=\"Your Name\",\n            description=\"Description of what your plugin does\",\n            capabilities={\"reporting\", \"notifications\"},  # Optional\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        \"\"\"Process validation results.\"\"\"\n        # Your plugin logic here\n        pass\n</code></pre>"},{"location":"plugin_system/#plugin-context","title":"Plugin Context","text":"<p>The <code>PluginExecutionContext</code> provides comprehensive information:</p> <pre><code>@dataclass\nclass PluginExecutionContext:\n    suite_name: str  # Name of the verification suite\n    datasources: list[str]  # Data sources used\n    key: ResultKey  # Date and tags\n    timestamp: float  # Unix timestamp\n    duration_ms: float  # Execution time in milliseconds\n    results: list[AssertionResult]  # All assertion results\n    symbols: list[SymbolInfo]  # All computed symbols\n</code></pre> <p>Available convenience methods: - <code>total_assertions() -&gt; int</code> - Total number of assertions - <code>failed_assertions() -&gt; int</code> - Number of failed assertions - <code>passed_assertions() -&gt; int</code> - Number of passed assertions - <code>assertion_pass_rate() -&gt; float</code> - Percentage of passed assertions - <code>total_symbols() -&gt; int</code> - Total number of symbols - <code>failed_symbols() -&gt; int</code> - Number of failed symbols - <code>assertions_by_severity() -&gt; dict[str, int]</code> - Count by severity - <code>failures_by_severity() -&gt; dict[str, int]</code> - Failures by severity</p>"},{"location":"plugin_system/#built-in-plugins","title":"Built-in Plugins","text":""},{"location":"plugin_system/#auditplugin","title":"AuditPlugin","text":"<p>The built-in audit plugin displays a Rich-formatted summary of validation results:</p> <pre><code>from dqx.api import VerificationSuite\n\n# Create suite - plugins are managed internally\nsuite = VerificationSuite(checks, db, \"MyDataQuality\")\n\n# Plugins are enabled by default when run() is called\nsuite.run(datasources, key)  # Plugins enabled\n\n# Or explicitly disable plugins during run\nsuite.run(datasources, key, enable_plugins=False)\n</code></pre> <p>Output example: <pre><code>\u2550\u2550\u2550 DQX Audit Report \u2550\u2550\u2550\nSuite: MyDataQuality\nDate: 2025-10-18\nDuration: 342.50ms\nDatasets: products, inventory\n\n     Execution Summary\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Metric           \u2502 Count \u2502  Rate \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Total Assertions \u2502     4 \u2502       \u2502\n\u2502 Passed \u2713         \u2502     3 \u2502 75.0% \u2502\n\u2502 Failed \u2717         \u2502     1 \u2502 25.0% \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre></p>"},{"location":"plugin_system/#example-plugins","title":"Example Plugins","text":""},{"location":"plugin_system/#json-reporter","title":"JSON Reporter","text":"<pre><code>class JSONReporterPlugin:\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"json_reporter\",\n            version=\"1.0.0\",\n            author=\"Your Team\",\n            description=\"Outputs results as JSON\",\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        import json\n\n        report = {\n            \"suite\": context.suite_name,\n            \"date\": context.key.yyyy_mm_dd.isoformat(),\n            \"duration_ms\": context.duration_ms,\n            \"summary\": {\n                \"total\": context.total_assertions(),\n                \"passed\": context.passed_assertions(),\n                \"failed\": context.failed_assertions(),\n                \"pass_rate\": context.assertion_pass_rate(),\n            },\n            \"failures_by_severity\": context.failures_by_severity(),\n        }\n\n        with open(\"validation_report.json\", \"w\") as f:\n            json.dump(report, f, indent=2)\n</code></pre>"},{"location":"plugin_system/#slack-notifier","title":"Slack Notifier","text":"<pre><code>class SlackNotifierPlugin:\n    def __init__(self, webhook_url: str):\n        self.webhook_url = webhook_url\n\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"slack_notifier\",\n            version=\"1.0.0\",\n            author=\"DevOps Team\",\n            description=\"Sends validation alerts to Slack\",\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        if context.failed_assertions() &gt; 0:\n            import requests\n\n            failures = context.failures_by_severity()\n            message = {\n                \"text\": f\"\u26a0\ufe0f Data Quality Alert: {context.suite_name}\",\n                \"blocks\": [\n                    {\n                        \"type\": \"section\",\n                        \"text\": {\n                            \"type\": \"mrkdwn\",\n                            \"text\": f\"*Suite:* {context.suite_name}\\n\"\n                            f\"*Pass Rate:* {context.assertion_pass_rate():.1f}%\\n\"\n                            f\"*Failures:* {failures}\",\n                        },\n                    }\n                ],\n            }\n\n            requests.post(self.webhook_url, json=message)\n</code></pre>"},{"location":"plugin_system/#metrics-collector","title":"Metrics Collector","text":"<pre><code>class MetricsCollectorPlugin:\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"metrics_collector\",\n            version=\"1.0.0\",\n            author=\"Analytics Team\",\n            description=\"Collects validation metrics\",\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        # Send metrics to monitoring system\n        import statsd\n\n        client = statsd.StatsClient(\"localhost\", 8125)\n\n        # Send gauges\n        client.gauge(\n            f\"dqx.{context.suite_name}.assertions.total\", context.total_assertions()\n        )\n        client.gauge(\n            f\"dqx.{context.suite_name}.assertions.failed\", context.failed_assertions()\n        )\n        client.gauge(\n            f\"dqx.{context.suite_name}.pass_rate\", context.assertion_pass_rate()\n        )\n\n        # Send timing\n        client.timing(f\"dqx.{context.suite_name}.duration\", context.duration_ms)\n</code></pre>"},{"location":"plugin_system/#plugin-registration","title":"Plugin Registration","text":""},{"location":"plugin_system/#method-1-entry-points-recommended","title":"Method 1: Entry Points (Recommended)","text":"<p>Register plugins in your package's <code>pyproject.toml</code>:</p> <pre><code>[project.entry-points.\"dqx.plugins\"]\njson_reporter = \"mypackage.plugins:JSONReporterPlugin\"\nslack_notifier = \"mypackage.plugins:SlackNotifierPlugin\"\n</code></pre> <p>This approach supports automatic plugin discovery when your package is installed.</p>"},{"location":"plugin_system/#method-2-manual-registration","title":"Method 2: Manual Registration","text":"<p>For testing or dynamic plugin loading:</p> <pre><code>from dqx.api import VerificationSuite\n\n# Create suite\nsuite = VerificationSuite(checks, db, \"MyData\")\n\n# Register custom plugins using fully qualified class names\nsuite.plugin_manager.register_plugin(\"mypackage.plugins.MyCustomPlugin\")\n\n# Clear default plugins if needed\nsuite.plugin_manager.clear_plugins()\n\n# Register only your plugins\nsuite.plugin_manager.register_plugin(\"mypackage.plugins.JSONReporterPlugin\")\n\n# Note: For plugins with constructor arguments, you'll need to use entry points\n# or create a wrapper class that handles initialization\n</code></pre>"},{"location":"plugin_system/#error-handling","title":"Error Handling","text":"<p>Plugins are executed with comprehensive error handling:</p> <ol> <li>Plugin Exceptions: Caught and logged, suite continues</li> <li>Timeouts: Plugins exceeding 60 seconds are terminated</li> <li>Invalid Plugins: Rejected during discovery</li> </ol> <p>Example error handling:</p> <pre><code>class RobustPlugin:\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        try:\n            # Risky operation\n            external_api_call()\n        except Exception as e:\n            # Plugin should handle its own errors gracefully\n            logger.error(f\"Plugin error: {e}\")\n            # Can still do partial processing\n            self.write_local_backup(context)\n</code></pre>"},{"location":"plugin_system/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Timeouts: Default 60-second timeout per plugin</li> <li>Async Operations: Plugins run synchronously; use threads/async internally if needed</li> <li>Resource Usage: Plugins should clean up resources in case of timeout</li> </ol> <pre><code>class EfficientPlugin:\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        # Use context methods for efficiency\n        if context.assertion_pass_rate() &gt; 99.0:\n            # Skip expensive processing for perfect runs\n            return\n\n        # Process only failures\n        for result in context.results:\n            if result.status == \"FAILURE\":\n                self.process_failure(result)\n</code></pre>"},{"location":"plugin_system/#testing-plugins","title":"Testing Plugins","text":"<pre><code>import pytest\nfrom datetime import datetime\nfrom dqx.common import PluginExecutionContext, ResultKey, AssertionResult\nfrom returns.result import Success\n\n\ndef test_my_plugin():\n    # Create test context\n    context = PluginExecutionContext(\n        suite_name=\"TestSuite\",\n        datasources=[\"test_db\"],\n        key=ResultKey(datetime.now().date(), {}),\n        timestamp=time.time(),\n        duration_ms=100.0,\n        results=[\n            AssertionResult(\n                yyyy_mm_dd=datetime.now().date(),\n                suite=\"TestSuite\",\n                check=\"test_check\",\n                assertion=\"test_assertion\",\n                severity=\"P1\",\n                status=\"OK\",\n                metric=Success(1.0),\n            )\n        ],\n        symbols=[],\n    )\n\n    # Test plugin\n    plugin = MyPlugin()\n    plugin.process(context)\n\n    # Assert expected behavior\n    assert os.path.exists(\"expected_output.json\")\n</code></pre>"},{"location":"plugin_system/#best-practices","title":"Best Practices","text":"<ol> <li>Be Resilient: Handle errors gracefully</li> <li>Be Fast: Complete processing quickly</li> <li>Be Focused: Do one thing well</li> <li>Be Testable: Write unit tests for your plugins</li> <li>Be Documented: Include clear metadata and docstrings</li> </ol>"},{"location":"plugin_system/#future-enhancements","title":"Future Enhancements","text":"<p>The plugin system is designed for extension. Potential future features: - Async plugin execution - Plugin dependencies - Plugin configuration system - Built-in plugin marketplace - Plugin health monitoring</p>"},{"location":"plugin_system/#see-also","title":"See Also","text":"<ul> <li>Plugin Demo - Complete working example</li> <li>API Reference - Full API documentation</li> <li>Architecture - System design details</li> </ul>"},{"location":"quick_reference/","title":"DQX Quick Reference","text":""},{"location":"quick_reference/#most-common-commands","title":"Most Common Commands","text":"<pre><code># Testing\nuv run pytest                                     # Run all tests\nuv run pytest --cov=src/dqx --cov-report=term    # With coverage\nuv run pytest -k \"pattern\"                        # Specific tests\n\n# Quality\nuv run ruff format                                # Format code\nuv run ruff check --fix                           # Lint &amp; fix\nuv run mypy src tests                             # Type check\nuv run pre-commit run --all-files                 # All hooks\n\n# Development\nuv sync                                           # Install deps\nuv run mkdocs serve                               # Serve docs\n</code></pre>"},{"location":"quick_reference/#code-standards-quick-reference","title":"Code Standards Quick Reference","text":"Standard Rule Import order stdlib \u2192 third-party \u2192 local Type hints Strict mode, all functions Docstrings Google style, required Line length 120 characters max Coverage 100% required"},{"location":"quick_reference/#quality-gates-checklist","title":"Quality Gates Checklist","text":"<p>Before completion: - [ ] All tests passing: <code>uv run pytest</code> - [ ] Coverage: 100%: <code>uv run pytest --cov=src/dqx --cov-report=term</code> - [ ] Pre-commit passing: <code>uv run pre-commit run --all-files</code> - [ ] No type errors: <code>uv run mypy src tests</code></p>"},{"location":"quick_reference/#feature-workflow","title":"Feature Workflow","text":"<ol> <li>Planning: Request feature \u2192 <code>dqx-plan</code> creates design docs</li> <li>Implementation: Approve \u2192 <code>dqx-implement</code> executes TDD phases</li> <li>PR Creation: Approve \u2192 <code>dqx-pr</code> creates pull request</li> <li>Feedback: Request \u2192 <code>dqx-feedback</code> addresses review comments</li> </ol>"},{"location":"quick_reference/#complete-documentation","title":"Complete Documentation","text":"<p>For comprehensive documentation, see workflow_example.md for an end-to-end example.</p>"},{"location":"quickstart/","title":"Quick Start","text":"<p>Get started with DQX in 5 minutes! This guide shows you how to create your first data quality checks.</p>"},{"location":"quickstart/#basic-example","title":"Basic Example","text":"<p>Here's a simple example checking data quality on a pandas DataFrame:</p> <pre><code>import pandas as pd\nfrom dqx import DataQualityValidator\n\n# Sample data\ndf = pd.DataFrame(\n    {\n        \"user_id\": [1, 2, 3, 4, 5],\n        \"age\": [25, 30, -5, 150, 35],\n        \"email\": [\n            \"john@example.com\",\n            \"invalid-email\",\n            \"jane@test.com\",\n            None,\n            \"bob@demo.com\",\n        ],\n        \"score\": [85.5, 92.0, 78.5, None, 88.0],\n    }\n)\n\n# Create validator\nvalidator = DataQualityValidator()\n\n# Define checks\nchecks = (\n    validator.create_checks(df)\n    .is_not_null(\"user_id\")\n    .is_between(\"age\", 0, 120)\n    .matches_pattern(\"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n    .is_not_null(\"score\")\n)\n\n# Run validation\nresults = validator.validate(df, checks)\n\n# Display results\nprint(results.summary())\n</code></pre>"},{"location":"quickstart/#understanding-results","title":"Understanding Results","text":"<p>DQX provides detailed validation results:</p> <pre><code># Check if validation passed\nif results.passed:\n    print(\"\u2705 All checks passed!\")\nelse:\n    print(f\"\u274c {results.failed_count} checks failed\")\n\n# Get detailed results\nfor check_result in results.details:\n    print(f\"{check_result.check_name}: {check_result.status}\")\n    if not check_result.passed:\n        print(f\"  Failed rows: {check_result.failed_rows}\")\n</code></pre>"},{"location":"quickstart/#common-data-quality-checks","title":"Common Data Quality Checks","text":""},{"location":"quickstart/#1-null-value-checks","title":"1. Null Value Checks","text":"<pre><code># Check for nulls\nvalidator.create_checks(df).is_not_null(\n    \"column_name\"\n).has_no_nulls()  # Check all columns\n</code></pre>"},{"location":"quickstart/#2-range-validation","title":"2. Range Validation","text":"<pre><code># Numeric ranges\nvalidator.create_checks(df).is_between(\"age\", 0, 120).is_positive(\n    \"amount\"\n).is_greater_than(\"score\", 0)\n</code></pre>"},{"location":"quickstart/#3-pattern-matching","title":"3. Pattern Matching","text":"<pre><code># String patterns\nvalidator.create_checks(df).matches_pattern(\n    \"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\"\n).matches_pattern(\"phone\", r\"^\\d{3}-\\d{3}-\\d{4}$\").has_length(\"zip_code\", 5)\n</code></pre>"},{"location":"quickstart/#4-uniqueness-checks","title":"4. Uniqueness Checks","text":"<pre><code># Unique values\nvalidator.create_checks(df).is_unique(\"user_id\").has_no_duplicates(\n    [\"first_name\", \"last_name\"]\n)\n</code></pre>"},{"location":"quickstart/#5-statistical-checks","title":"5. Statistical Checks","text":"<pre><code># Statistical validation\nvalidator.create_checks(df).mean_between(\"score\", 70, 90).std_dev_less_than(\n    \"price\", 100\n).percentile_between(\"income\", 0.25, 10000, 50000)\n</code></pre>"},{"location":"quickstart/#working-with-different-data-sources","title":"Working with Different Data Sources","text":""},{"location":"quickstart/#sql-databases","title":"SQL Databases","text":"<pre><code>from dqx import SQLDataSource\n\n# Connect to database\ndatasource = SQLDataSource(connection_string=\"postgresql://...\")\n\n# Validate query results\nquery = \"SELECT * FROM users WHERE created_at &gt; '2024-01-01'\"\nresults = validator.validate_query(datasource, query, checks)\n</code></pre>"},{"location":"quickstart/#csv-files","title":"CSV Files","text":"<pre><code># Validate CSV directly\nresults = validator.validate_file(\"data.csv\", checks)\n\n# Or load and validate\ndf = pd.read_csv(\"data.csv\")\nresults = validator.validate(df, checks)\n</code></pre>"},{"location":"quickstart/#parquet-files","title":"Parquet Files","text":"<pre><code># Validate Parquet files\nresults = validator.validate_file(\"data.parquet\", checks)\n</code></pre>"},{"location":"quickstart/#custom-validation-rules","title":"Custom Validation Rules","text":"<p>Create custom validation logic:</p> <pre><code>from dqx import custom_check\n\n\n@custom_check\ndef business_rule_check(df):\n    \"\"\"Custom business rule validation\"\"\"\n    mask = (df[\"status\"] == \"active\") &amp; (df[\"balance\"] &gt; 0)\n    return mask\n\n\n# Use custom check\nvalidator.create_checks(df).add_custom_check(\n    business_rule_check, \"active_positive_balance\"\n)\n</code></pre>"},{"location":"quickstart/#validation-reporting","title":"Validation Reporting","text":""},{"location":"quickstart/#summary-report","title":"Summary Report","text":"<pre><code># Get summary statistics\nsummary = results.summary()\nprint(f\"Total checks: {summary['total']}\")\nprint(f\"Passed: {summary['passed']}\")\nprint(f\"Failed: {summary['failed']}\")\nprint(f\"Pass rate: {summary['pass_rate']:.1%}\")\n</code></pre>"},{"location":"quickstart/#detailed-report","title":"Detailed Report","text":"<pre><code># Generate detailed HTML report\nresults.to_html(\"validation_report.html\")\n\n# Or get DataFrame of results\nresults_df = results.to_dataframe()\n</code></pre>"},{"location":"quickstart/#export-results","title":"Export Results","text":"<pre><code># Export to various formats\nresults.to_json(\"results.json\")\nresults.to_csv(\"results.csv\")\n</code></pre>"},{"location":"quickstart/#error-handling","title":"Error Handling","text":"<p>DQX provides clear error messages:</p> <pre><code>try:\n    results = validator.validate(df, checks)\nexcept ValidationError as e:\n    print(f\"Validation error: {e}\")\nexcept DataSourceError as e:\n    print(f\"Data source error: {e}\")\n</code></pre>"},{"location":"quickstart/#best-practices","title":"Best Practices","text":"<ol> <li>Start Simple: Begin with basic null and range checks</li> <li>Incremental Validation: Add checks gradually</li> <li>Use Descriptive Names: Name your checks clearly</li> <li>Set Appropriate Thresholds: Be realistic with ranges</li> <li>Monitor Trends: Track validation results over time</li> </ol>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the User Guide for advanced features</li> <li>Learn about Plugin System for extending DQX</li> <li>Check API Reference for detailed documentation</li> <li>See Examples for real-world use cases</li> </ul>"},{"location":"quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Full Documentation</li> <li>\ud83d\udcac GitHub Discussions</li> <li>\ud83d\udc1b Report Issues</li> <li>\ud83d\udce7 Contact Support</li> </ul> <p>Ready to dive deeper? Check out the User Guide for comprehensive documentation.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the DQX User Guide! This comprehensive guide covers all aspects of using DQX for data quality validation.</p>"},{"location":"user-guide/#overview","title":"Overview","text":"<p>DQX (Data Quality Excellence) transforms data validation into mathematical expressions, making it easy to find data quality issues before they impact your business.</p>"},{"location":"user-guide/#core-concepts","title":"Core Concepts","text":""},{"location":"user-guide/#1-validators","title":"1. Validators","text":"<p>Validators are the heart of DQX. They orchestrate the validation process:</p> <pre><code>from dqx import DataQualityValidator\n\nvalidator = DataQualityValidator()\n</code></pre>"},{"location":"user-guide/#2-checks","title":"2. Checks","text":"<p>Checks define what to validate. DQX provides many built-in checks:</p> <ul> <li>Completeness: Null checks, missing value detection</li> <li>Consistency: Pattern matching, format validation</li> <li>Accuracy: Range checks, statistical validation</li> <li>Uniqueness: Duplicate detection, key validation</li> </ul>"},{"location":"user-guide/#3-data-sources","title":"3. Data Sources","text":"<p>DQX supports multiple data sources:</p> <ul> <li>Pandas DataFrames</li> <li>SQL databases (PostgreSQL, MySQL, SQLite)</li> <li>CSV, Parquet, JSON files</li> <li>Cloud storage (S3, GCS, Azure)</li> </ul>"},{"location":"user-guide/#4-results","title":"4. Results","text":"<p>Validation results provide detailed insights:</p> <ul> <li>Pass/fail status</li> <li>Row-level details</li> <li>Statistical summaries</li> <li>Trend analysis</li> </ul>"},{"location":"user-guide/#validation-workflow","title":"Validation Workflow","text":"<pre><code>graph LR\n    A[Data Source] --&gt; B[Define Checks]\n    B --&gt; C[Run Validation]\n    C --&gt; D[Analyze Results]\n    D --&gt; E[Take Action]</code></pre>"},{"location":"user-guide/#detailed-features","title":"Detailed Features","text":""},{"location":"user-guide/#completeness-validation","title":"Completeness Validation","text":"<p>Check for missing or null values:</p> <pre><code># Single column\nchecks.is_not_null(\"customer_id\")\n\n# Multiple columns\nchecks.are_not_null([\"name\", \"email\", \"phone\"])\n\n# Completeness threshold\nchecks.has_completeness(\"optional_field\", threshold=0.95)\n</code></pre>"},{"location":"user-guide/#consistency-validation","title":"Consistency Validation","text":"<p>Ensure data follows expected patterns:</p> <pre><code># Email format\nchecks.matches_pattern(\"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n\n# Date format\nchecks.matches_date_format(\"birth_date\", \"%Y-%m-%d\")\n\n# Custom formats\nchecks.matches_format(\"product_code\", \"XXX-####\")\n</code></pre>"},{"location":"user-guide/#accuracy-validation","title":"Accuracy Validation","text":"<p>Validate data accuracy and ranges:</p> <pre><code># Numeric ranges\nchecks.is_between(\"age\", 0, 120)\nchecks.is_positive(\"amount\")\nchecks.is_not_negative(\"balance\")\n\n# Date ranges\nchecks.date_between(\"order_date\", \"2020-01-01\", \"2024-12-31\")\n\n# Statistical checks\nchecks.mean_between(\"score\", 70, 90)\nchecks.std_dev_less_than(\"variance\", 10)\n</code></pre>"},{"location":"user-guide/#uniqueness-validation","title":"Uniqueness Validation","text":"<p>Detect duplicates and ensure uniqueness:</p> <pre><code># Single column uniqueness\nchecks.is_unique(\"user_id\")\n\n# Composite key uniqueness\nchecks.has_unique_combination([\"first_name\", \"last_name\", \"birth_date\"])\n\n# Duplicate detection\nchecks.has_no_duplicates()\nchecks.duplicate_count_less_than(\"email\", 5)\n</code></pre>"},{"location":"user-guide/#cross-column-validation","title":"Cross-Column Validation","text":"<p>Validate relationships between columns:</p> <pre><code># Column comparison\nchecks.column_greater_than(\"end_date\", \"start_date\")\nchecks.columns_match(\"billing_address\", \"shipping_address\")\n\n# Conditional validation\nchecks.when('status == \"active\"').then(\"balance &gt; 0\")\n\n# Complex rules\nchecks.satisfies(lambda df: df[\"price\"] * df[\"quantity\"] == df[\"total\"])\n</code></pre>"},{"location":"user-guide/#advanced-features","title":"Advanced Features","text":""},{"location":"user-guide/#custom-validation-functions","title":"Custom Validation Functions","text":"<p>Create domain-specific validations:</p> <pre><code>@validator.custom_check\ndef validate_business_rule(df):\n    \"\"\"Custom business logic\"\"\"\n    valid_mask = (\n        (df[\"customer_type\"] == \"premium\") &amp; (df[\"credit_limit\"] &gt;= 10000)\n    ) | ((df[\"customer_type\"] == \"standard\") &amp; (df[\"credit_limit\"] &lt;= 5000))\n    return valid_mask\n</code></pre>"},{"location":"user-guide/#validation-pipelines","title":"Validation Pipelines","text":"<p>Chain multiple validations:</p> <pre><code>pipeline = validator.create_pipeline()\n\n# Stage 1: Basic checks\npipeline.add_stage(\"basic\", [checks.is_not_null(\"id\"), checks.is_unique(\"id\")])\n\n# Stage 2: Business rules\npipeline.add_stage(\n    \"business\",\n    [checks.is_positive(\"revenue\"), checks.date_not_future(\"transaction_date\")],\n)\n\n# Run pipeline\nresults = pipeline.run(df)\n</code></pre>"},{"location":"user-guide/#conditional-validation","title":"Conditional Validation","text":"<p>Apply checks based on conditions:</p> <pre><code># Different rules for different segments\nchecks.when('region == \"US\"').then(\n    checks.matches_pattern(\"phone\", r\"^\\d{3}-\\d{3}-\\d{4}$\")\n)\n\nchecks.when('region == \"UK\"').then(checks.matches_pattern(\"phone\", r\"^\\+44\\d{10}$\"))\n</code></pre>"},{"location":"user-guide/#sampling-and-performance","title":"Sampling and Performance","text":"<p>Optimize validation for large datasets:</p> <pre><code># Sample validation\nvalidator.validate_sample(df, sample_size=10000, checks=checks)\n\n# Chunk processing\nvalidator.validate_chunks(df, chunk_size=50000, checks=checks)\n\n# Parallel validation\nvalidator.validate_parallel(df, checks=checks, n_jobs=4)\n</code></pre>"},{"location":"user-guide/#reporting-and-monitoring","title":"Reporting and Monitoring","text":""},{"location":"user-guide/#html-reports","title":"HTML Reports","text":"<p>Generate interactive reports:</p> <pre><code>results.generate_report(\n    \"validation_report.html\", include_charts=True, include_failed_rows=True\n)\n</code></pre>"},{"location":"user-guide/#dashboard-integration","title":"Dashboard Integration","text":"<p>Export metrics for monitoring:</p> <pre><code># Prometheus metrics\nmetrics = results.to_prometheus()\n\n# JSON for APIs\njson_results = results.to_json()\n\n# Time series data\ntime_series = results.to_time_series()\n</code></pre>"},{"location":"user-guide/#alerting","title":"Alerting","text":"<p>Set up alerts for validation failures:</p> <pre><code># Email alerts\nif not results.passed:\n    validator.send_alert(\n        to=[\"data-team@company.com\"], subject=\"Data Quality Alert\", results=results\n    )\n\n# Slack integration\nvalidator.notify_slack(webhook_url=\"https://hooks.slack.com/...\", results=results)\n</code></pre>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/#1-start-with-critical-checks","title":"1. Start with Critical Checks","text":"<p>Begin with the most important validations: - Primary key uniqueness - Not null for required fields - Basic range validations</p>"},{"location":"user-guide/#2-use-descriptive-names","title":"2. Use Descriptive Names","text":"<pre><code># Good\nchecks.is_not_null(\"customer_id\").with_name(\"Customer ID Required\")\n\n# Better\nchecks.is_not_null(\"customer_id\").with_name(\n    \"Customer ID Required\", description=\"Every order must have a valid customer ID\"\n)\n</code></pre>"},{"location":"user-guide/#3-set-appropriate-thresholds","title":"3. Set Appropriate Thresholds","text":"<pre><code># Allow some nulls in optional fields\nchecks.has_completeness(\"middle_name\", threshold=0.8)\n\n# Strict for critical fields\nchecks.has_completeness(\"email\", threshold=1.0)\n</code></pre>"},{"location":"user-guide/#4-group-related-checks","title":"4. Group Related Checks","text":"<pre><code>customer_checks = CheckGroup(\"Customer Validation\")\ncustomer_checks.add(\n    [\n        checks.is_not_null(\"customer_id\"),\n        checks.matches_pattern(\"email\", email_regex),\n        checks.is_between(\"age\", 18, 120),\n    ]\n)\n</code></pre>"},{"location":"user-guide/#5-version-your-validations","title":"5. Version Your Validations","text":"<pre><code># Track validation rules in version control\nvalidator.save_rules(\"validations/v1.0.0/customer_rules.json\")\n\n# Load versioned rules\nvalidator.load_rules(\"validations/v1.0.0/customer_rules.json\")\n</code></pre>"},{"location":"user-guide/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/#with-pandas","title":"With Pandas","text":"<pre><code># Direct DataFrame validation\ndf = pd.read_csv(\"data.csv\")\nresults = validator.validate(df, checks)\n</code></pre>"},{"location":"user-guide/#with-sql-databases","title":"With SQL Databases","text":"<pre><code># PostgreSQL\nconn_string = \"postgresql://user:pass@localhost/db\"\nresults = validator.validate_query(conn_string, \"SELECT * FROM customers\", checks)\n</code></pre>"},{"location":"user-guide/#with-apache-spark","title":"With Apache Spark","text":"<pre><code># Spark DataFrame validation\nspark_df = spark.read.parquet(\"data.parquet\")\nresults = validator.validate_spark(spark_df, checks)\n</code></pre>"},{"location":"user-guide/#with-airflow","title":"With Airflow","text":"<pre><code># DQX Airflow operator\nfrom dqx.airflow import DQXValidationOperator\n\nvalidation_task = DQXValidationOperator(\n    task_id=\"validate_customer_data\",\n    source=\"s3://bucket/data.parquet\",\n    checks=customer_checks,\n    fail_on_error=True,\n)\n</code></pre>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/#common-issues","title":"Common Issues","text":"<ol> <li>Memory errors with large datasets</li> <li>Use sampling or chunk processing</li> <li>Increase available memory</li> <li> <p>Use distributed processing</p> </li> <li> <p>Slow validation performance</p> </li> <li>Create indexes on validated columns</li> <li>Use parallel processing</li> <li> <p>Optimize regex patterns</p> </li> <li> <p>Connection issues</p> </li> <li>Check database credentials</li> <li>Verify network connectivity</li> <li>Check firewall rules</li> </ol>"},{"location":"user-guide/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging:</p> <pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\nvalidator = DataQualityValidator(debug=True)\n</code></pre>"},{"location":"user-guide/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the Plugin System to extend DQX</li> <li>Read the API Reference for detailed documentation</li> <li>Check out real-world examples</li> <li>Join the community</li> </ul> <p>Need help? Check our FAQ or open an issue.</p>"},{"location":"workflow_example/","title":"DQX Feature Development Workflow - Complete Example","text":"<p>This document walks through a complete feature development workflow using the new agent orchestration system.</p>"},{"location":"workflow_example/#scenario-adding-metric-caching","title":"Scenario: Adding Metric Caching","text":"<p>User Goal: Add LRU caching to avoid recomputing expensive metrics.</p> <p>Expected Outcome: - Production-ready caching feature - 100% test coverage - Comprehensive documentation - PR ready for review</p>"},{"location":"workflow_example/#phase-1-planning-30-minutes","title":"Phase 1: Planning (~30 minutes)","text":""},{"location":"workflow_example/#user-initiates-request","title":"User Initiates Request","text":"<pre><code>User: \"I want to add metric caching to avoid recomputing expensive metrics. The cache should support LRU eviction and optional TTL.\"\n</code></pre>"},{"location":"workflow_example/#core-agent-response","title":"Core Agent Response","text":"<pre><code>I'll help you plan the metric caching feature. Let me start by exploring the codebase and designing the solution.\n\n[Launches dqx-plan agent]\n</code></pre>"},{"location":"workflow_example/#dqx-plan-agent-execution","title":"dqx-plan Agent Execution","text":"<p>Step 1: Exploration (delegated to specialized agents) <pre><code>[Launches dqx-explore agent]\nPrompt: \"Quick search: Find existing caching patterns in DQX. Look for:\n- MetricProvider implementation\n- Similar optimization patterns\n- Related tests\nReturn: file paths and key insights.\"\n\n[Launches dqx-api agent]\nPrompt: \"Review API design patterns for caching in DQX. Check for:\n- Protocol usage patterns\n- Error handling approaches\n- Integration points\nReturn: patterns to follow.\"\n</code></pre></p> <p>Step 2: Design Document Generation</p> <p>dqx-plan creates three modular documents:</p> <p><code>docs/plans/metric_caching_technical_spec.md</code> (312 lines) <pre><code># Metric Caching Technical Specification\n\n## Problem Statement\nMetricProvider currently recomputes metrics on every access, which is\ninefficient for expensive operations (aggregations, complex transformations).\nThis leads to slow validation suite execution, especially with multiple\nassertions using the same metrics.\n\n## Architecture Decisions\n\n### Decision 1: LRU Cache with TTL\n**Rationale**: LRU provides predictable memory usage while TTL handles\ndata staleness. Combination balances performance and correctness.\n**Alternatives considered**:\n- Pure LRU (no TTL) - Rejected: can't handle stale data\n- Pure TTL - Rejected: unbounded memory growth\n- LFU - Rejected: more complex, marginal benefits\n\n### Decision 2: Protocol-based Cache Backend\n**Rationale**: Allows custom implementations (Redis, Memcached) without\nchanging core code. Follows DQX's Protocol pattern.\n**Alternatives considered**:\n- Hardcoded in-memory only - Rejected: not extensible\n- Abstract base class - Rejected: Protocol is more Pythonic\n\n## API Design\n\n### CacheBackend Protocol\n```python\n@runtime_checkable\nclass CacheBackend(Protocol):\n    \"\"\"Protocol for cache backend implementations.\"\"\"\n\n    def get(self, key: str) -&gt; Any | None:\n        \"\"\"Retrieve value or None if not found/expired.\"\"\"\n        ...\n\n    def set(self, key: str, value: Any, ttl: int | None = None) -&gt; None:\n        \"\"\"Store value with optional TTL in seconds.\"\"\"\n        ...\n\n    def clear(self) -&gt; None:\n        \"\"\"Clear all cached entries.\"\"\"\n        ...\n</code></pre></p> <p>{... rest of API design ...}</p>"},{"location":"workflow_example/#integration-points","title":"Integration Points","text":""},{"location":"workflow_example/#metricprovider-srcdqxproviderpy","title":"MetricProvider (<code>src/dqx/provider.py</code>)","text":"<p>Changes needed: Wrap metric computations with cache lookup Impact: Backward compatible - caching is optional</p> <p>{... rest of spec ...} <pre><code>**`docs/plans/metric_caching_implementation_guide.md` (478 lines)**\n```markdown\n# Metric Caching Implementation Guide\n\n## Overview\nImplement LRU cache with TTL support for MetricProvider metrics.\n\n## Phase Breakdown\n\n### Phase 1: Core Cache Data Structures\n**Goal**: Implement LRU cache with TTL support\n**Duration**: 1.5 hours\n\n**Files to create**:\n- `src/dqx/cache.py` - Cache implementation\n\n**Tests to write**:\n```python\ndef test_lru_cache_creation(): ...\ndef test_lru_cache_set_and_get(): ...\ndef test_lru_cache_eviction_on_full(): ...\ndef test_lru_cache_ttl_expiration(): ...\ndef test_lru_cache_update_access_order(): ...\ndef test_lru_cache_clear(): ...\n</code></pre></p> <p>Success criteria: - [ ] All tests passing - [ ] Coverage: 100% - [ ] Pre-commit: passing</p> <p>Commit: <code>feat(cache): add core cache data structures</code></p> <p>{... more phases ...} <pre><code>**`docs/plans/metric_caching_context.md` (245 lines)**\n```markdown\n# Metric Caching Context for Implementation\n\n## DQX Architecture Overview\n\n### MetricProvider (`src/dqx/provider.py`)\n- Purpose: Provides metric computation API (num_rows, sum, average, etc.)\n- Key methods: See lines 45-120\n- How caching relates: Wrap each metric method with cache lookup\n\n### Analyzer (`src/dqx/analyzer.py`)\n- Purpose: Converts symbolic expressions to SQL\n- How caching relates: Cache key should include SQL query\n\n## Code Patterns to Follow\n\n### Pattern 1: Protocol-based Interfaces\n**When to use**: Defining extensible interfaces\n\n**Example from DQX**:\n```python\n@runtime_checkable\nclass SqlDataSource(Protocol):\n    def execute(self, query: str) -&gt; pa.Table: ...\n</code></pre></p> <p>Apply to caching: Define CacheBackend as Protocol</p> <p>{... more patterns ...} <pre><code>### Core Agent Presents Summary\n</code></pre> Design documents created for metric caching:</p> <p>\ud83d\udcc4 Technical Specification: docs/plans/metric_caching_technical_spec.md (312 lines)    Key decisions:    - LRU cache with TTL support (balances performance and correctness)    - Protocol-based backend (extensible for Redis/Memcached)    - Optional caching (backward compatible)</p> <p>\ud83d\udccb Implementation Guide: docs/plans/metric_caching_implementation_guide.md (478 lines)    - 4 phases    - Estimated time: ~5 hours    - Phase 1: Core cache data structures (1.5h)    - Phase 2: Cache backend protocol (1.5h)    - Phase 3: MetricProvider integration (1.5h)    - Phase 4: E2E tests + docs (0.5h)</p> <p>\ud83d\udcda Context Document: docs/plans/metric_caching_context.md (245 lines)    - 3 DQX components covered    - 4 code patterns documented    - 3 common pitfalls highlighted</p> <p>Total: 1,035 lines across 3 modular documents (vs typical 1,500+ lines in single monolithic doc)</p> <p>Ready to proceed with implementation? Or would you like to review/modify the design first? <pre><code>### User Approves Design\n</code></pre> User: \"Looks good, proceed with implementation\" <pre><code>---\n\n## Phase 2: Implementation (~5 hours)\n\n### Core Agent Response\n</code></pre> Starting implementation...</p> <p>[Launches dqx-implement agent] <pre><code>### dqx-implement Agent Execution\n\n**Phase 1: Core Cache Data Structures**\n</code></pre> Loading context:   \u2713 Implementation guide - Phase 1 section   \u2713 Technical spec - LRUCache design   \u2713 Context doc - Protocol pattern</p> <p>Step 1: Writing tests FIRST (TDD)   Creating tests/test_cache.py:     \u2713 test_lru_cache_creation     \u2713 test_lru_cache_set_and_get     \u2713 test_lru_cache_eviction_on_full     \u2713 test_lru_cache_ttl_expiration     \u2713 test_lru_cache_update_access_order     \u2713 test_lru_cache_clear     \u2713 test_lru_cache_max_size_zero     \u2713 test_lru_cache_none_value</p> <p>Running tests (expecting failures):     $ uv run pytest tests/test_cache.py     \u2717 All tests fail (expected - no implementation yet)</p> <p>Step 2: Implementing LRUCache   Creating src/dqx/cache.py:     \u2713 Imports and type hints     \u2713 LRUCache class with init     \u2713 set() method with LRU tracking     \u2713 get() method with TTL check     \u2713 clear() method     \u2713 _evict() helper method     \u2713 Complete docstrings (Google style)</p> <p>Running tests:     $ uv run pytest tests/test_cache.py -v     \u2713 All 8 tests passing</p> <p>Step 3: Quality Gate - Coverage   $ uv run pytest tests/test_cache.py --cov=src/dqx/cache --cov-report=term-missing   \u2713 Coverage: 100%</p> <p>Step 4: Quality Gate - Pre-commit   $ uv run pre-commit run --all-files   \u2713 ruff format: passing   \u2713 ruff check: passing   \u2713 mypy: passing</p> <p>Step 5: Quality Gate - Full Test Suite   $ uv run pytest   \u2713 All 847 tests passing (no regressions)</p> <p>Step 6: Commit   $ git add src/dqx/cache.py tests/test_cache.py   $ git commit -m \"feat(cache): add core cache data structures\"   \u2713 Committed: abc1234</p> <p>\u2713 Phase \u00bc: Core cache data structures   \u2022 Tests written: 8 tests   \u2022 Implementation: complete   \u2022 All tests: passing   \u2022 Coverage: 100%   \u2022 Pre-commit hooks: passing   \u2022 Committed: abc1234 - feat(cache): add core cache data structures <pre><code>**Phase 2: Cache Backend Protocol**\n</code></pre> Loading context:   \u2713 Implementation guide - Phase 2 section   \u2713 Technical spec - CacheBackend protocol   \u2713 Context doc - Protocol pattern</p> <p>Step 1: Writing tests FIRST   Updating tests/test_cache.py:     \u2713 test_cache_backend_protocol_check     \u2713 test_in_memory_cache_backend_get_miss     \u2713 test_in_memory_cache_backend_get_hit     \u2713 test_in_memory_cache_backend_set     \u2713 test_in_memory_cache_backend_ttl     \u2713 test_in_memory_cache_backend_clear</p> <p>Running new tests:     $ uv run pytest tests/test_cache.py::test_cache_backend* -v     \u2717 All new tests fail (expected)</p> <p>Step 2: Implementing CacheBackend Protocol   Updating src/dqx/cache.py:     \u2713 CacheBackend Protocol definition     \u2713 InMemoryCacheBackend implementation     \u2713 Integration with LRUCache     \u2713 Complete docstrings</p> <p>Running tests:     $ uv run pytest tests/test_cache.py -v     \u2713 All 20 tests passing</p> <p>Step 3: Quality Gates   \u2713 Coverage: 100%   \u2713 Pre-commit: passing   \u2713 Full test suite: 859 tests passing</p> <p>Step 4: Commit   $ git commit -m \"feat(cache): implement cache backend protocol\"   \u2713 Committed: def5678</p> <p>\u2713 Phase 2/4: Cache backend protocol   \u2022 Tests written: 12 tests   \u2022 Implementation: complete   \u2022 All tests: passing (20 total in test_cache.py)   \u2022 Coverage: 100%   \u2022 Pre-commit hooks: passing   \u2022 Committed: def5678 - feat(cache): implement cache backend protocol <pre><code>**Phase 3: MetricProvider Integration**\n</code></pre> Loading context:   \u2713 Implementation guide - Phase 3 section   \u2713 Technical spec - MetricProvider integration   \u2713 src/dqx/provider.py (existing code)</p> <p>Step 1: Writing tests FIRST   Creating tests/test_provider_cache_integration.py:     \u2713 test_metric_provider_with_cache     \u2713 test_metric_provider_cache_hit     \u2713 test_metric_provider_cache_miss     \u2713 test_metric_provider_cache_disabled     \u2713 test_metric_provider_cache_invalidation</p> <p>Running new tests:     \u2717 All fail (expected - no integration yet)</p> <p>Step 2: Implementing Integration   Updating src/dqx/provider.py:     \u2713 Add cache parameter to init     \u2713 Wrap num_rows() with cache     \u2713 Wrap sum() with cache     \u2713 Wrap average() with cache     {... all metric methods ...}     \u2713 Add cache key generation     \u2713 Update docstrings</p> <p>Updating src/dqx/init.py:     \u2713 Export cache classes</p> <p>Running tests:     $ uv run pytest tests/test_provider_cache_integration.py -v     \u2713 All 15 tests passing</p> <p>Step 3: Quality Gates   \u2713 Coverage: 100%   \u2713 Pre-commit: passing   \u2713 Full test suite: 874 tests passing</p> <p>Step 4: Commit   $ git commit -m \"feat(cache): integrate caching with MetricProvider\"   \u2713 Committed: ghi9012</p> <p>\u2713 Phase \u00be: MetricProvider integration   \u2022 Tests written: 15 tests   \u2022 Implementation: complete   \u2022 All tests: passing (35 total for caching)   \u2022 Coverage: 100%   \u2022 Pre-commit hooks: passing   \u2022 Committed: ghi9012 - feat(cache): integrate caching with MetricProvider <pre><code>**Phase 4: E2E Tests + Documentation**\n</code></pre> Loading context:   \u2713 Implementation guide - Phase 4 section   \u2713 Technical spec - full document</p> <p>Step 1: Writing E2E tests   Creating tests/e2e/test_cache_e2e.py:     \u2713 test_verification_suite_with_caching     \u2713 test_cache_performance_improvement     \u2713 test_cache_across_multiple_checks</p> <p>Running E2E tests:     $ uv run pytest tests/e2e/test_cache_e2e.py -v     \u2713 All 6 tests passing</p> <p>Step 2: Documentation   Updating docs/api-reference.md:     \u2713 Added CacheBackend protocol docs     \u2713 Added InMemoryCacheBackend docs     \u2713 Added usage examples</p> <p>Updating README.md:     \u2713 Added caching example</p> <p>Step 3: Quality Gates   \u2713 Coverage: 100%   \u2713 Pre-commit: passing   \u2713 Full test suite: 880 tests passing</p> <p>Step 4: Commit   $ git commit -m \"docs(cache): add caching documentation and examples\"   \u2713 Committed: jkl3456</p> <p>\u2713 Phase 4/4: E2E tests + docs   \u2022 Tests written: 6 tests   \u2022 Documentation: updated   \u2022 All tests: passing (41 total for caching)   \u2022 Coverage: 100%   \u2022 Pre-commit hooks: passing   \u2022 Committed: jkl3456 - docs(cache): add caching documentation <pre><code>### Core Agent Presents Summary\n</code></pre> Implementation complete!</p> <p>\ud83d\udcca Summary: \u2022 Phases completed: 4/4 \u2022 Total tests: 41 (8 + 12 + 15 + 6) \u2022 Coverage: 100% \u2022 Commits created: 4 \u2022 All pre-commit hooks: passing \u2022 No regressions: 880 total tests passing</p> <p>\ud83d\udcdd Commit history: abc1234 feat(cache): add core cache data structures def5678 feat(cache): implement cache backend protocol ghi9012 feat(cache): integrate caching with MetricProvider jkl3456 docs(cache): add caching documentation</p> <p>Ready to create pull request? <pre><code>### User Approves PR Creation\n</code></pre> User: \"Yes, create PR\" <pre><code>---\n\n## Phase 3: PR Creation (~5 minutes)\n\n### Core Agent Response\n</code></pre> Creating pull request...</p> <p>[Launches dqx-pr agent] <pre><code>### dqx-pr Agent Execution\n</code></pre> Step 1: Analyzing feature branch   \u2713 Branch: feature/metric-caching   \u2713 Commits since main: 4   \u2713 Files changed: 6   \u2713 Lines added: +523   \u2713 Lines removed: -12</p> <p>Step 2: Loading design documents   \u2713 Technical spec: docs/plans/metric_caching_technical_spec.md   \u2713 Implementation guide: docs/plans/metric_caching_implementation_guide.md   Extracting key information...</p> <p>Step 3: Verifying quality gates   $ uv run pytest   \u2713 All 880 tests passing</p> <p>$ uv run pytest --cov=src/dqx --cov-report=term   \u2713 Coverage: 100%</p> <p>$ uv run pre-commit run --all-files   \u2713 All hooks passing</p> <p>Step 4: Generating PR description   \u2713 Summary extracted from technical spec   \u2713 Architecture decisions documented   \u2713 Phase breakdown with commit references   \u2713 Test verification included   \u2713 Design doc links added</p> <p>Step 5: Creating PR   $ git push -u origin feature/metric-caching   \u2713 Pushed to remote</p> <p>$ gh pr create --title \"feat(cache): add LRU cache with TTL support\" --body \"...\"   \u2713 PR created: #123</p> <p>Step 6: PR created successfully   URL: https://github.com/user/dqx/pull/123 <pre><code>### Core Agent Presents PR Details\n</code></pre> Pull request created successfully!</p> <p>\ud83d\udd17 PR URL: https://github.com/user/dqx/pull/123</p> <p>\ud83d\udcca Summary: \u2022 Commits: 4 \u2022 Files changed: 6 \u2022 Tests added: 41 \u2022 Coverage: 100%</p> <p>\ud83d\udcc1 Design docs: 3 files in docs/plans/ \u2022 Technical spec: metric_caching_technical_spec.md \u2022 Implementation guide: metric_caching_implementation_guide.md \u2022 Context doc: metric_caching_context.md</p> <p>\u2705 Quality gates: \u2022 All tests passing (880 total) \u2022 Coverage: 100% \u2022 Pre-commit hooks: passing</p> <p>\ud83d\udd04 Next steps: 1. CodeRabbit will automatically review the PR 2. Address any feedback with targeted commits 3. Request human review when ready 4. Merge after approval</p> <p>The PR description includes links to all design documents for reviewers. <pre><code>---\n\n## Phase 4: Feedback Iteration (~1-2 hours)\n\n### CodeRabbit Reviews PR\n\nCodeRabbit posts 8 review comments:\n- 2 P0 (blockers): Missing type hint, missing test\n- 4 P1 (important): Naming improvements, docstring additions\n- 2 P2 (nice-to-have): Refactoring suggestions\n\n### User Requests Feedback Resolution\n</code></pre> User: \"Address CodeRabbit feedback\" <pre><code>### Core Agent Response\n</code></pre> Analyzing review comments...</p> <p>[Launches dqx-feedback agent] <pre><code>### dqx-feedback Agent Execution\n</code></pre> Step 1: Fetching comments   $ gh pr view 123 --json comments   \u2713 Fetched 8 review comments</p> <p>Step 2: Grouping and prioritizing   \u2713 P0 (blockers): 2 comments   \u2713 P1 (important): 4 comments   \u2713 P2 (nice-to-have): 2 comments</p> <p>Step 3: Addressing P0 comments</p> <p>Comment #1 (P0): src/dqx/cache.py:78   Issue: \"Missing return type hint for evict method\"</p> <p>Loading minimal context:     \u2713 src/dqx/cache.py</p> <p>Fix:     Updated line 78:     - def evict(self):     + def evict(self) -&gt; tuple[str, Any]:</p> <p>Verification:     $ uv run mypy src/dqx/cache.py     \u2713 Type checking passing</p> <pre><code>$ uv run pytest tests/test_cache.py -v\n\u2713 All tests passing\n</code></pre> <p>Commit:     $ git commit -m \"fix: add type hint for evict method\"     \u2713 Committed: aaa1111</p> <p>Comment #2 (P0): tests/test_cache.py:120   Issue: \"Add test for cache full with TTL edge case\"</p> <p>Loading minimal context:     \u2713 tests/test_cache.py     \u2713 src/dqx/cache.py (lines 45-90)</p> <p>Fix:     Added test at line 120:     def test_cache_full_with_expired_entries(self) -&gt; None:         \"\"\"Test eviction considers expired entries.\"\"\"         cache = LRUCache(max_size=2)         cache.set(\"a\", 1, ttl=0.1)         time.sleep(0.2)  # Let \"a\" expire         cache.set(\"b\", 2)         cache.set(\"c\", 3)  # Should NOT evict \"b\"         assert cache.get(\"a\") is None         assert cache.get(\"b\") == 2         assert cache.get(\"c\") == 3</p> <p>Verification:     $ uv run pytest tests/test_cache.py::test_cache_full_with_expired_entries -v     \u2713 New test passing</p> <p>Commit:     $ git commit -m \"test: add cache full with TTL edge case\"     \u2713 Committed: bbb2222</p> <p>\u2713 P0 issues: 2/2 fixed</p> <p>Step 4: Addressing P1 comments</p> <p>{Similar process for 4 P1 comments...}</p> <p>\u2713 P1 issues: 4/4 fixed</p> <p>Step 5: Addressing P2 comments</p> <p>{Similar process for 2 P2 comments...}</p> <p>\u2713 P2 issues: 2/2 fixed</p> <p>Step 6: Final verification   $ uv run pytest   \u2713 All 882 tests passing (2 new tests added)</p> <p>$ uv run pytest --cov=src/dqx --cov-report=term   \u2713 Coverage: 100%</p> <p>$ uv run pre-commit run --all-files   \u2713 All hooks passing</p> <p>Step 7: Pushing fixes   $ git push   \u2713 Pushed 8 fix commits</p> <p>Step 8: Commenting on PR   $ gh pr comment 123 --body \"...\"   \u2713 Posted summary comment <pre><code>### Core Agent Presents Summary\n</code></pre> Review feedback addressed successfully!</p> <p>\ud83d\udcca Summary: \u2022 Total comments: 8 \u2022 P0 (blockers): 2 - All fixed \u2713 \u2022 P1 (important): 4 - All fixed \u2713 \u2022 P2 (nice-to-have): 2 - All fixed \u2713</p> <p>\ud83d\udcdd Changes made: src/dqx/cache.py (4 changes)   \u2022 Added type hint for evict method   \u2022 Improved variable naming in _evict()   \u2022 Added docstring for _is_expired()   \u2022 Refactored TTL check logic</p> <p>tests/test_cache.py (3 changes)   \u2022 Added cache full with TTL edge case test   \u2022 Added integration test for cache invalidation   \u2022 Added performance benchmark test</p> <p>docs/plans/metric_caching_technical_spec.md (1 change)   \u2022 Clarified TTL behavior in decision section</p> <p>\u2705 Quality gates: \u2022 Full test suite: passing (882 tests, +2 new) \u2022 Coverage: 100% \u2022 Pre-commit hooks: passing</p> <p>\ud83d\udcbe Commits pushed: 8 aaa1111 - fix: add type hint for evict method bbb2222 - test: add cache full with TTL edge case ccc3333 - style: improve variable naming in evict logic ddd4444 - docs: add docstring for is_expired helper eee5555 - refactor: simplify TTL check logic fff6666 - test: add cache invalidation integration test ggg7777 - test: add performance benchmark for caching hhh8888 - docs: clarify TTL behavior in spec</p> <p>Ready for next review cycle! <pre><code>---\n\n## Phase 5: Merge &amp; Completion\n\n### Human Reviewer Approves\n\nAfter reviewing the PR and all feedback responses, human reviewer approves.\n</code></pre> User: \"Merge the PR\" <pre><code>### User Merges\n</code></pre> $ gh pr merge 123 --squash \u2713 Merged PR #123 into main</p> <p>Feature complete! Metric caching is now available in DQX. <pre><code>---\n\n## Workflow Benefits Demonstrated\n\n### Context Management\n- **Planning**: 1,035 lines across 3 docs (vs 1,500+ monolithic)\n- **Implementation**: Only ~300-500 lines loaded per phase\n- **Feedback**: Only relevant files loaded per comment\n- **Total context reduction**: ~60%\n\n### Automation\n- **Manual interventions**: 5 (approve design, approve impl, approve PR, request feedback, merge)\n- **Automated steps**: 40+ (tests, coverage, commits, quality gates, fixes)\n- **Automation rate**: ~90%\n\n### Quality Assurance\n- **Coverage**: 100% throughout (enforced automatically)\n- **Pre-commit**: Passed after every phase\n- **Regressions**: 0 (verified after each phase)\n- **Code style**: Consistent (auto-formatted)\n\n### Time Efficiency\n- **Planning**: 30 min (including exploration)\n- **Implementation**: 5 hours (4 phases, automated)\n- **PR creation**: 5 min (fully automated)\n- **Feedback**: 1-2 hours (8 comments addressed)\n- **Total**: ~7 hours for production-ready feature\n\n### Documentation\n- **Design docs**: 3 comprehensive documents\n- **PR description**: Links to all design context\n- **Code comments**: Complete docstrings\n- **Examples**: Added to API docs and README\n\n---\n\n## Comparison: Old vs New Workflow\n\n### Old Workflow (Manual)\n</code></pre> Time: ~12 hours Context: Monolithic design doc (1,500+ lines) Iterations: Multiple back-and-forth for quality issues Coverage: Often 95-98% (manual verification) Commits: Often lumped together Documentation: Written after implementation <pre><code>### New Workflow (Automated)\n</code></pre> Time: ~7 hours Context: Modular docs (3 \u00d7 300-400 lines) Iterations: Minimal (quality enforced automatically) Coverage: Always 100% (automated verification) Commits: Atomic, one per phase Documentation: Generated during implementation ```</p> <p>Improvement: ~40% time reduction, higher quality, better documentation.</p>"},{"location":"design/profiles/","title":"Profiles: Configurable Data Quality Rules","text":""},{"location":"design/profiles/#problem","title":"Problem","text":"<p>Data quality checks fail during holiday seasons. Order volumes drop. User behavior shifts. Metrics that pass on normal days fail on Christmas.</p> <p>Teams need three capabilities:</p> <ol> <li>Disable checks that do not apply during holidays</li> <li>Compensate metrics by scaling values to account for expected changes</li> <li>Adjust severity to reduce alert noise during known disruption periods</li> </ol>"},{"location":"design/profiles/#solution","title":"Solution","text":"<p>Profiles modify assertion behavior during specific periods. A profile activates based on the current date and applies rules: disable assertions, scale metric values, or adjust severity.</p> <pre><code>christmas = HolidayProfile(\n    name=\"Christmas 2024\",\n    start_date=date(2024, 12, 20),\n    end_date=date(2025, 1, 5),\n    rules=[\n        tag(\"xmas\").set(metric_multiplier=2.0),\n        tag(\"non-critical\").set(severity=\"P3\"),  # Downgrade during holidays\n        check(\"Volume Check\").disable(),\n    ],\n)\n\nsuite = VerificationSuite(\n    checks=[volume_check, quality_check], db=db, name=\"My Suite\", profiles=[christmas]\n)\n</code></pre>"},{"location":"design/profiles/#key-concepts","title":"Key Concepts","text":""},{"location":"design/profiles/#dqx-constructs","title":"DQX Constructs","text":"Construct Purpose Example Check Groups related assertions <code>@check(name=\"Volume Check\")</code> Assertion Single validation rule <code>ctx.assert_that(orders).is_gt(100)</code> Threshold Pass/fail boundary The <code>100</code> in <code>is_gt(100)</code> <p>A check contains one or more assertions. Each assertion compares a metric against a threshold.</p> <pre><code>@check(name=\"Volume Check\")\ndef volume_check(mp, ctx):\n    ctx.assert_that(mp.sum(\"orders\")).config(\n        name=\"Daily orders above minimum\", tags={\"volume\", \"xmas\"}\n    ).is_gt(100)\n</code></pre>"},{"location":"design/profiles/#profile","title":"Profile","text":"<p>A profile activates during a date range and applies rules to matching assertions.</p> <pre><code>@runtime_checkable\nclass Profile(Protocol):\n    name: str\n\n    def is_active(self, target_date: date) -&gt; bool: ...\n\n    @property\n    def rules(self) -&gt; list[Rule]: ...\n</code></pre> <p>The protocol enables future profile types with different activation logic.</p>"},{"location":"design/profiles/#rule","title":"Rule","text":"<p>A rule selects assertions and specifies an action.</p> <pre><code>@dataclass(frozen=True)\nclass Rule:\n    selector: Selector\n    disabled: bool = False\n    metric_multiplier: float = 1.0\n    severity: SeverityLevel | None = None\n</code></pre>"},{"location":"design/profiles/#selector","title":"Selector","text":"<p>Selectors identify which assertions a rule targets.</p> <p>AssertionSelector matches by check name and assertion name:</p> <pre><code>assertion(\"Volume Check\", \"Daily orders above minimum\")  # exact match\ncheck(\"Volume Check\")  # all assertions in check\n</code></pre> <p>TagSelector matches by tag:</p> <pre><code>tag(\"xmas\")\n</code></pre>"},{"location":"design/profiles/#detailed-design","title":"Detailed Design","text":""},{"location":"design/profiles/#core-types","title":"Core Types","text":"<p>Create <code>src/dqx/profiles.py</code>:</p> <pre><code>from __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom datetime import date\nfrom typing import Protocol, runtime_checkable\n\n\nSelector = AssertionSelector | TagSelector\n\n\n@dataclass(frozen=True)\nclass AssertionSelector:\n    \"\"\"Matches assertions by check and assertion name.\"\"\"\n\n    check: str\n    assertion: str | None = None\n\n    def matches(self, check_name: str, assertion_name: str) -&gt; bool:\n        if check_name != self.check:\n            return False\n        if self.assertion is None:\n            return True\n        return assertion_name == self.assertion\n\n\n@dataclass(frozen=True)\nclass TagSelector:\n    \"\"\"Matches assertions by tag.\"\"\"\n\n    tag: str\n\n    def matches(self, tags: frozenset[str]) -&gt; bool:\n        return self.tag in tags\n\n\n@dataclass(frozen=True)\nclass Rule:\n    \"\"\"Pairs a selector with an action.\"\"\"\n\n    selector: Selector\n    disabled: bool = False\n    metric_multiplier: float = 1.0\n    severity: SeverityLevel | None = None\n\n\n@runtime_checkable\nclass Profile(Protocol):\n    \"\"\"Base protocol for all profile types.\"\"\"\n\n    name: str\n\n    def is_active(self, target_date: date) -&gt; bool: ...\n\n    @property\n    def rules(self) -&gt; list[Rule]: ...\n\n\n@dataclass\nclass HolidayProfile:\n    \"\"\"Profile active during a date range.\"\"\"\n\n    name: str\n    start_date: date\n    end_date: date\n    rules: list[Rule] = field(default_factory=list)\n\n    def is_active(self, target_date: date) -&gt; bool:\n        return self.start_date &lt;= target_date &lt;= self.end_date\n</code></pre>"},{"location":"design/profiles/#builder-functions","title":"Builder Functions","text":"<p>Builders provide a fluent API for creating rules:</p> <pre><code>class RuleBuilder:\n    \"\"\"Constructs rules with a fluent interface.\"\"\"\n\n    def __init__(self, selector: Selector):\n        self._selector = selector\n\n    def disable(self) -&gt; Rule:\n        return Rule(selector=self._selector, disabled=True)\n\n    def set(\n        self, *, metric_multiplier: float = 1.0, severity: SeverityLevel | None = None\n    ) -&gt; Rule:\n        return Rule(\n            selector=self._selector,\n            metric_multiplier=metric_multiplier,\n            severity=severity,\n        )\n\n\ndef assertion(check: str, name: str | None = None) -&gt; RuleBuilder:\n    \"\"\"Select by check and assertion name.\"\"\"\n    return RuleBuilder(AssertionSelector(check=check, assertion=name))\n\n\ndef check(name: str) -&gt; RuleBuilder:\n    \"\"\"Select all assertions in a check.\"\"\"\n    return RuleBuilder(AssertionSelector(check=name, assertion=None))\n\n\ndef tag(name: str) -&gt; RuleBuilder:\n    \"\"\"Select assertions with a specific tag.\"\"\"\n    return RuleBuilder(TagSelector(tag=name))\n</code></pre>"},{"location":"design/profiles/#profile-resolution","title":"Profile Resolution","text":"<p>The evaluator resolves rules before evaluating each assertion:</p> <pre><code>@dataclass\nclass ResolvedOverrides:\n    \"\"\"Accumulated overrides from all matching rules.\"\"\"\n\n    disabled: bool = False\n    metric_multiplier: float = 1.0\n    severity: SeverityLevel | None = None\n\n\ndef resolve_overrides(\n    check_name: str,\n    assertion: AssertionNode,\n    profiles: list[Profile],\n    target_date: date,\n) -&gt; ResolvedOverrides:\n    \"\"\"Apply all matching rules from active profiles.\"\"\"\n\n    result = ResolvedOverrides()\n\n    for profile in profiles:\n        if not profile.is_active(target_date):\n            continue\n\n        for rule in profile.rules:\n            if not _matches(rule.selector, check_name, assertion):\n                continue\n\n            if rule.disabled:\n                result.disabled = True\n\n            result.metric_multiplier *= rule.metric_multiplier\n\n            if rule.severity is not None:\n                result.severity = rule.severity\n\n    return result\n\n\ndef _matches(\n    selector: Selector,\n    check_name: str,\n    assertion: AssertionNode,\n) -&gt; bool:\n    match selector:\n        case AssertionSelector():\n            return selector.matches(check_name, assertion.name)\n        case TagSelector():\n            return selector.matches(assertion.tags)\n</code></pre>"},{"location":"design/profiles/#metric-multiplier","title":"Metric Multiplier","text":"<p>The multiplier scales the computed metric value before comparison. This compensates for expected metric changes during the profile period.</p> <p>Example: Orders drop 50% during Christmas.</p> <pre><code># Assertion: orders &gt; 100\n# Christmas day: orders = 60\n\n# Without profile: 60 &gt; 100 \u2192 FAILED\n# With metric_multiplier=2.0: 60 \u00d7 2.0 = 120 &gt; 100 \u2192 PASSED\n</code></pre> <p>The evaluator applies the multiplier:</p> <pre><code># In Evaluator.visit():\nmatch node._metric:\n    case Success(value):\n        adjusted = value * overrides.metric_multiplier\n        passed = node.validator.fn(adjusted)\n        node._result = \"PASSED\" if passed else \"FAILED\"\n</code></pre>"},{"location":"design/profiles/#severity-override","title":"Severity Override","text":"<p>The severity override changes an assertion's priority level. Use it to reduce alert noise during periods of expected disruption.</p> <p>Example: Non-critical checks trigger pages during normal operations but should only log during holidays.</p> <pre><code># Assertion defined with severity P1\nctx.assert_that(orders).config(name=\"Order count\", severity=\"P1\", tags={\"non-critical\"})\n\n# During Christmas, downgrade to P3\ntag(\"non-critical\").set(severity=\"P3\")\n</code></pre> <p>The last matching rule determines severity. Unlike multipliers, severities do not compound.</p> <pre><code>rules = [\n    tag(\"volume\").set(severity=\"P2\"),\n    tag(\"xmas\").set(severity=\"P3\"),\n]\n# Assertion with both tags: severity = P3 (last match wins)\n</code></pre>"},{"location":"design/profiles/#rule-ordering","title":"Rule Ordering","text":"<p>Rules apply in definition order. Later rules compound with earlier ones (multipliers multiply, severity uses last match):</p> <pre><code>rules = [\n    tag(\"volume\").set(metric_multiplier=1.5),\n    assertion(\"Check\", \"Orders\").set(metric_multiplier=2.0),\n]\n# For \"Orders\" with tag \"volume\": multiplier = 1.5 \u00d7 2.0 = 3.0\n</code></pre>"},{"location":"design/profiles/#usage-examples","title":"Usage Examples","text":""},{"location":"design/profiles/#holiday-profile","title":"Holiday Profile","text":"<pre><code>from datetime import date\nfrom dqx.profiles import HolidayProfile, tag, assertion, check\n\nchristmas = HolidayProfile(\n    name=\"Christmas 2024\",\n    start_date=date(2024, 12, 20),\n    end_date=date(2025, 1, 5),\n    rules=[\n        tag(\"xmas\").set(metric_multiplier=2.0),\n        check(\"Volume Check\").disable(),\n    ],\n)\n</code></pre>"},{"location":"design/profiles/#checks-with-tags","title":"Checks with Tags","text":"<pre><code>@check(name=\"Volume Check\")\ndef volume_check(mp, ctx):\n    ctx.assert_that(mp.sum(\"orders\")).config(\n        name=\"Daily orders above minimum\", tags={\"volume\", \"xmas\"}\n    ).is_gt(100)\n\n\n@check(name=\"Quality Check\")\ndef quality_check(mp, ctx):\n    ctx.assert_that(mp.average(\"error_rate\")).config(\n        name=\"Error rate below threshold\", tags={\"quality\"}\n    ).is_lt(0.05)\n</code></pre>"},{"location":"design/profiles/#running-with-profiles","title":"Running with Profiles","text":"<pre><code>suite = VerificationSuite(\n    checks=[volume_check, quality_check],\n    db=db,\n    name=\"Daily Checks\",\n    profiles=[christmas],\n)\n\nkey = ResultKey(date(2024, 12, 25), tags={})\nsuite.run(datasources, key)  # Profile activates, rules apply\n</code></pre>"},{"location":"design/profiles/#multiple-profiles","title":"Multiple Profiles","text":"<pre><code>christmas = HolidayProfile(\n    name=\"Christmas\",\n    start_date=date(2024, 12, 20),\n    end_date=date(2025, 1, 5),\n    rules=[tag(\"xmas\").set(metric_multiplier=2.0)],\n)\n\nblack_friday = HolidayProfile(\n    name=\"Black Friday\",\n    start_date=date(2024, 11, 29),\n    end_date=date(2024, 12, 2),\n    rules=[check(\"Volume Check\").set(metric_multiplier=3.0)],\n)\n\nsuite = VerificationSuite(\n    checks=[...],\n    db=db,\n    name=\"Suite\",\n    profiles=[christmas, black_friday],\n)\n</code></pre>"},{"location":"design/profiles/#files-to-modify","title":"Files to Modify","text":"File Change <code>src/dqx/profiles.py</code> Create: Profile protocol, selectors, rules, builders <code>src/dqx/api.py</code> Add <code>profiles</code> to <code>VerificationSuite</code> <code>src/dqx/evaluator.py</code> Resolve and apply <code>metric_multiplier</code> before validation <code>src/dqx/__init__.py</code> Export profile types"},{"location":"design/profiles/#testing-strategy","title":"Testing Strategy","text":""},{"location":"design/profiles/#unit-tests","title":"Unit Tests","text":"<ol> <li>Selector matching \u2014 AssertionSelector and TagSelector match correctly</li> <li>Rule application \u2014 metric_multiplier compounds across rules</li> <li>Profile activation \u2014 date range logic works</li> <li>Rule ordering \u2014 later rules compound with earlier ones</li> </ol>"},{"location":"design/profiles/#integration-tests","title":"Integration Tests","text":"<ol> <li>Disabled assertion \u2014 assertion skipped when rule disables it</li> <li>Scaled metric \u2014 assertion uses adjusted value</li> <li>Multiple profiles \u2014 rules from all active profiles apply</li> <li>No active profile \u2014 assertions evaluate normally</li> </ol>"},{"location":"design/profiles/#future-extensions","title":"Future Extensions","text":"<p>The <code>Profile</code> protocol enables additional profile types:</p> <ul> <li>MaintenanceProfile \u2014 relax checks during scheduled maintenance</li> <li>RegionProfile \u2014 apply region-specific multipliers</li> <li>ABTestProfile \u2014 test different configurations</li> </ul> <p>Each implements <code>is_active()</code> and <code>rules</code> with its own activation logic.</p>"}]}