{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DQX - Data Quality Excellence","text":"<p>Data quality as code. Works with your warehouse, scales with your needs.</p> <p> </p>"},{"location":"#why-dqx","title":"Why DQX?","text":"<ul> <li>Write validation logic as testable Python functions - No more complex SQL scripts scattered across your codebase</li> <li>Execute efficiently on any SQL backend - DuckDB, BigQuery, Snowflake, or your existing data warehouse</li> <li>No clusters or complex infrastructure needed - Runs wherever your data lives</li> <li>Integrates seamlessly with existing workflows - Drop it into your current pipeline</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install dqlib\n</code></pre> <p>Define your data quality checks as Python functions:</p> <pre><code>import pyarrow as pa\nfrom dqx.api import check, VerificationSuite, MetricProvider, Context\nfrom dqx.common import ResultKey\nfrom dqx.datasource import DuckRelationDataSource\nfrom dqx.orm.repositories import InMemoryMetricDB\n\n\n# Define your validation rules\n@check(name=\"Revenue integrity\")\ndef validate_revenue(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Verify reported revenue is positive\n    reported = mp.sum(\"revenue\")\n    ctx.assert_that(reported).where(\n        name=\"Revenue is positive\", severity=\"P0\"\n    ).is_positive()\n\n    # Check average transaction size is reasonable\n    avg_revenue = mp.average(\"revenue\")\n    ctx.assert_that(avg_revenue).where(\n        name=\"Average transaction size\", severity=\"P1\"\n    ).is_between(10, 100)\n\n\n# Your own metric store\ndb = InMemoryMetricDB()\nsuite = VerificationSuite([validate_revenue], db, \"Daily validation\")\n\n# Data comes from your warehouse\ndata = pa.Table.from_pydict(\n    {\"price\": [10.5, 20.0, 15.5], \"quantity\": [2, 1, 3], \"revenue\": [21.0, 20.0, 46.5]}\n)\ndatasource = DuckRelationDataSource.from_arrow(data)\n\n# Validate your data\nsuite.run([datasource], ResultKey())\n# \u2713 Revenue integrity: OK\n</code></pre>"},{"location":"#real-world-examples","title":"Real-World Examples","text":""},{"location":"#1-data-completeness","title":"1. Data Completeness","text":""},{"location":"#monitor-critical-fields-arent-missing","title":"Monitor critical fields aren't missing","text":"<pre><code>@check(name=\"Customer data quality\")\ndef check_completeness(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Flag if more than 5% of emails are missing\n    null_rate = mp.null_count(\"email\") / mp.num_rows()\n    ctx.assert_that(null_rate).where(name=\"Email completeness\", severity=\"P0\").is_lt(\n        0.05\n    )\n\n    # Ensure all orders have customer IDs\n    ctx.assert_that(mp.null_count(\"customer_id\")).where(\n        name=\"Customer ID required\", severity=\"P0\"\n    ).is_eq(0)\n</code></pre>"},{"location":"#2-revenue-integrity","title":"2. Revenue Integrity","text":""},{"location":"#catch-calculation-errors-in-financial-data","title":"Catch calculation errors in financial data","text":"<pre><code>@check(name=\"Financial accuracy\")\ndef validate_financials(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Verify totals match across systems\n    total_revenue = mp.sum(\"revenue\")\n    total_collected = mp.sum(\"payments\")\n\n    ctx.assert_that(total_collected / total_revenue).where(\n        name=\"Payment collection rate\", severity=\"P1\"\n    ).is_between(\n        0.95, 1.05\n    )  # 5% tolerance\n\n    # Check for negative prices\n    ctx.assert_that(mp.minimum(\"price\")).where(\n        name=\"No negative prices\", severity=\"P0\"\n    ).is_geq(0)\n</code></pre>"},{"location":"#3-trend-monitoring","title":"3. Trend Monitoring","text":""},{"location":"#alert-on-unexpected-metric-changes","title":"Alert on unexpected metric changes","text":"<pre><code>@check(name=\"Business metrics stability\")\ndef monitor_trends(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Alert on significant daily changes\n    daily_change = mp.sum(\"revenue\") / mp.sum(\"revenue\", lag=1)\n    ctx.assert_that(daily_change).where(\n        name=\"Daily revenue stability\", severity=\"P0\"\n    ).is_between(\n        0.8, 1.2\n    )  # \u00b120% change\n\n    # Track week-over-week growth\n    wow_change = mp.sum(\"revenue\") / mp.sum(\"revenue\", lag=7)\n    ctx.assert_that(wow_change).where(\n        name=\"Weekly revenue trend\", severity=\"P1\"\n    ).is_geq(\n        0.95\n    )  # Allow 5% decline\n</code></pre>"},{"location":"#4-cross-dataset-validation","title":"4. Cross-Dataset Validation","text":""},{"location":"#ensure-consistency-across-environments","title":"Ensure consistency across environments","text":"<pre><code>@check(name=\"Production vs Staging\", datasets=[\"production\", \"staging\"])\ndef validate_environments(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Compare row counts\n    prod_count = mp.num_rows(dataset=\"production\")\n    staging_count = mp.num_rows(dataset=\"staging\")\n\n    ctx.assert_that(prod_count).where(name=\"Row count match\", severity=\"P1\").is_between(\n        staging_count - 100, staging_count + 100\n    )  # Allow 100 row difference\n\n    # Verify key metrics align\n    prod_revenue = mp.sum(\"revenue\", dataset=\"production\")\n    staging_revenue = mp.sum(\"revenue\", dataset=\"staging\")\n\n    ctx.assert_that((prod_revenue - staging_revenue) / prod_revenue).where(\n        name=\"Revenue consistency\", severity=\"P0\"\n    ).is_lt(\n        0.01\n    )  # Less than 1% difference\n</code></pre>"},{"location":"#5-data-quality-slas","title":"5. Data Quality SLAs","text":""},{"location":"#track-quality-metrics-with-severity-levels","title":"Track quality metrics with severity levels","text":"<pre><code>@check(name=\"Data quality SLAs\")\ndef enforce_slas(mp: MetricProvider, ctx: Context) -&gt; None:\n    # P0: Critical - No duplicate transactions\n    ctx.assert_that(mp.duplicate_count([\"transaction_id\"])).where(\n        name=\"Transaction uniqueness\", severity=\"P0\"\n    ).is_eq(0)\n\n    # P1: High - Recent activity\n    recent_count = mp.count_values(\"status\", \"active\")\n    total_count = mp.num_rows()\n    active_rate = recent_count / total_count\n\n    ctx.assert_that(active_rate).where(\n        name=\"Active record percentage\", severity=\"P1\"\n    ).is_gt(\n        0.5\n    )  # At least 50% active\n\n    # P2: Medium - Cardinality checks\n    unique_users = mp.unique_count(\"user_id\")\n    ctx.assert_that(unique_users).where(\n        name=\"Active user threshold\", severity=\"P2\"\n    ).is_gt(1000)\n</code></pre>"},{"location":"#quick-reference","title":"Quick Reference","text":""},{"location":"#available-metrics","title":"Available Metrics","text":"Metric Description Example <code>num_rows()</code> Total row count <code>mp.num_rows()</code> <code>sum(col)</code> Sum of values <code>mp.sum(\"revenue\")</code> <code>average(col)</code> Mean value <code>mp.average(\"price\")</code> <code>minimum(col)</code> / <code>maximum(col)</code> Min/max values <code>mp.minimum(\"age\")</code> <code>first(col)</code> First value in column <code>mp.first(\"timestamp\")</code> <code>variance(col)</code> Statistical variance <code>mp.variance(\"score\")</code> <code>null_count(col)</code> Count of null values <code>mp.null_count(\"email\")</code> <code>duplicate_count([cols])</code> Count of duplicate rows <code>mp.duplicate_count([\"id\"])</code> <code>count_values(col, val)</code> Count specific values <code>mp.count_values(\"status\", \"active\")</code> <code>unique_count(col)</code> Distinct value count <code>mp.unique_count(\"user_id\")</code>"},{"location":"#extended-metrics","title":"Extended Metrics","text":"Metric Description Example <code>ext.day_over_day(metric)</code> Day-over-day change <code>mp.ext.day_over_day(mp.sum(\"revenue\"))</code> <code>ext.week_over_week(metric)</code> Week-over-week change <code>mp.ext.week_over_week(mp.average(\"price\"))</code> <code>ext.stddev(metric, offset, n)</code> Standard deviation over window <code>mp.ext.stddev(mp.sum(\"sales\"), offset=0, n=7)</code>"},{"location":"#available-assertions","title":"Available Assertions","text":"Assertion Description Example <code>is_eq(value, tol)</code> Equals with tolerance <code>.is_eq(100, tol=0.01)</code> <code>is_between(min, max)</code> In range (inclusive) <code>.is_between(0, 100)</code> <code>is_positive()</code> Greater than zero <code>.is_positive()</code> <code>is_zero()</code> Equals zero <code>.is_zero()</code> <code>is_negative()</code> Less than zero <code>.is_negative()</code> <code>is_gt(val)</code> / <code>is_geq(val)</code> Greater than (or equal) <code>.is_gt(0.95)</code> <code>is_lt(val)</code> / <code>is_leq(val)</code> Less than (or equal) <code>.is_lt(0.05)</code> <code>noop()</code> No validation (collect only) <code>.noop()</code>"},{"location":"#license","title":"License","text":"<p>MIT License. See LICENSE for details.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API documentation for DQX (Data Quality Excellence).</p>"},{"location":"api-reference/#core-api","title":"Core API","text":""},{"location":"api-reference/#dataqualityvalidator","title":"DataQualityValidator","text":"<p>The main entry point for data validation.</p> <pre><code>from dqx import DataQualityValidator\n\nvalidator = DataQualityValidator(\n    name=\"MyValidator\",\n    description=\"Validates customer data\",\n    fail_fast=False,\n    parallel=True,\n)\n</code></pre>"},{"location":"api-reference/#parameters","title":"Parameters","text":"<ul> <li><code>name</code> (str, optional): Name of the validator instance</li> <li><code>description</code> (str, optional): Description of the validator's purpose</li> <li><code>fail_fast</code> (bool, default=False): Stop validation on first failure</li> <li><code>parallel</code> (bool, default=True): Enable parallel processing</li> </ul>"},{"location":"api-reference/#methods","title":"Methods","text":""},{"location":"api-reference/#validate","title":"validate()","text":"<p>Run validation checks on data.</p> <pre><code>results = validator.validate(data, checks, sample_size=None, context=None)\n</code></pre> <p>Parameters: - <code>data</code>: DataFrame, file path, or data source to validate - <code>checks</code>: List of Check objects or CheckGroup - <code>sample_size</code> (int, optional): Number of rows to sample - <code>context</code> (dict, optional): Additional context for validation</p> <p>Returns: <code>ValidationResults</code> object</p>"},{"location":"api-reference/#create_checks","title":"create_checks()","text":"<p>Create a check builder for fluent API.</p> <pre><code>checks = (\n    validator.create_checks(data).is_not_null(\"column1\").is_unique(\"column2\").build()\n)\n</code></pre>"},{"location":"api-reference/#check-classes","title":"Check Classes","text":""},{"location":"api-reference/#basecheck","title":"BaseCheck","text":"<p>Abstract base class for all checks.</p> <pre><code>class BaseCheck:\n    def __init__(self, name, description=None, severity=\"error\"):\n        self.name = name\n        self.description = description\n        self.severity = severity\n</code></pre>"},{"location":"api-reference/#built-in-checks","title":"Built-in Checks","text":""},{"location":"api-reference/#notnullcheck","title":"NotNullCheck","text":"<pre><code>from dqx.checks import NotNullCheck\n\ncheck = NotNullCheck(column=\"user_id\", name=\"User ID Required\", severity=\"critical\")\n</code></pre>"},{"location":"api-reference/#rangecheck","title":"RangeCheck","text":"<pre><code>from dqx.checks import RangeCheck\n\ncheck = RangeCheck(\n    column=\"age\", min_value=0, max_value=120, inclusive=True, name=\"Valid Age Range\"\n)\n</code></pre>"},{"location":"api-reference/#patterncheck","title":"PatternCheck","text":"<pre><code>from dqx.checks import PatternCheck\n\ncheck = PatternCheck(\n    column=\"email\", pattern=r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\", name=\"Valid Email Format\"\n)\n</code></pre>"},{"location":"api-reference/#uniquecheck","title":"UniqueCheck","text":"<pre><code>from dqx.checks import UniqueCheck\n\ncheck = UniqueCheck(\n    columns=[\"user_id\"], name=\"Unique User ID\"  # Can be single column or list\n)\n</code></pre>"},{"location":"api-reference/#checkbuilder-api","title":"CheckBuilder API","text":"<p>Fluent interface for building checks.</p> <pre><code>checks = (\n    CheckBuilder(df)\n    # Null checks\n    .is_not_null(\"column\")\n    .are_not_null([\"col1\", \"col2\"])\n    .has_no_nulls()\n    # Range checks\n    .is_between(\"age\", 0, 120)\n    .is_positive(\"amount\")\n    .is_negative(\"loss\")\n    .is_greater_than(\"score\", 50)\n    .is_less_than(\"cost\", 1000)\n    # Pattern checks\n    .matches_pattern(\"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n    .matches_date_format(\"date\", \"%Y-%m-%d\")\n    .has_length(\"zip_code\", 5)\n    .starts_with(\"product_code\", \"PRD\")\n    .ends_with(\"filename\", \".csv\")\n    # Uniqueness checks\n    .is_unique(\"id\")\n    .has_unique_combination([\"first_name\", \"last_name\"])\n    .has_no_duplicates()\n    # Statistical checks\n    .mean_between(\"score\", 70, 90)\n    .std_dev_less_than(\"variance\", 10)\n    .percentile_between(\"income\", 0.25, 10000, 50000)\n    # Build final check list\n    .build()\n)\n</code></pre>"},{"location":"api-reference/#validationresults","title":"ValidationResults","text":"<p>Results container with analysis methods.</p> <pre><code>class ValidationResults:\n    @property\n    def passed(self) -&gt; bool:\n        \"\"\"Whether all checks passed\"\"\"\n\n    @property\n    def failed_count(self) -&gt; int:\n        \"\"\"Number of failed checks\"\"\"\n\n    @property\n    def pass_rate(self) -&gt; float:\n        \"\"\"Percentage of passed checks\"\"\"\n\n    def summary(self) -&gt; dict:\n        \"\"\"Get summary statistics\"\"\"\n\n    def failed_checks(self) -&gt; List[CheckResult]:\n        \"\"\"Get only failed check results\"\"\"\n\n    def to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Convert results to DataFrame\"\"\"\n\n    def to_json(self, filepath: str = None) -&gt; str:\n        \"\"\"Export results as JSON\"\"\"\n\n    def to_html(self, filepath: str) -&gt; None:\n        \"\"\"Generate HTML report\"\"\"\n</code></pre>"},{"location":"api-reference/#data-sources","title":"Data Sources","text":""},{"location":"api-reference/#pandasdatasource","title":"PandasDataSource","text":"<pre><code>from dqx.sources import PandasDataSource\n\nsource = PandasDataSource(df)\n</code></pre>"},{"location":"api-reference/#sqldatasource","title":"SQLDataSource","text":"<pre><code>from dqx.sources import SQLDataSource\n\nsource = SQLDataSource(\n    connection_string=\"postgresql://user:pass@host/db\", query=\"SELECT * FROM table\"\n)\n</code></pre>"},{"location":"api-reference/#filedatasource","title":"FileDataSource","text":"<pre><code>from dqx.sources import FileDataSource\n\nsource = FileDataSource(filepath=\"data.csv\", format=\"csv\", **read_options)\n</code></pre>"},{"location":"api-reference/#clouddatasource","title":"CloudDataSource","text":"<pre><code>from dqx.sources import CloudDataSource\n\nsource = CloudDataSource(\n    uri=\"s3://bucket/path/data.parquet\", credentials=aws_credentials\n)\n</code></pre>"},{"location":"api-reference/#advanced-features","title":"Advanced Features","text":""},{"location":"api-reference/#custom-checks","title":"Custom Checks","text":"<p>Create custom validation logic.</p> <pre><code>from dqx import custom_check\n\n\n@custom_check\ndef business_rule_check(df):\n    \"\"\"Custom validation function\"\"\"\n    return (df[\"status\"] == \"active\") &amp; (df[\"balance\"] &gt; 0)\n\n\n# Or as a class\nclass CustomBusinessCheck(BaseCheck):\n    def validate(self, df):\n        valid_mask = self._apply_business_logic(df)\n        return CheckResult(\n            check_name=self.name,\n            passed=valid_mask.all(),\n            failed_rows=df[~valid_mask].index.tolist(),\n        )\n</code></pre>"},{"location":"api-reference/#conditional-validation","title":"Conditional Validation","text":"<p>Apply checks conditionally.</p> <pre><code>from dqx import ConditionalCheck\n\ncheck = ConditionalCheck(\n    condition=lambda df: df[\"region\"] == \"US\",\n    check=PatternCheck(\"phone\", r\"^\\d{3}-\\d{3}-\\d{4}$\"),\n)\n</code></pre>"},{"location":"api-reference/#check-groups","title":"Check Groups","text":"<p>Organize related checks.</p> <pre><code>from dqx import CheckGroup\n\ncustomer_checks = CheckGroup(\"Customer Validation\")\ncustomer_checks.add_checks(\n    [\n        NotNullCheck(\"customer_id\"),\n        UniqueCheck(\"customer_id\"),\n        PatternCheck(\"email\", email_regex),\n    ]\n)\n\norder_checks = CheckGroup(\"Order Validation\")\norder_checks.add_checks([NotNullCheck(\"order_id\"), RangeCheck(\"amount\", min_value=0)])\n</code></pre>"},{"location":"api-reference/#validation-pipelines","title":"Validation Pipelines","text":"<p>Chain validation stages.</p> <pre><code>from dqx import ValidationPipeline\n\npipeline = ValidationPipeline()\n\n# Add stages\npipeline.add_stage(\"basic\", basic_checks, fail_fast=True)\npipeline.add_stage(\"business\", business_checks)\npipeline.add_stage(\"statistical\", stats_checks)\n\n# Run pipeline\nresults = pipeline.run(data)\n</code></pre>"},{"location":"api-reference/#configuration","title":"Configuration","text":""},{"location":"api-reference/#global-configuration","title":"Global Configuration","text":"<pre><code>from dqx import config\n\n# Set global defaults\nconfig.set_defaults(fail_fast=False, parallel=True, max_workers=4, sample_size=100000)\n\n# Configure logging\nconfig.set_logging(\n    level=\"INFO\", format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\n</code></pre>"},{"location":"api-reference/#validator-configuration","title":"Validator Configuration","text":"<pre><code># From file\nvalidator = DataQualityValidator.from_config(\"config.yaml\")\n\n# Or programmatically\nvalidator.configure(parallel=True, max_workers=8, memory_limit=\"4GB\")\n</code></pre>"},{"location":"api-reference/#metrics-and-monitoring","title":"Metrics and Monitoring","text":""},{"location":"api-reference/#metrics-collection","title":"Metrics Collection","text":"<pre><code>from dqx.metrics import MetricsCollector\n\ncollector = MetricsCollector()\nvalidator.add_metrics_collector(collector)\n\n# After validation\nmetrics = collector.get_metrics()\nprint(f\"Validation time: {metrics['duration_ms']}ms\")\nprint(f\"Rows processed: {metrics['rows_processed']}\")\n</code></pre>"},{"location":"api-reference/#export-formats","title":"Export Formats","text":"<pre><code># Prometheus format\nprometheus_metrics = results.to_prometheus()\n\n# StatsD format\nstatsd_metrics = results.to_statsd()\n\n# Custom format\ncustom_metrics = results.export_metrics(formatter=lambda m: f\"{m['name']}:{m['value']}\")\n</code></pre>"},{"location":"api-reference/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/#exception-types","title":"Exception Types","text":"<pre><code>from dqx.exceptions import (\n    ValidationError,\n    DataSourceError,\n    CheckConfigurationError,\n    ConnectionError,\n)\n\ntry:\n    results = validator.validate(data, checks)\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\nexcept DataSourceError as e:\n    print(f\"Data source error: {e}\")\n</code></pre>"},{"location":"api-reference/#error-recovery","title":"Error Recovery","text":"<pre><code># Retry logic\nvalidator.validate_with_retry(data, checks, max_retries=3, retry_delay=1.0)\n\n# Fallback handling\nresults = validator.validate_with_fallback(\n    primary_source=sql_source, fallback_source=file_source, checks=checks\n)\n</code></pre>"},{"location":"api-reference/#utilities","title":"Utilities","text":""},{"location":"api-reference/#data-profiling","title":"Data Profiling","text":"<pre><code>from dqx.utils import DataProfiler\n\nprofiler = DataProfiler()\nprofile = profiler.analyze(df)\n\nprint(profile.summary())\n# Shows: column types, null counts, unique values, etc.\n</code></pre>"},{"location":"api-reference/#check-generator","title":"Check Generator","text":"<pre><code>from dqx.utils import CheckGenerator\n\ngenerator = CheckGenerator()\nsuggested_checks = generator.suggest_checks(\n    df, include_statistical=True, confidence_level=0.95\n)\n</code></pre>"},{"location":"api-reference/#migration-tools","title":"Migration Tools","text":"<pre><code>from dqx.utils import migrate_rules\n\n# Migrate from other formats\ndqx_checks = migrate_rules(source=\"great_expectations\", rules_file=\"expectations.json\")\n</code></pre>"},{"location":"api-reference/#integration-apis","title":"Integration APIs","text":""},{"location":"api-reference/#rest-api-client","title":"REST API Client","text":"<pre><code>from dqx.api import DQXClient\n\nclient = DQXClient(base_url=\"https://dqx-api.company.com\", api_key=\"your-api-key\")\n\n# Submit validation job\njob_id = client.submit_validation(\n    dataset_id=\"customers\", check_suite_id=\"customer_checks\"\n)\n\n# Get results\nresults = client.get_results(job_id)\n</code></pre>"},{"location":"api-reference/#webhook-integration","title":"Webhook Integration","text":"<pre><code>from dqx.integrations import WebhookNotifier\n\nnotifier = WebhookNotifier(\n    url=\"https://hooks.company.com/dqx\", headers={\"Authorization\": \"Bearer token\"}\n)\n\nvalidator.add_notifier(notifier)\n</code></pre>"},{"location":"api-reference/#type-definitions","title":"Type Definitions","text":"<pre><code>from typing import TypedDict, List, Optional, Union\n\n\nclass CheckResult(TypedDict):\n    check_name: str\n    passed: bool\n    failed_count: int\n    failed_rows: List[int]\n    error_message: Optional[str]\n\n\nclass ValidationSummary(TypedDict):\n    total_checks: int\n    passed_checks: int\n    failed_checks: int\n    pass_rate: float\n    duration_ms: float\n\n\nDataSource = Union[pd.DataFrame, str, SQLDataSource, FileDataSource]\n</code></pre>"},{"location":"api-reference/#constants-and-enums","title":"Constants and Enums","text":"<pre><code>from dqx.constants import Severity, CheckType\n\n\nclass Severity(Enum):\n    INFO = \"info\"\n    WARNING = \"warning\"\n    ERROR = \"error\"\n    CRITICAL = \"critical\"\n\n\nclass CheckType(Enum):\n    COMPLETENESS = \"completeness\"\n    CONSISTENCY = \"consistency\"\n    ACCURACY = \"accuracy\"\n    UNIQUENESS = \"uniqueness\"\n    CUSTOM = \"custom\"\n</code></pre> <p>For more examples and detailed usage, see the User Guide and examples directory.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to DQX are documented here. This changelog is automatically included from the project's root CHANGELOG.md.</p>"},{"location":"changelog/#v055-2025-10-30","title":"v0.5.5 (2025-10-30)","text":""},{"location":"changelog/#feat","title":"Feat","text":"<ul> <li>Add CommercialDataSource with date filtering support (#17)</li> <li>add metric expiration methods to MetricDB (#15)</li> <li>ci: standardize workflows and add GitHub settings (#9)</li> </ul>"},{"location":"changelog/#fix","title":"Fix","text":"<ul> <li>resolve deprecation warning for invalid escape sequence (#16)</li> <li>orm: remove unnecessary lambda from uuid default value (#14)</li> <li>address Python special method protocol violation in test (#11)</li> <li>resolve GitHub release character limit issue (#8)</li> </ul>"},{"location":"changelog/#v054-2025-10-29","title":"v0.5.4 (2025-10-29)","text":""},{"location":"changelog/#fix_1","title":"Fix","text":"<ul> <li>resolve GitHub release character limit issue</li> <li>resolve release workflow issues and update dqlib documentation (#7)</li> </ul>"},{"location":"changelog/#v053-2025-10-29","title":"v0.5.3 (2025-10-29)","text":""},{"location":"changelog/#fix_2","title":"Fix","text":"<ul> <li>resolve release workflow issues and update dqlib documentation</li> </ul>"},{"location":"changelog/#v052-2025-10-29","title":"v0.5.2 (2025-10-29)","text":""},{"location":"changelog/#fix_3","title":"Fix","text":"<ul> <li>ci: remove docker-publish job from release workflow (#5)</li> </ul>"},{"location":"changelog/#v051-2025-10-29","title":"v0.5.1 (2025-10-29)","text":""},{"location":"changelog/#fix_4","title":"Fix","text":"<ul> <li>ci: remove docker-publish job from release workflow</li> </ul>"},{"location":"changelog/#v050-2025-10-29","title":"v0.5.0 (2025-10-29)","text":""},{"location":"changelog/#feat_1","title":"Feat","text":"<ul> <li>add version attribute to dqx module</li> </ul>"},{"location":"changelog/#fix_5","title":"Fix","text":"<ul> <li>ci: fix test-release job to handle PEP 668 system Python protection</li> <li>ci: remove redundant pull_request_target from release-drafter workflow</li> <li>ci: add pull-requests write permission to docs workflow</li> <li>ci: correct codecov action parameter from 'file' to 'files'</li> <li>ci: add --system flag to release workflow test installation</li> </ul> <p>For more detailed release notes, see the GitHub Releases page.</p>"},{"location":"ci-cd-setup/","title":"CI/CD Setup Guide for DQX","text":"<p>This guide documents the complete CI/CD setup for the DQX project, including all required secrets and configurations.</p>"},{"location":"ci-cd-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>GitHub CI/CD Setup Guide - Step-by-step setup instructions</li> <li>GitHub CI/CD Operations Guide - Daily operations and usage</li> </ul> <p>This document provides a technical overview and reference. For practical guides, see the documents above.</p>"},{"location":"ci-cd-setup/#github-actions-workflows","title":"GitHub Actions Workflows","text":""},{"location":"ci-cd-setup/#1-test-coverage-workflow","title":"1. Test &amp; Coverage Workflow","text":"<p>File: <code>.github/workflows/test.yml</code> - Runs on: Push to main/develop, pull requests - Tests multiple Python versions (3.11, 3.12, 3.13) - Generates coverage reports and badges - Includes type coverage reporting</p>"},{"location":"ci-cd-setup/#2-documentation-workflow","title":"2. Documentation Workflow","text":"<p>File: <code>.github/workflows/docs.yml</code> - Builds MkDocs documentation - Tests documentation build - Publishes to GitHub Pages (optional)</p>"},{"location":"ci-cd-setup/#3-release-workflow","title":"3. Release Workflow","text":"<p>File: <code>.github/workflows/release.yml</code> - Triggers on: GitHub releases - Builds Python packages (wheel and sdist) - Publishes to PyPI - Creates GitHub release artifacts</p>"},{"location":"ci-cd-setup/#4-security-scanning","title":"4. Security Scanning","text":"<p>File: <code>.github/workflows/codeql.yml</code> - Runs CodeQL analysis - Performs dependency review on PRs - Runs pip-audit for vulnerability scanning</p>"},{"location":"ci-cd-setup/#5-example-validation","title":"5. Example Validation","text":"<p>File: <code>.github/workflows/examples.yml</code> - Validates all example scripts - Ensures examples stay up-to-date</p>"},{"location":"ci-cd-setup/#required-secrets","title":"Required Secrets","text":""},{"location":"ci-cd-setup/#pypi-publishing","title":"PyPI Publishing","text":"<ul> <li><code>PYPI_API_TOKEN</code>: PyPI API token for package publishing</li> <li>Create at: https://pypi.org/manage/account/token/</li> <li>Scope: Can upload to project \"dqx\"</li> </ul>"},{"location":"ci-cd-setup/#test-pypi-optional","title":"Test PyPI (Optional)","text":"<ul> <li><code>TEST_PYPI_API_TOKEN</code>: Test PyPI API token</li> <li>Create at: https://test.pypi.org/manage/account/token/</li> <li>Use for testing releases before production</li> </ul>"},{"location":"ci-cd-setup/#github-pages-optional","title":"GitHub Pages (Optional)","text":"<ul> <li><code>GITHUB_TOKEN</code>: Automatically provided by GitHub Actions</li> <li>No setup required</li> <li>Used for publishing documentation</li> </ul>"},{"location":"ci-cd-setup/#google-analytics-optional","title":"Google Analytics (Optional)","text":"<ul> <li><code>GOOGLE_ANALYTICS_KEY</code>: Google Analytics tracking ID</li> <li>Format: <code>G-XXXXXXXXXX</code></li> <li>Used in MkDocs for documentation analytics</li> </ul>"},{"location":"ci-cd-setup/#external-services","title":"External Services","text":""},{"location":"ci-cd-setup/#1-readthedocs","title":"1. ReadTheDocs","text":"<p>Configuration: <code>.readthedocs.yml</code> - Sign up at: https://readthedocs.org - Import your GitHub repository - Documentation will be available at: https://dqx.readthedocs.io</p>"},{"location":"ci-cd-setup/#2-coderabbit","title":"2. CodeRabbit","text":"<p>Configuration: <code>.coderabbit.yaml</code> - Install from: https://github.com/marketplace/coderabbit - Provides AI-powered code reviews - No additional configuration needed</p>"},{"location":"ci-cd-setup/#3-dependabot","title":"3. Dependabot","text":"<p>Configuration: <code>.github/dependabot.yml</code> - Automatically enabled for GitHub repositories - Creates PRs for dependency updates - Review and merge security updates promptly</p>"},{"location":"ci-cd-setup/#4-release-drafter","title":"4. Release Drafter","text":"<p>Configuration: <code>.github/release-drafter.yml</code> - Automatically creates draft releases - Categorizes changes based on PR labels - Updates release notes with each merge to main</p>"},{"location":"ci-cd-setup/#setting-up-secrets","title":"Setting Up Secrets","text":""},{"location":"ci-cd-setup/#via-github-web-interface","title":"Via GitHub Web Interface","text":"<ol> <li>Go to Settings \u2192 Secrets and variables \u2192 Actions</li> <li>Click \"New repository secret\"</li> <li>Add each secret with its name and value</li> </ol>"},{"location":"ci-cd-setup/#via-github-cli","title":"Via GitHub CLI","text":"<pre><code># Install GitHub CLI\nbrew install gh  # macOS\n# or visit: https://cli.github.com/\n\n# Authenticate\ngh auth login\n\n# Add secrets\ngh secret set PYPI_API_TOKEN --body=\"pypi-...\"\ngh secret set TEST_PYPI_API_TOKEN --body=\"pypi-...\"\n</code></pre>"},{"location":"ci-cd-setup/#workflow-permissions","title":"Workflow Permissions","text":"<p>Ensure workflows have proper permissions:</p> <ol> <li>Go to Settings \u2192 Actions \u2192 General</li> <li>Under \"Workflow permissions\", select:</li> <li>\"Read and write permissions\"</li> <li>\"Allow GitHub Actions to create and approve pull requests\"</li> </ol>"},{"location":"ci-cd-setup/#branch-protection","title":"Branch Protection","text":"<p>Recommended branch protection rules for <code>main</code>:</p> <ol> <li>Require pull request reviews</li> <li>Require status checks:</li> <li><code>test (3.11)</code> - Main test suite</li> <li><code>analyze</code> - CodeQL security</li> <li><code>docs</code> - Documentation build</li> <li>Include administrators</li> <li>Allow force pushes (only for admins)</li> </ol>"},{"location":"ci-cd-setup/#local-development","title":"Local Development","text":""},{"location":"ci-cd-setup/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<pre><code># Install pre-commit hooks\npre-commit install\n\n# Run hooks manually\nuv run hooks --all\n\n# Skip specific hooks\nSKIP=mypy git commit -m \"...\"\n</code></pre>"},{"location":"ci-cd-setup/#testing-workflows-locally","title":"Testing Workflows Locally","text":"<pre><code># Install act (GitHub Actions local runner)\nbrew install act  # macOS\n\n# Run specific workflow\nact -W .github/workflows/test.yml\n\n# Run with secrets\nact -W .github/workflows/release.yml --secret-file .secrets\n</code></pre>"},{"location":"ci-cd-setup/#monitoring-maintenance","title":"Monitoring &amp; Maintenance","text":""},{"location":"ci-cd-setup/#github-actions-dashboard","title":"GitHub Actions Dashboard","text":"<ul> <li>Monitor at: <code>https://github.com/&lt;owner&gt;/dqx/actions</code></li> <li>Set up notifications for failed workflows</li> <li>Review workflow run times and optimize if needed</li> </ul>"},{"location":"ci-cd-setup/#dependency-updates","title":"Dependency Updates","text":"<ul> <li>Review Dependabot PRs weekly</li> <li>Run security audits: <code>uv run pip-audit</code></li> <li>Keep GitHub Actions versions updated</li> </ul>"},{"location":"ci-cd-setup/#documentation","title":"Documentation","text":"<ul> <li>Verify ReadTheDocs builds after each release</li> <li>Check for broken links: <code>mkdocs serve --strict</code></li> <li>Update screenshots and examples regularly</li> </ul>"},{"location":"ci-cd-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ci-cd-setup/#common-issues","title":"Common Issues","text":"<ol> <li>PyPI Upload Fails</li> <li>Verify API token has upload permissions</li> <li>Check package version isn't already published</li> <li> <p>Ensure package builds locally: <code>uv build</code></p> </li> <li> <p>Documentation Build Fails</p> </li> <li>Check MkDocs configuration: <code>mkdocs build --strict</code></li> <li>Verify all referenced files exist</li> <li> <p>Check for Python version compatibility</p> </li> <li> <p>Tests Fail on CI but Pass Locally</p> </li> <li>Check for environment differences</li> <li>Verify all test dependencies are installed</li> <li> <p>Look for timing-dependent tests</p> </li> <li> <p>Coverage Reports Not Updating</p> </li> <li>Ensure coverage files are generated</li> <li>Check GitHub token permissions</li> <li>Verify badge URLs are correct</li> </ol>"},{"location":"ci-cd-setup/#release-process","title":"Release Process","text":"<ol> <li> <p>Prepare Release <pre><code># Update version in pyproject.toml\n# Update CHANGELOG.md\ngit commit -m \"chore: prepare release v0.4.0\"\ngit tag v0.4.0\ngit push origin main --tags\n</code></pre></p> </li> <li> <p>Create GitHub Release</p> </li> <li>Go to Releases \u2192 Draft a new release</li> <li>Choose tag <code>v0.4.0</code></li> <li>Release notes are auto-generated</li> <li> <p>Publish release</p> </li> <li> <p>Verify Deployment</p> </li> <li>Check PyPI: https://pypi.org/project/dqx/</li> <li>Verify docs: https://dqx.readthedocs.io</li> <li>Test installation: <code>pip install dqx==0.4.0</code></li> </ol>"},{"location":"ci-cd-setup/#security-considerations","title":"Security Considerations","text":"<ul> <li>Rotate API tokens annually</li> <li>Use environment-specific secrets</li> <li>Enable 2FA on PyPI and GitHub accounts</li> <li>Review security alerts promptly</li> <li>Keep workflows up-to-date</li> </ul>"},{"location":"ci-cd-setup/#contact-support","title":"Contact &amp; Support","text":"<p>For CI/CD issues: - Check GitHub Actions logs - Review workflow configuration - Open an issue with the <code>ci</code> label - Tag @phamducnam for urgent issues</p>"},{"location":"design/","title":"DQX Design Document","text":""},{"location":"design/#1-overview","title":"1. Overview","text":""},{"location":"design/#what-is-dqx","title":"What is DQX","text":"<p>DQX is a data quality analysis framework that enables developers to define and run data quality checks using native Python code. It provides a SQL-based backend for efficient computation and supports extensible metrics, validators, and data sources.</p>"},{"location":"design/#core-design-philosophy","title":"Core Design Philosophy","text":"<p>DQX prioritizes simplicity, composability, and performance: - Code over configuration: Define checks in Python, not through configuration - SQL-powered: Execute queries directly on data warehouses - Modular architecture: Extend with custom metrics and validators - Symbolic computation: Express complex business rules naturally</p>"},{"location":"design/#2-native-python-api-vs-configuration","title":"2. Native Python API vs Configuration","text":""},{"location":"design/#design-decision-code-over-config","title":"Design Decision: Code over Config","text":"<p>Unlike configuration-based systems that use YAML or JSON, DQX uses Python code as the primary interface for defining data quality checks. This fundamental design choice drives the entire architecture.</p>"},{"location":"design/#advantages","title":"Advantages","text":"<ul> <li>IDE support: Full autocomplete, type checking, and inline documentation</li> <li>Composable &amp; reusable functions: Build complex checks from simple components</li> <li>Version control friendly: Standard code review processes apply</li> <li>Dynamic check generation: Use loops, conditions, and functions to create checks programmatically</li> </ul>"},{"location":"design/#3-modular-extensible-architecture","title":"3. Modular &amp; Extensible Architecture","text":""},{"location":"design/#plugin-based-design","title":"Plugin-Based Design","text":"<p>DQX uses a protocol-based architecture that allows users to extend the framework without modifying core code.</p>"},{"location":"design/#extension-points","title":"Extension Points","text":"<ul> <li>Custom Metrics: Implement the <code>MetricSpec</code> protocol to create new metrics</li> <li>Custom Validators: Implement validation functions following the standard signature</li> <li>Custom Data Sources: Implement the <code>SqlDataSource</code> protocol for new data backends</li> <li>Custom SQL Dialects: Add support for database-specific SQL syntax</li> </ul>"},{"location":"design/#4-symbolic-metrics","title":"4. Symbolic Metrics","text":""},{"location":"design/#how-symbolic-metrics-work","title":"How Symbolic Metrics Work","text":"<p>Metrics in DQX are symbolic expressions powered by SymPy, Python's symbolic mathematics library. The framework evaluates metrics by collecting symbol values through SQL queries at execution time.</p>"},{"location":"design/#key-advantages","title":"Key Advantages","text":"<ul> <li>Mathematical operations on metrics: Combine metrics using any SymPy functions</li> <li>Cross-datasource validation: Combine metrics from different data sources in a single expression</li> <li>Lazy evaluation: SQL generation happens only when needed</li> <li>Declarative expressions: Write business rules as mathematical formulas</li> </ul>"},{"location":"design/#5-sql-backend-architecture","title":"5. SQL Backend Architecture","text":""},{"location":"design/#why-sql-over-spark","title":"Why SQL over Spark","text":"<p>DQX uses SQL as its computation backend instead of distributed frameworks like Spark:</p> <ul> <li>Faster execution for single-node operations: Direct SQL execution without cluster overhead</li> <li>No Spark cluster required: Simpler infrastructure and lower operational costs</li> <li>Lower operational complexity: No JVM tuning or cluster management</li> <li>Rich analytical functions: Leverage database-native window functions and aggregations</li> </ul>"},{"location":"design/#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Single-pass computation for multiple metrics for multiple days.</li> <li>Efficient CTE-based query generation</li> </ul>"},{"location":"design/#6-severity-levels","title":"6. Severity Levels","text":""},{"location":"design/#p0-p3-definitions","title":"P0-P3 Definitions","text":"<ul> <li>P0 (Crisis): Data corruption or complete failure requiring immediate intervention</li> <li>P1 (Major): Significant issues affecting data reliability and business decisions</li> <li>P2 (Degraded): Quality degradation that needs investigation but not immediate action</li> <li>P3 (Minor Noise): Informational alerts for monitoring trends and anomalies</li> </ul>"},{"location":"design/#7-api-reference-supported-operations","title":"7. API Reference &amp; Supported Operations","text":""},{"location":"design/#supported-dialects","title":"Supported Dialects","text":"Dialect Description DuckDB Default dialect, in-memory analytical database BigQuery Google Cloud data warehouse PyArrow Arrow tables via DuckDB integration"},{"location":"design/#supported-metrics","title":"Supported Metrics","text":"Metric Method Description Row Count <code>num_rows</code> Total number of rows First <code>first</code> First value in column Average <code>average</code> Mean value of column Sum <code>sum</code> Sum of column values Minimum <code>minimum</code> Minimum value Maximum <code>maximum</code> Maximum value Variance <code>variance</code> Statistical variance Null Count <code>null_count</code> Count of null values Duplicate Count <code>duplicate_count</code> Count of duplicate rows"},{"location":"design/#assertion-methods","title":"Assertion Methods","text":"Method Description <code>is_eq</code> Assert equals with tolerance <code>is_gt</code> Assert greater than <code>is_lt</code> Assert less than <code>is_geq</code> Assert greater than or equal to <code>is_leq</code> Assert less than or equal to <code>is_between</code> Assert in range (inclusive) <code>is_positive</code> Assert value &gt; 0 <code>is_negative</code> Assert value &lt; 0 <code>is_zero</code> Assert value is effectively zero <code>within_tol</code> Assert within relative or absolute tolerance"},{"location":"dqguard-to-dqx-comparison/","title":"DQGuard to DQX: Evolution of Data Quality at Scale","text":""},{"location":"dqguard-to-dqx-comparison/#executive-summary","title":"Executive Summary","text":"<p>DQX represents the next generation of data quality tooling, evolving from DQGuard's configuration-based approach to a code-first framework. While DQGuard pioneered automated quality monitoring through JSON configurations, DQX advances the field with mathematical expressions, type safety, and modern architecture.</p> <p>This document guides teams through understanding the evolution, key improvements, and migration considerations.</p>"},{"location":"dqguard-to-dqx-comparison/#the-evolution-story","title":"The Evolution Story","text":""},{"location":"dqguard-to-dqx-comparison/#where-we-started-dqguard","title":"Where We Started: DQGuard","text":"<p>DQGuard solved critical problems: - High overhead in quality monitoring across teams - Need for long-term reliability measurement - Slow incident response times - Unreliable business-critical data</p> <p>The solution: JSON-based configurations that automated metric collection and validation.</p>"},{"location":"dqguard-to-dqx-comparison/#where-were-going-dqx","title":"Where We're Going: DQX","text":"<p>DQX addresses modern challenges: - Complex validation logic requiring mathematical expressions - Efficient data processing through modern architecture - Developer productivity through type safety and IDE support - Flexible assertions beyond time-series patterns</p>"},{"location":"dqguard-to-dqx-comparison/#key-improvements","title":"Key Improvements","text":""},{"location":"dqguard-to-dqx-comparison/#1-from-configuration-to-code","title":"1. From Configuration to Code","text":"<p>DQGuard: Define checks in JSON <pre><code>{\n    \"name\": \"default.reservation_flatter\",\n    \"type\": \"table\",\n    \"metrics\": [\"num_rows\"],\n    \"validators\": [{\n        \"name\": \"is_geq\",\n        \"threshold\": 1000000\n    }]\n}\n</code></pre></p> <p>DQX: Express checks as Python functions <pre><code>@check(\"Reservations have sufficient volume\")\ndef validate_reservations(mp: MetricProvider, ctx: Context) -&gt; None:\n    ctx.assert_that(mp.num_rows()).where(name=\"Daily volume check\").is_geq(1000000)\n</code></pre></p> <p>Benefits: - Type checking catches errors before runtime - IDE autocompletion speeds development - Version control shows meaningful diffs - Reusable logic through standard Python patterns</p>"},{"location":"dqguard-to-dqx-comparison/#2-mathematical-expressions","title":"2. Mathematical Expressions","text":"<p>DQGuard: Fixed validator patterns <pre><code>{\n    \"validators\": [\"within_2_sd\", \"wow_change\"]\n}\n</code></pre></p> <p>DQX: Arbitrary mathematical assertions <pre><code># Revenue integrity check\ncalculated = mp.sum(\"price\") * mp.sum(\"quantity\")\nreported = mp.sum(\"revenue\")\nerror_rate = sp.Abs(calculated - reported) / reported\n\nctx.assert_that(error_rate).where(name=\"Revenue calculation accuracy\").is_lt(0.001)\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#3-processing-architecture","title":"3. Processing Architecture","text":"<p>DQGuard: - Spark-based processing - Separate metric collection and validation passes - Scales with cluster resources</p> <p>DQX: - DuckDB columnar engine - Single-pass optimization - Efficient query execution</p>"},{"location":"dqguard-to-dqx-comparison/#4-developer-experience","title":"4. Developer Experience","text":"<p>DQGuard: <pre><code># Edit JSON\nvim lib/quality_check.json\n\n# Run in workflow\n&lt;action name=\"quality_check\"&gt;\n    &lt;sub-workflow&gt;\n        &lt;app-path&gt;${workflowsBaseDir}/data-quality-library/production-app&lt;/app-path&gt;\n    &lt;/sub-workflow&gt;\n&lt;/action&gt;\n</code></pre></p> <p>DQX: <pre><code># Write with IDE support\ndef validate_orders(mp: MetricProvider, ctx: Context) -&gt; None:\n    # Autocompletion shows available metrics\n    ctx.assert_that(mp.average(\"price\")).where(name=\"Price validation\").is_positive()\n\n\n# Run directly\nsuite = VerificationSuite([validate_orders], db)\nsuite.run(datasources, key)\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#feature-comparison","title":"Feature Comparison","text":"Feature DQGuard DQX Configuration JSON files Python code Type Safety Runtime validation Compile-time checking Metrics 15 predefined Extensible + custom Validators 12 patterns Unlimited expressions Engine Spark clusters DuckDB Processing Model Multiple passes Single pass Architecture Distributed Columnar engine IDE Support JSON schemas Full Python tooling Testing Manual validation Standard unit tests Debugging Log analysis Interactive debugging Deployment Oozie workflows Any Python environment"},{"location":"dqguard-to-dqx-comparison/#migration-guide","title":"Migration Guide","text":""},{"location":"dqguard-to-dqx-comparison/#assessment-phase","title":"Assessment Phase","text":"<ol> <li>Inventory Current Checks</li> <li>List all DQGuard configurations</li> <li>Identify custom validators</li> <li> <p>Note integration points</p> </li> <li> <p>Complexity Analysis</p> </li> <li>Simple threshold checks \u2192 Direct migration</li> <li>Time-series validators \u2192 May need custom logic</li> <li>Complex preprocessors \u2192 Evaluate alternatives</li> </ol>"},{"location":"dqguard-to-dqx-comparison/#migration-patterns","title":"Migration Patterns","text":""},{"location":"dqguard-to-dqx-comparison/#pattern-1-simple-metrics","title":"Pattern 1: Simple Metrics","text":"<p>DQGuard: <pre><code>{\n    \"metrics\": [\"num_rows\", \"null_count\"],\n    \"validators\": [{\"name\": \"is_geq\", \"threshold\": 0}]\n}\n</code></pre></p> <p>DQX: <pre><code>ctx.assert_that(mp.num_rows()).where(name=\"Has rows\").is_positive()\nctx.assert_that(mp.null_count(\"id\")).where(name=\"No null IDs\").is_zero()\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#pattern-2-time-series-validation","title":"Pattern 2: Time-Series Validation","text":"<p>DQGuard: <pre><code>{\n    \"validators\": [\"within_2_sd\"],\n    \"time_range\": \"7 days\"\n}\n</code></pre></p> <p>DQX: <pre><code># Collect historical metrics\nhistory = [mp.sum(\"revenue\", key=ctx.key.lag(i)) for i in range(1, 8)]\nmean = sum(history) / len(history)\nstd = calculate_std(history)\n\n# Apply validation\ncurrent = mp.sum(\"revenue\")\nz_score = abs(current - mean) / std\nctx.assert_that(z_score).where(name=\"Within 2 SD\").is_lt(2)\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#pattern-3-duplicate-detection","title":"Pattern 3: Duplicate Detection","text":"<p>DQGuard: <pre><code>{\n    \"metrics\": [{\n        \"name\": \"has_duplicate\",\n        \"columns\": [\"transaction_id\"]\n    }]\n}\n</code></pre></p> <p>DQX: <pre><code># Built-in duplicate detection\nduplicate_count = mp.duplicate_count(\"transaction_id\")\nctx.assert_that(duplicate_count).where(name=\"No duplicates\").is_zero()\n</code></pre></p>"},{"location":"dqguard-to-dqx-comparison/#coexistence-strategy","title":"Coexistence Strategy","text":"<p>Teams can run both systems during migration:</p> <ol> <li>Phase 1: Shadow Mode</li> <li>Keep DQGuard running</li> <li>Add DQX checks in parallel</li> <li> <p>Compare results</p> </li> <li> <p>Phase 2: Gradual Cutover</p> </li> <li>Migrate one dataset at a time</li> <li>Maintain critical DQGuard checks</li> <li> <p>Build confidence in DQX</p> </li> <li> <p>Phase 3: Full Migration</p> </li> <li>Retire DQGuard configurations</li> <li>Leverage DQX-only features</li> <li>Optimize for performance</li> </ol>"},{"location":"dqguard-to-dqx-comparison/#advanced-dqx-capabilities","title":"Advanced DQX Capabilities","text":""},{"location":"dqguard-to-dqx-comparison/#1-cross-dataset-validation","title":"1. Cross-Dataset Validation","text":"<pre><code>@check(\"Production matches staging\")\ndef compare_environments(mp: MetricProvider, ctx: Context) -&gt; None:\n    prod = mp.sum(\"revenue\", dataset=\"production\")\n    staging = mp.sum(\"revenue\", dataset=\"staging\")\n\n    ctx.assert_that(prod).where(name=\"Environment parity\").is_eq(staging, tol=0.01)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#2-custom-metric-extensions","title":"2. Custom Metric Extensions","text":"<pre><code># DQX supports custom metrics through extensions\nday_over_day = mp.ext.day_over_day(specs.Average(\"response_time\"))\nctx.assert_that(day_over_day).where(name=\"Response time trend\").is_between(-0.1, 0.1)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#3-symbolic-mathematics","title":"3. Symbolic Mathematics","text":"<pre><code># Complex business rules as mathematical expressions\nmargin = (mp.sum(\"revenue\") - mp.sum(\"cost\")) / mp.sum(\"revenue\")\ntarget_margin = 0.3\n\nctx.assert_that(margin).where(name=\"Profit margin target\", severity=\"P0\").is_geq(\n    target_margin\n)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#best-practices","title":"Best Practices","text":""},{"location":"dqguard-to-dqx-comparison/#1-name-every-assertion","title":"1. Name Every Assertion","text":"<pre><code># Good: Clear, specific names\nctx.assert_that(metric).where(name=\"Daily revenue within 10% of average\")\n\n# Avoid: Generic names\nctx.assert_that(metric).where(name=\"Revenue check\")\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#2-group-related-checks","title":"2. Group Related Checks","text":"<pre><code>@check(\"Payment integrity\", datasets=[\"payments\"])\ndef validate_payments(mp: MetricProvider, ctx: Context) -&gt; None:\n    # All payment validations in one check\n    ctx.assert_that(mp.null_count(\"payment_id\")).where(\n        name=\"Payment ID completeness\"\n    ).is_zero()\n\n    ctx.assert_that(mp.average(\"amount\")).where(\n        name=\"Average payment reasonable\"\n    ).is_between(10, 1000)\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#3-use-severity-levels","title":"3. Use Severity Levels","text":"<pre><code>ctx.assert_that(critical_metric).where(\n    name=\"Critical business metric\", severity=\"P0\"  # Pages on-call\n).is_positive()\n\nctx.assert_that(quality_metric).where(\n    name=\"Data quality indicator\", severity=\"P2\"  # Daily review\n).is_within_range()\n</code></pre>"},{"location":"dqguard-to-dqx-comparison/#conclusion","title":"Conclusion","text":"<p>DQX builds upon DQGuard's foundation while addressing modern data quality challenges. The evolution from configuration to code enables:</p> <ul> <li>Better expressiveness through mathematical assertions</li> <li>Modern architecture with DuckDB's columnar processing</li> <li>Enhanced productivity with type safety and IDE support</li> <li>Greater flexibility for complex business rules</li> </ul> <p>Teams should evaluate their current DQGuard usage and plan migration based on complexity and criticality. The coexistence strategy allows gradual adoption while maintaining quality coverage.</p> <p>For teams starting fresh, DQX provides a modern, flexible solution for data quality validation.</p>"},{"location":"github-cicd-operations-guide/","title":"GitHub CI/CD Operations Guide","text":"<p>This guide covers daily operations and interactions with the CI/CD system after initial setup.</p>"},{"location":"github-cicd-operations-guide/#daily-development-workflow","title":"Daily Development Workflow","text":""},{"location":"github-cicd-operations-guide/#working-with-pre-commit-hooks","title":"Working with Pre-commit Hooks","text":"<p>Pre-commit hooks run automatically before each commit to catch issues early.</p>"},{"location":"github-cicd-operations-guide/#running-hooks-locally","title":"Running Hooks Locally","text":"<pre><code># Run all hooks on staged files\nuv run hooks\n\n# Run all hooks on all files\nuv run hooks --all\n\n# Run specific hook\nuv run hooks mypy\n\n# See available options\nuv run hooks --help\n</code></pre>"},{"location":"github-cicd-operations-guide/#common-hook-failures-and-fixes","title":"Common Hook Failures and Fixes","text":"<p>Ruff formatting issues: <pre><code># Auto-fix formatting\nuv run ruff check --fix .\nuv run ruff format .\n\n# Then stage the fixes\ngit add -u\n</code></pre></p> <p>Mypy type errors: - Add missing type hints - Fix type inconsistencies - Use <code># type: ignore[error-code]</code> sparingly with justification</p> <p>Trailing whitespace: - Most editors can auto-remove on save - The hook will fix automatically</p>"},{"location":"github-cicd-operations-guide/#bypassing-hooks-use-sparingly","title":"Bypassing Hooks (Use Sparingly)","text":"<pre><code># Skip all hooks - use only when necessary\ngit commit --no-verify -m \"emergency: fix critical bug\"\n\n# Skip specific hooks\nSKIP=mypy git commit -m \"wip: debugging in progress\"\n</code></pre>"},{"location":"github-cicd-operations-guide/#commit-standards","title":"Commit Standards","text":"<p>Follow conventional commits for clear history and automatic versioning.</p>"},{"location":"github-cicd-operations-guide/#format","title":"Format","text":"<pre><code>type(scope): subject\n\nbody (optional)\n\nfooter (optional)\n</code></pre>"},{"location":"github-cicd-operations-guide/#common-types","title":"Common Types","text":"<ul> <li><code>feat</code>: New feature (triggers minor version)</li> <li><code>fix</code>: Bug fix (triggers patch version)</li> <li><code>docs</code>: Documentation only</li> <li><code>style</code>: Code style (no logic changes)</li> <li><code>refactor</code>: Code restructure</li> <li><code>perf</code>: Performance improvement</li> <li><code>test</code>: Test additions/fixes</li> <li><code>chore</code>: Maintenance tasks</li> </ul>"},{"location":"github-cicd-operations-guide/#examples","title":"Examples","text":"<pre><code>git commit -m \"feat(analyzer): add batch processing support\"\ngit commit -m \"fix(validator): handle null values correctly\"\ngit commit -m \"docs: update API examples\"\n</code></pre>"},{"location":"github-cicd-operations-guide/#creating-pull-requests","title":"Creating Pull Requests","text":"<ol> <li> <p>Create feature branch: <pre><code>git checkout -b feat/your-feature-name\n</code></pre></p> </li> <li> <p>Push and create PR: <pre><code>git push -u origin feat/your-feature-name\ngh pr create --title \"feat: your feature\" --body \"Description\"\n</code></pre></p> </li> <li> <p>Required elements:</p> </li> <li>Descriptive title following commit conventions</li> <li>Clear description of changes</li> <li>Link to related issue (if any)</li> <li>Screenshots for UI changes</li> </ol>"},{"location":"github-cicd-operations-guide/#code-review-process","title":"Code Review Process","text":""},{"location":"github-cicd-operations-guide/#understanding-coderabbit-ai-reviews","title":"Understanding CodeRabbit AI Reviews","text":"<p>CodeRabbit automatically reviews PRs within 5 minutes.</p>"},{"location":"github-cicd-operations-guide/#review-components","title":"Review Components","text":"<ol> <li>Summary Section</li> <li>High-level overview</li> <li>Key changes identified</li> <li> <p>Potential issues flagged</p> </li> <li> <p>Detailed Comments</p> </li> <li>Line-by-line suggestions</li> <li>Best practice violations</li> <li>Security concerns</li> <li> <p>Performance issues</p> </li> <li> <p>Review Status</p> </li> <li>\u2705 Approved: No critical issues</li> <li>\ud83d\udcac Comments: Suggestions provided</li> <li>\ud83d\udd04 Changes requested: Critical issues found</li> </ol>"},{"location":"github-cicd-operations-guide/#interacting-with-coderabbit","title":"Interacting with CodeRabbit","text":"<p>Common commands in PR comments: <pre><code>@coderabbitai review\n@coderabbitai resolve\n@coderabbitai ignore\n@coderabbitai help\n</code></pre></p> <p>Responding to suggestions: 1. Accept suggestion: Click \"Accept\" on the comment 2. Dismiss: Reply explaining why it's not applicable 3. Ask for clarification: Reply with your question</p>"},{"location":"github-cicd-operations-guide/#customizing-reviews","title":"Customizing Reviews","text":"<p>Edit <code>.coderabbit.yaml</code> to adjust: - Review strictness - Custom patterns - Excluded paths - Project-specific rules</p>"},{"location":"github-cicd-operations-guide/#handling-review-feedback","title":"Handling Review Feedback","text":"<ol> <li>Address all comments - Even if just to explain why not changed</li> <li>Batch fixes - Make all changes before requesting re-review</li> <li>Update PR description - Note what feedback was addressed</li> <li>Request re-review - Use GitHub's re-review feature</li> </ol>"},{"location":"github-cicd-operations-guide/#managing-dependencies","title":"Managing Dependencies","text":""},{"location":"github-cicd-operations-guide/#dependabot-pull-requests","title":"Dependabot Pull Requests","text":"<p>Dependabot creates PRs for dependency updates automatically.</p>"},{"location":"github-cicd-operations-guide/#understanding-update-prs","title":"Understanding Update PRs","text":"<p>PR Title Format: <pre><code>Bump package-name from 1.2.3 to 1.2.4\n</code></pre></p> <p>PR includes: - Changelog excerpts - Commit list - Compatibility score - Release notes link</p>"},{"location":"github-cicd-operations-guide/#review-process","title":"Review Process","text":"<ol> <li>Check CI status - All tests must pass</li> <li>Review changelog - Look for breaking changes</li> <li>Check compatibility - Verify with your Python versions</li> <li>Test locally if needed: <pre><code>gh pr checkout 123\nuv sync\nuv run pytest tests/\n</code></pre></li> </ol>"},{"location":"github-cicd-operations-guide/#dependabot-commands","title":"Dependabot Commands","text":"<p>Use these in PR comments:</p> <pre><code>@dependabot rebase\n@dependabot recreate\n@dependabot merge\n@dependabot squash and merge\n@dependabot cancel merge\n@dependabot reopen\n@dependabot close\n@dependabot ignore this major version\n@dependabot ignore this minor version\n@dependabot ignore this dependency\n</code></pre>"},{"location":"github-cicd-operations-guide/#merge-strategies","title":"Merge Strategies","text":"<p>Security updates: Merge immediately after tests pass</p> <p>Minor updates: - Group weekly - Test together - Merge as batch</p> <p>Major updates: - Test thoroughly - Check migration guides - Consider compatibility</p>"},{"location":"github-cicd-operations-guide/#managing-multiple-updates","title":"Managing Multiple Updates","text":"<pre><code># List all Dependabot PRs\ngh pr list --label dependencies\n\n# Bulk operations with GitHub CLI\ngh pr list --label dependencies --json number --jq '.[].number' | \\\n  xargs -I {} gh pr comment {} --body \"@dependabot rebase\"\n</code></pre>"},{"location":"github-cicd-operations-guide/#release-process","title":"Release Process","text":""},{"location":"github-cicd-operations-guide/#preparing-a-release","title":"Preparing a Release","text":"<ol> <li> <p>Update version in <code>pyproject.toml</code>: <pre><code>version = \"0.4.0\"\n</code></pre></p> </li> <li> <p>Update CHANGELOG.md:</p> </li> <li>Add release date</li> <li>Review all changes</li> <li> <p>Highlight breaking changes</p> </li> <li> <p>Create release PR: <pre><code>git checkout -b release/v0.4.0\ngit add pyproject.toml CHANGELOG.md\ngit commit -m \"chore: prepare release v0.4.0\"\ngit push -u origin release/v0.4.0\ngh pr create --title \"Release v0.4.0\" --label release\n</code></pre></p> </li> </ol>"},{"location":"github-cicd-operations-guide/#using-release-drafter","title":"Using Release Drafter","text":"<p>Release Drafter automatically maintains draft release notes.</p>"},{"location":"github-cicd-operations-guide/#how-it-works","title":"How It Works","text":"<ol> <li>Monitors merged PRs - Collects since last release</li> <li>Categorizes by labels - Groups changes by type</li> <li>Determines version - Based on change types</li> <li>Updates draft - After each PR merge</li> </ol>"},{"location":"github-cicd-operations-guide/#pr-labels-for-versioning","title":"PR Labels for Versioning","text":"<p>Major version (breaking changes): - <code>breaking-change</code> - <code>breaking</code></p> <p>Minor version (features): - <code>feature</code> - <code>enhancement</code> - <code>feat</code></p> <p>Patch version (fixes): - <code>fix</code> - <code>bug</code> - <code>perf</code> - <code>docs</code></p>"},{"location":"github-cicd-operations-guide/#editing-release-notes","title":"Editing Release Notes","text":"<ol> <li>Go to Releases \u2192 Draft release</li> <li>Review auto-generated notes</li> <li>Add highlights section</li> <li>Include migration guide for breaking changes</li> <li>Preview before publishing</li> </ol>"},{"location":"github-cicd-operations-guide/#publishing-a-release","title":"Publishing a Release","text":"<ol> <li>Final checks:</li> <li>All CI passes on main</li> <li>Version updated in code</li> <li> <p>Documentation updated</p> </li> <li> <p>Create and push tag: <pre><code>git checkout main\ngit pull origin main\ngit tag v0.4.0\ngit push origin v0.4.0\n</code></pre></p> </li> <li> <p>Publish GitHub release:</p> </li> <li>Go to draft release</li> <li>Select the tag</li> <li>Review notes one more time</li> <li> <p>Click \"Publish release\"</p> </li> <li> <p>Monitor deployment:</p> </li> <li>Check Actions tab for release workflow</li> <li>Verify PyPI upload</li> <li>Test installation: <code>pip install dqx==0.4.0</code></li> </ol>"},{"location":"github-cicd-operations-guide/#post-release-tasks","title":"Post-Release Tasks","text":"<ol> <li> <p>Verify deployment: <pre><code># Test from PyPI\npip install dqx==0.4.0\npython -c \"import dqx; print(dqx.__version__)\"\n</code></pre></p> </li> <li> <p>Update documentation:</p> </li> <li>Check ReadTheDocs built new version</li> <li>Update version references</li> <li> <p>Announce in relevant channels</p> </li> <li> <p>Create next development cycle: <pre><code># Bump to next dev version\n# Update pyproject.toml to 0.5.0-dev\ngit commit -m \"chore: bump version to 0.5.0-dev\"\n</code></pre></p> </li> </ol>"},{"location":"github-cicd-operations-guide/#monitoring-cicd","title":"Monitoring CI/CD","text":""},{"location":"github-cicd-operations-guide/#github-actions-dashboard","title":"GitHub Actions Dashboard","text":"<p>Access at: <code>https://github.com/&lt;owner&gt;/dqx/actions</code></p>"},{"location":"github-cicd-operations-guide/#key-metrics","title":"Key Metrics","text":"<ul> <li>Success rate by workflow</li> <li>Average run time</li> <li>Recent failures</li> <li>Usage minutes</li> </ul>"},{"location":"github-cicd-operations-guide/#workflow-management","title":"Workflow Management","text":"<p>Re-run failed jobs: 1. Click on failed workflow run 2. Click \"Re-run failed jobs\" 3. Or \"Re-run all jobs\" if needed</p> <p>Cancel stuck workflows: <pre><code>gh run list --status in_progress\ngh run cancel &lt;run-id&gt;\n</code></pre></p> <p>Download artifacts: <pre><code>gh run download &lt;run-id&gt; -n &lt;artifact-name&gt;\n</code></pre></p>"},{"location":"github-cicd-operations-guide/#debugging-ci-failures","title":"Debugging CI Failures","text":"<ol> <li>Check summary - Look for error annotations</li> <li>Expand failed step - Find exact error</li> <li>Download logs - For detailed analysis</li> <li>Run locally - Try to reproduce</li> </ol>"},{"location":"github-cicd-operations-guide/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Test failures on CI only: - Check for environment differences - Look for timing issues - Verify test data availability</p> <p>Timeout errors: - Increase timeout in workflow - Split long-running tests - Add progress output</p> <p>Permission errors: - Check token permissions - Verify secrets are set - Review repository settings</p>"},{"location":"github-cicd-operations-guide/#quick-reference","title":"Quick Reference","text":""},{"location":"github-cicd-operations-guide/#essential-commands","title":"Essential Commands","text":"<pre><code># Pre-commit hooks\nuv run hooks --all           # Run all hooks\nuv run hooks --help          # Show options\n\n# GitHub CLI\ngh pr create                 # Create PR\ngh pr list                   # List PRs\ngh pr checks                 # Show CI status\ngh workflow run              # Trigger workflow\n\n# Git\ngit tag v0.4.0              # Create version tag\ngit push origin v0.4.0      # Push tag\n\n# Python/uv\nuv sync                     # Install dependencies\nuv run pytest               # Run tests\nuv build                    # Build package\n</code></pre>"},{"location":"github-cicd-operations-guide/#status-badge-urls","title":"Status Badge URLs","text":"<pre><code>![Tests](https://github.com/&lt;owner&gt;/dqx/workflows/tests/badge.svg)\n![Coverage](https://github.com/&lt;owner&gt;/dqx/coverage.svg)\n![Docs](https://readthedocs.org/projects/dqx/badge/)\n![PyPI](https://badge.fury.io/py/dqx.svg)\n</code></pre>"},{"location":"github-cicd-operations-guide/#useful-links","title":"Useful Links","text":"<ul> <li>GitHub Actions Docs</li> <li>Conventional Commits</li> <li>CodeRabbit Docs</li> <li>Dependabot Docs</li> </ul> <p>For initial setup instructions, see the GitHub CI/CD Setup Guide.</p>"},{"location":"github-cicd-setup-guide/","title":"GitHub CI/CD Setup Guide","text":"<p>This guide walks through setting up GitHub Actions CI/CD for the DQX project.</p>"},{"location":"github-cicd-setup-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>GitHub account with repository access</li> <li>PyPI account for package publishing</li> <li>Basic understanding of GitHub Actions</li> </ul>"},{"location":"github-cicd-setup-guide/#step-1-create-pypi-account-and-api-token","title":"Step 1: Create PyPI Account and API Token","text":""},{"location":"github-cicd-setup-guide/#create-pypi-account","title":"Create PyPI Account","text":"<ol> <li>Visit pypi.org</li> <li>Click \"Register\"</li> <li>Fill the registration form:</li> <li>Username: Choose a unique identifier</li> <li>Email: Use your primary email</li> <li>Password: Create a strong password</li> <li>Verify your email address</li> </ol>"},{"location":"github-cicd-setup-guide/#generate-api-token","title":"Generate API Token","text":"<ol> <li>Log into PyPI</li> <li>Go to Account Settings \u2192 API tokens</li> <li>Click \"Add API token\"</li> <li>Configure the token:</li> <li>Token name: <code>github-actions-dqx</code></li> <li>Scope: \"Project: dqx\" (or \"Entire account\" for first release)</li> <li>Click \"Add token\"</li> <li>Copy the token immediately - it shows only once</li> <li>Format: <code>pypi-AgEIcHlwaS5vcmcCJGE4ZjY5...</code></li> <li>Save it securely</li> </ol>"},{"location":"github-cicd-setup-guide/#set-up-test-pypi-optional-but-recommended","title":"Set Up Test PyPI (Optional but Recommended)","text":"<ol> <li>Visit test.pypi.org</li> <li>Create a separate account (can use same email)</li> <li>Generate API token following same steps</li> <li>Use for testing releases before production</li> </ol>"},{"location":"github-cicd-setup-guide/#step-2-configure-github-repository-secrets","title":"Step 2: Configure GitHub Repository Secrets","text":""},{"location":"github-cicd-setup-guide/#add-pypi-token","title":"Add PyPI Token","text":"<ol> <li>Go to your GitHub repository</li> <li>Navigate to Settings \u2192 Secrets and variables \u2192 Actions</li> <li>Click \"New repository secret\"</li> <li>Add the secret:</li> <li>Name: <code>PYPI_API_TOKEN</code></li> <li>Value: Paste your PyPI token</li> <li>Click \"Add secret\"</li> </ol>"},{"location":"github-cicd-setup-guide/#add-test-pypi-token-optional","title":"Add Test PyPI Token (Optional)","text":"<p>Repeat the above with: - Name: <code>TEST_PYPI_API_TOKEN</code> - Value: Your Test PyPI token</p>"},{"location":"github-cicd-setup-guide/#verify-secrets","title":"Verify Secrets","text":"<p>Your secrets page should show: - <code>PYPI_API_TOKEN</code> (updated just now) - <code>TEST_PYPI_API_TOKEN</code> (updated just now)</p>"},{"location":"github-cicd-setup-guide/#step-3-set-up-readthedocs","title":"Step 3: Set Up ReadTheDocs","text":""},{"location":"github-cicd-setup-guide/#create-account","title":"Create Account","text":"<ol> <li>Visit readthedocs.org</li> <li>Sign up with GitHub OAuth (recommended) or create account</li> <li>Authorize ReadTheDocs to access your repositories</li> </ol>"},{"location":"github-cicd-setup-guide/#import-project","title":"Import Project","text":"<ol> <li>Click \"Import a Project\"</li> <li>Select your repository from the list</li> <li>Or click \"Import Manually\" and enter repo URL</li> <li>Configure project details:</li> <li>Name: <code>dqx</code></li> <li>Repository URL: <code>https://github.com/yourusername/dqx</code></li> <li>Repository type: Git</li> <li>Default branch: <code>main</code></li> <li>Click \"Next\"</li> </ol>"},{"location":"github-cicd-setup-guide/#configure-build","title":"Configure Build","text":"<ol> <li>In project dashboard, go to Admin \u2192 Advanced Settings</li> <li>Set Python configuration:</li> <li>Python interpreter: CPython 3.11</li> <li>Install method: pip</li> <li>Requirements file: Leave empty (using pyproject.toml)</li> <li>Enable these options:</li> <li>Build pull requests</li> <li>Public versions</li> <li>Single version docs (if you want /latest/ only)</li> <li>Save changes</li> </ol>"},{"location":"github-cicd-setup-guide/#first-build","title":"First Build","text":"<ol> <li>Go to Builds tab</li> <li>Click \"Build Version\"</li> <li>Monitor the build log</li> <li>Once successful, view docs at <code>https://dqx.readthedocs.io</code></li> </ol>"},{"location":"github-cicd-setup-guide/#webhook-setup-automatic","title":"Webhook Setup (Automatic)","text":"<p>ReadTheDocs automatically creates a webhook in your GitHub repo. Verify: 1. GitHub repo \u2192 Settings \u2192 Webhooks 2. Look for ReadTheDocs webhook 3. Should trigger on push events</p>"},{"location":"github-cicd-setup-guide/#step-4-install-github-apps","title":"Step 4: Install GitHub Apps","text":""},{"location":"github-cicd-setup-guide/#coderabbit","title":"CodeRabbit","text":"<ol> <li>Visit GitHub Marketplace - CodeRabbit</li> <li>Click \"Set up a plan\"</li> <li>Choose pricing plan (free tier available)</li> <li>Select repositories:</li> <li>Choose \"Only select repositories\"</li> <li>Select your DQX repository</li> <li>Complete installation</li> </ol> <p>CodeRabbit will automatically review PRs once installed.</p>"},{"location":"github-cicd-setup-guide/#dependabot-already-enabled","title":"Dependabot (Already Enabled)","text":"<p>Dependabot is automatically available. Ensure it's active: 1. Go to Settings \u2192 Security &amp; analysis 2. Enable:    - Dependency graph    - Dependabot alerts    - Dependabot security updates</p>"},{"location":"github-cicd-setup-guide/#release-drafter","title":"Release Drafter","text":"<p>The Release Drafter workflow is already configured. It will: - Auto-generate release notes from PRs - Categorize changes by labels - Create draft releases automatically</p>"},{"location":"github-cicd-setup-guide/#step-5-configure-github-actions-permissions","title":"Step 5: Configure GitHub Actions Permissions","text":""},{"location":"github-cicd-setup-guide/#repository-permissions","title":"Repository Permissions","text":"<ol> <li>Go to Settings \u2192 Actions \u2192 General</li> <li>Under \"Actions permissions\":</li> <li>Select \"Allow all actions and reusable workflows\"</li> <li>Under \"Workflow permissions\":</li> <li>Select \"Read and write permissions\"</li> <li>Check \"Allow GitHub Actions to create and approve pull requests\"</li> <li>Click \"Save\"</li> </ol>"},{"location":"github-cicd-setup-guide/#branch-protection","title":"Branch Protection","text":"<ol> <li>Go to Settings \u2192 Branches</li> <li>Click \"Add rule\"</li> <li>Configure protection for <code>main</code>:</li> <li>Branch name pattern: <code>main</code></li> <li>Enable:<ul> <li>Require pull request before merging</li> <li>Require status checks:</li> <li><code>test (3.11)</code></li> <li><code>analyze</code></li> <li><code>docs</code></li> <li>Require branches to be up to date</li> <li>Include administrators (optional)</li> </ul> </li> <li>Click \"Create\"</li> </ol>"},{"location":"github-cicd-setup-guide/#step-6-test-the-setup","title":"Step 6: Test the Setup","text":""},{"location":"github-cicd-setup-guide/#verify-workflows","title":"Verify Workflows","text":"<ol> <li> <p>Create a test branch:    <pre><code>git checkout -b test/ci-setup\n</code></pre></p> </li> <li> <p>Make a small change:    <pre><code>echo \"# Test\" &gt;&gt; test.md\ngit add test.md\ngit commit -m \"test: verify CI setup\"\ngit push origin test/ci-setup\n</code></pre></p> </li> <li> <p>Create a pull request</p> </li> <li>Watch the checks run:</li> <li>Tests should pass</li> <li>CodeRabbit should comment</li> <li>All status checks should be green</li> </ol>"},{"location":"github-cicd-setup-guide/#test-documentation-build","title":"Test Documentation Build","text":"<ol> <li> <p>Make a docs change:    <pre><code>echo \"Test content\" &gt;&gt; docs/test.md\ngit add docs/test.md\ngit commit -m \"docs: test documentation build\"\ngit push\n</code></pre></p> </li> <li> <p>Check ReadTheDocs:</p> </li> <li>Go to your project builds</li> <li>Verify build triggered and passed</li> </ol>"},{"location":"github-cicd-setup-guide/#test-release-process-dry-run","title":"Test Release Process (Dry Run)","text":"<ol> <li>Update version in <code>pyproject.toml</code></li> <li> <p>Create and push a tag:    <pre><code>git tag v0.3.1-rc1\ngit push origin v0.3.1-rc1\n</code></pre></p> </li> <li> <p>Check Actions tab for release workflow</p> </li> <li>Verify it would publish correctly (without creating release)</li> </ol>"},{"location":"github-cicd-setup-guide/#step-7-local-documentation-development","title":"Step 7: Local Documentation Development","text":""},{"location":"github-cicd-setup-guide/#install-mkdocs","title":"Install MkDocs","text":"<pre><code># In your project directory\nuv pip install mkdocs mkdocs-material mkdocstrings[python]\n</code></pre>"},{"location":"github-cicd-setup-guide/#run-documentation-server","title":"Run Documentation Server","text":"<pre><code># Start local server\nmkdocs serve\n\n# Output:\n# INFO - Building documentation...\n# INFO - Cleaning site directory\n# INFO - Documentation built in 2.34 seconds\n# INFO - Serving on http://127.0.0.1:8000\n</code></pre>"},{"location":"github-cicd-setup-guide/#live-development","title":"Live Development","text":"<ol> <li>Open browser to <code>http://localhost:8000</code></li> <li>Edit any markdown file in <code>docs/</code></li> <li>Save the file</li> <li>Browser auto-refreshes with changes</li> </ol>"},{"location":"github-cicd-setup-guide/#build-documentation","title":"Build Documentation","text":"<pre><code># Build static site\nmkdocs build\n\n# Output creates site/ directory\n# Upload site/ contents to any web server\n</code></pre>"},{"location":"github-cicd-setup-guide/#test-strict-mode","title":"Test Strict Mode","text":"<pre><code># Catch broken links and references\nmkdocs build --strict\n\n# Fails on warnings - same as CI\n</code></pre>"},{"location":"github-cicd-setup-guide/#preview-different-themes","title":"Preview Different Themes","text":"<p>Edit <code>mkdocs.yml</code>: <pre><code>theme:\n  name: material\n  palette:\n    scheme: slate  # Try 'default' for light\n</code></pre></p> <p>Save and see instant changes.</p>"},{"location":"github-cicd-setup-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"github-cicd-setup-guide/#pypi-upload-fails","title":"PyPI Upload Fails","text":"<p>Token scope too narrow: - First release needs \"Entire account\" scope - After first release, can limit to project</p> <p>Version already exists: - PyPI never allows reusing versions - Increment version in <code>pyproject.toml</code></p> <p>Authentication failed: - Verify secret name is exactly <code>PYPI_API_TOKEN</code> - Check token starts with <code>pypi-</code> - Regenerate token if needed</p>"},{"location":"github-cicd-setup-guide/#readthedocs-build-fails","title":"ReadTheDocs Build Fails","text":"<p>Import error: - Check <code>.readthedocs.yml</code> syntax - Verify Python version matches project</p> <p>MkDocs not found: - Ensure MkDocs installed in build commands - Check pip install succeeds in logs</p> <p>Theme missing: - Add <code>mkdocs-material</code> to dependencies - Clear build cache and retry</p>"},{"location":"github-cicd-setup-guide/#github-actions-timeout","title":"GitHub Actions Timeout","text":"<p>Long test runs: - Add <code>timeout-minutes: 30</code> to job - Split tests into parallel jobs - Cache dependencies</p> <p>Hanging process: - Check for infinite loops - Add proper test timeouts - Kill subprocess in tests</p>"},{"location":"github-cicd-setup-guide/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Rotate tokens annually</li> <li>Set calendar reminder</li> <li> <p>Update both PyPI and GitHub</p> </li> <li> <p>Use environment protection</p> </li> <li>Limit production deployments</li> <li> <p>Require reviews for releases</p> </li> <li> <p>Enable 2FA everywhere</p> </li> <li>GitHub (required for Actions)</li> <li>PyPI (highly recommended)</li> <li> <p>ReadTheDocs</p> </li> <li> <p>Monitor security alerts</p> </li> <li>Check GitHub Security tab weekly</li> <li>Act on Dependabot alerts quickly</li> <li>Review CodeQL findings</li> </ol>"},{"location":"github-cicd-setup-guide/#next-steps","title":"Next Steps","text":"<p>With CI/CD configured:</p> <ol> <li>Make your first release</li> <li>Update version and changelog</li> <li>Create GitHub release</li> <li> <p>Monitor PyPI publication</p> </li> <li> <p>Customize workflows</p> </li> <li>Add deployment environments</li> <li>Include performance tests</li> <li> <p>Add container builds</p> </li> <li> <p>Enhance documentation</p> </li> <li>Add API references</li> <li>Include tutorials</li> <li> <p>Create video guides</p> </li> <li> <p>Monitor metrics</p> </li> <li>Track build times</li> <li>Review test coverage</li> <li>Analyze deployment frequency</li> </ol> <p>For issues, check workflow logs first, then consult this guide's troubleshooting section.</p>"},{"location":"github-cicd-setup-guide/#related-documentation","title":"Related Documentation","text":"<ul> <li>GitHub CI/CD Operations Guide - Daily operations and interactions</li> <li>CI/CD Overview - Technical reference and file descriptions</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>DQX can be installed using pip from PyPI or directly from source.</p>"},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or higher</li> <li>pip package manager</li> </ul>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>The simplest way to install DQX:</p> <pre><code>pip install dqx\n</code></pre> <p>For specific version:</p> <pre><code>pip install dqx==0.3.0\n</code></pre>"},{"location":"installation/#install-from-source","title":"Install from Source","text":"<p>To install the latest development version:</p> <pre><code>git clone https://github.com/yourusername/dqx.git\ncd dqx\npip install -e .\n</code></pre>"},{"location":"installation/#install-with-extras","title":"Install with Extras","text":"<p>DQX provides optional dependencies for specific features:</p>"},{"location":"installation/#development-dependencies","title":"Development Dependencies","text":"<p>For contributing to DQX:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This includes: - pytest for testing - ruff for linting - mypy for type checking - pre-commit hooks</p>"},{"location":"installation/#documentation-dependencies","title":"Documentation Dependencies","text":"<p>For building documentation:</p> <pre><code>pip install -e \".[docs]\"\n</code></pre>"},{"location":"installation/#all-dependencies","title":"All Dependencies","text":"<p>To install all optional dependencies:</p> <pre><code>pip install -e \".[dev,docs]\"\n</code></pre>"},{"location":"installation/#using-uv-recommended-for-development","title":"Using UV (Recommended for Development)","text":"<p>DQX uses uv for dependency management:</p> <pre><code># Install uv\npip install uv\n\n# Clone and setup\ngit clone https://github.com/yourusername/dqx.git\ncd dqx\n\n# Install all dependencies\nuv sync\n\n# Run tests\nuv run pytest\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify DQX is working:</p> <pre><code>import dqx\n\nprint(dqx.__version__)\n</code></pre> <p>Or from command line:</p> <pre><code>python -c \"import dqx; print(dqx.__version__)\"\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#python-version","title":"Python Version","text":"<p>DQX requires Python 3.11+. Check your version:</p> <pre><code>python --version\n</code></pre>"},{"location":"installation/#virtual-environment","title":"Virtual Environment","text":"<p>We recommend using a virtual environment:</p> <pre><code># Create virtual environment\npython -m venv venv\n\n# Activate it\nsource venv/bin/activate  # On Unix/macOS\nvenv\\Scripts\\activate     # On Windows\n\n# Install DQX\npip install dqx\n</code></pre>"},{"location":"installation/#permission-issues","title":"Permission Issues","text":"<p>If you encounter permission errors:</p> <pre><code>pip install --user dqx\n</code></pre>"},{"location":"installation/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>If you have dependency conflicts, try installing in a clean environment:</p> <pre><code>python -m venv clean_env\nsource clean_env/bin/activate\npip install dqx\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<ul> <li>Follow the Quick Start Guide to create your first data quality checks</li> <li>Read the User Guide for detailed usage instructions</li> <li>Check out examples for real-world usage</li> </ul>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":"<p>To remove DQX:</p> <pre><code>pip uninstall dqx\n</code></pre> <p>For issues with installation, please open an issue on GitHub.</p>"},{"location":"plugin_system/","title":"DQX Plugin System Documentation","text":"<p>The DQX Plugin System allows extending validation result processing with custom plugins. Plugins can generate reports, send notifications, store metrics, or perform any custom processing after validation completes.</p>"},{"location":"plugin_system/#overview","title":"Overview","text":"<p>The plugin system provides: - Extensibility: Add custom result processors without modifying core DQX code - Isolation: Plugin failures don't affect validation execution - Performance: Built-in timeouts prevent slow plugins from blocking - Rich Context: Access to all validation results, symbols, and metadata</p>"},{"location":"plugin_system/#architecture","title":"Architecture","text":"<pre><code>VerificationSuite\n    \u2502\n    \u251c\u2500\u2500 Executes validations\n    \u2502\n    \u2514\u2500\u2500 PluginManager.process_all()\n            \u2502\n            \u251c\u2500\u2500 AuditPlugin (built-in)\n            \u251c\u2500\u2500 CustomPlugin1\n            \u2514\u2500\u2500 CustomPlugin2\n</code></pre>"},{"location":"plugin_system/#creating-a-plugin","title":"Creating a Plugin","text":"<p>Plugins must implement the <code>PostProcessor</code> protocol:</p> <pre><code>from dqx.common import PluginExecutionContext, PluginMetadata\nfrom dqx.plugins import PostProcessor\n\n\nclass MyPlugin:\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"my_plugin\",\n            version=\"1.0.0\",\n            author=\"Your Name\",\n            description=\"Description of what your plugin does\",\n            capabilities={\"reporting\", \"notifications\"},  # Optional\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        \"\"\"Process validation results.\"\"\"\n        # Your plugin logic here\n        pass\n</code></pre>"},{"location":"plugin_system/#plugin-context","title":"Plugin Context","text":"<p>The <code>PluginExecutionContext</code> provides comprehensive information:</p> <pre><code>@dataclass\nclass PluginExecutionContext:\n    suite_name: str  # Name of the verification suite\n    datasources: list[str]  # Data sources used\n    key: ResultKey  # Date and tags\n    timestamp: float  # Unix timestamp\n    duration_ms: float  # Execution time in milliseconds\n    results: list[AssertionResult]  # All assertion results\n    symbols: list[SymbolInfo]  # All computed symbols\n</code></pre> <p>Available convenience methods: - <code>total_assertions() -&gt; int</code> - Total number of assertions - <code>failed_assertions() -&gt; int</code> - Number of failed assertions - <code>passed_assertions() -&gt; int</code> - Number of passed assertions - <code>assertion_pass_rate() -&gt; float</code> - Percentage of passed assertions - <code>total_symbols() -&gt; int</code> - Total number of symbols - <code>failed_symbols() -&gt; int</code> - Number of failed symbols - <code>assertions_by_severity() -&gt; dict[str, int]</code> - Count by severity - <code>failures_by_severity() -&gt; dict[str, int]</code> - Failures by severity</p>"},{"location":"plugin_system/#built-in-plugins","title":"Built-in Plugins","text":""},{"location":"plugin_system/#auditplugin","title":"AuditPlugin","text":"<p>The built-in audit plugin displays a Rich-formatted summary of validation results:</p> <pre><code>from dqx.api import VerificationSuite\n\n# Create suite - plugins are managed internally\nsuite = VerificationSuite(checks, db, \"MyDataQuality\")\n\n# Plugins are enabled by default when run() is called\nsuite.run(datasources, key)  # Plugins enabled\n\n# Or explicitly disable plugins during run\nsuite.run(datasources, key, enable_plugins=False)\n</code></pre> <p>Output example: <pre><code>\u2550\u2550\u2550 DQX Audit Report \u2550\u2550\u2550\nSuite: MyDataQuality\nDate: 2025-10-18\nDuration: 342.50ms\nDatasets: products, inventory\n\n     Execution Summary\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Metric           \u2502 Count \u2502  Rate \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Total Assertions \u2502     4 \u2502       \u2502\n\u2502 Passed \u2713         \u2502     3 \u2502 75.0% \u2502\n\u2502 Failed \u2717         \u2502     1 \u2502 25.0% \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre></p>"},{"location":"plugin_system/#example-plugins","title":"Example Plugins","text":""},{"location":"plugin_system/#json-reporter","title":"JSON Reporter","text":"<pre><code>class JSONReporterPlugin:\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"json_reporter\",\n            version=\"1.0.0\",\n            author=\"Your Team\",\n            description=\"Outputs results as JSON\",\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        import json\n\n        report = {\n            \"suite\": context.suite_name,\n            \"date\": context.key.yyyy_mm_dd.isoformat(),\n            \"duration_ms\": context.duration_ms,\n            \"summary\": {\n                \"total\": context.total_assertions(),\n                \"passed\": context.passed_assertions(),\n                \"failed\": context.failed_assertions(),\n                \"pass_rate\": context.assertion_pass_rate(),\n            },\n            \"failures_by_severity\": context.failures_by_severity(),\n        }\n\n        with open(\"validation_report.json\", \"w\") as f:\n            json.dump(report, f, indent=2)\n</code></pre>"},{"location":"plugin_system/#slack-notifier","title":"Slack Notifier","text":"<pre><code>class SlackNotifierPlugin:\n    def __init__(self, webhook_url: str):\n        self.webhook_url = webhook_url\n\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"slack_notifier\",\n            version=\"1.0.0\",\n            author=\"DevOps Team\",\n            description=\"Sends validation alerts to Slack\",\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        if context.failed_assertions() &gt; 0:\n            import requests\n\n            failures = context.failures_by_severity()\n            message = {\n                \"text\": f\"\u26a0\ufe0f Data Quality Alert: {context.suite_name}\",\n                \"blocks\": [\n                    {\n                        \"type\": \"section\",\n                        \"text\": {\n                            \"type\": \"mrkdwn\",\n                            \"text\": f\"*Suite:* {context.suite_name}\\n\"\n                            f\"*Pass Rate:* {context.assertion_pass_rate():.1f}%\\n\"\n                            f\"*Failures:* {failures}\",\n                        },\n                    }\n                ],\n            }\n\n            requests.post(self.webhook_url, json=message)\n</code></pre>"},{"location":"plugin_system/#metrics-collector","title":"Metrics Collector","text":"<pre><code>class MetricsCollectorPlugin:\n    @staticmethod\n    def metadata() -&gt; PluginMetadata:\n        return PluginMetadata(\n            name=\"metrics_collector\",\n            version=\"1.0.0\",\n            author=\"Analytics Team\",\n            description=\"Collects validation metrics\",\n        )\n\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        # Send metrics to monitoring system\n        import statsd\n\n        client = statsd.StatsClient(\"localhost\", 8125)\n\n        # Send gauges\n        client.gauge(\n            f\"dqx.{context.suite_name}.assertions.total\", context.total_assertions()\n        )\n        client.gauge(\n            f\"dqx.{context.suite_name}.assertions.failed\", context.failed_assertions()\n        )\n        client.gauge(\n            f\"dqx.{context.suite_name}.pass_rate\", context.assertion_pass_rate()\n        )\n\n        # Send timing\n        client.timing(f\"dqx.{context.suite_name}.duration\", context.duration_ms)\n</code></pre>"},{"location":"plugin_system/#plugin-registration","title":"Plugin Registration","text":""},{"location":"plugin_system/#method-1-entry-points-recommended","title":"Method 1: Entry Points (Recommended)","text":"<p>Register plugins in your package's <code>pyproject.toml</code>:</p> <pre><code>[project.entry-points.\"dqx.plugins\"]\njson_reporter = \"mypackage.plugins:JSONReporterPlugin\"\nslack_notifier = \"mypackage.plugins:SlackNotifierPlugin\"\n</code></pre> <p>This approach supports automatic plugin discovery when your package is installed.</p>"},{"location":"plugin_system/#method-2-manual-registration","title":"Method 2: Manual Registration","text":"<p>For testing or dynamic plugin loading:</p> <pre><code>from dqx.api import VerificationSuite\n\n# Create suite\nsuite = VerificationSuite(checks, db, \"MyData\")\n\n# Register custom plugins using fully qualified class names\nsuite.plugin_manager.register_plugin(\"mypackage.plugins.MyCustomPlugin\")\n\n# Clear default plugins if needed\nsuite.plugin_manager.clear_plugins()\n\n# Register only your plugins\nsuite.plugin_manager.register_plugin(\"mypackage.plugins.JSONReporterPlugin\")\n\n# Note: For plugins with constructor arguments, you'll need to use entry points\n# or create a wrapper class that handles initialization\n</code></pre>"},{"location":"plugin_system/#error-handling","title":"Error Handling","text":"<p>Plugins are executed with comprehensive error handling:</p> <ol> <li>Plugin Exceptions: Caught and logged, suite continues</li> <li>Timeouts: Plugins exceeding 60 seconds are terminated</li> <li>Invalid Plugins: Rejected during discovery</li> </ol> <p>Example error handling:</p> <pre><code>class RobustPlugin:\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        try:\n            # Risky operation\n            external_api_call()\n        except Exception as e:\n            # Plugin should handle its own errors gracefully\n            logger.error(f\"Plugin error: {e}\")\n            # Can still do partial processing\n            self.write_local_backup(context)\n</code></pre>"},{"location":"plugin_system/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Timeouts: Default 60-second timeout per plugin</li> <li>Async Operations: Plugins run synchronously; use threads/async internally if needed</li> <li>Resource Usage: Plugins should clean up resources in case of timeout</li> </ol> <pre><code>class EfficientPlugin:\n    def process(self, context: PluginExecutionContext) -&gt; None:\n        # Use context methods for efficiency\n        if context.assertion_pass_rate() &gt; 99.0:\n            # Skip expensive processing for perfect runs\n            return\n\n        # Process only failures\n        for result in context.results:\n            if result.status == \"FAILURE\":\n                self.process_failure(result)\n</code></pre>"},{"location":"plugin_system/#testing-plugins","title":"Testing Plugins","text":"<pre><code>import pytest\nfrom datetime import datetime\nfrom dqx.common import PluginExecutionContext, ResultKey, AssertionResult\nfrom returns.result import Success\n\n\ndef test_my_plugin():\n    # Create test context\n    context = PluginExecutionContext(\n        suite_name=\"TestSuite\",\n        datasources=[\"test_db\"],\n        key=ResultKey(datetime.now().date(), {}),\n        timestamp=time.time(),\n        duration_ms=100.0,\n        results=[\n            AssertionResult(\n                yyyy_mm_dd=datetime.now().date(),\n                suite=\"TestSuite\",\n                check=\"test_check\",\n                assertion=\"test_assertion\",\n                severity=\"P1\",\n                status=\"OK\",\n                metric=Success(1.0),\n            )\n        ],\n        symbols=[],\n    )\n\n    # Test plugin\n    plugin = MyPlugin()\n    plugin.process(context)\n\n    # Assert expected behavior\n    assert os.path.exists(\"expected_output.json\")\n</code></pre>"},{"location":"plugin_system/#best-practices","title":"Best Practices","text":"<ol> <li>Be Resilient: Handle errors gracefully</li> <li>Be Fast: Complete processing quickly</li> <li>Be Focused: Do one thing well</li> <li>Be Testable: Write unit tests for your plugins</li> <li>Be Documented: Include clear metadata and docstrings</li> </ol>"},{"location":"plugin_system/#future-enhancements","title":"Future Enhancements","text":"<p>The plugin system is designed for extension. Potential future features: - Async plugin execution - Plugin dependencies - Plugin configuration system - Built-in plugin marketplace - Plugin health monitoring</p>"},{"location":"plugin_system/#see-also","title":"See Also","text":"<ul> <li>Plugin Demo - Complete working example</li> <li>API Reference - Full API documentation</li> <li>Architecture - System design details</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":"<p>Get started with DQX in 5 minutes! This guide shows you how to create your first data quality checks.</p>"},{"location":"quickstart/#basic-example","title":"Basic Example","text":"<p>Here's a simple example checking data quality on a pandas DataFrame:</p> <pre><code>import pandas as pd\nfrom dqx import DataQualityValidator\n\n# Sample data\ndf = pd.DataFrame(\n    {\n        \"user_id\": [1, 2, 3, 4, 5],\n        \"age\": [25, 30, -5, 150, 35],\n        \"email\": [\n            \"john@example.com\",\n            \"invalid-email\",\n            \"jane@test.com\",\n            None,\n            \"bob@demo.com\",\n        ],\n        \"score\": [85.5, 92.0, 78.5, None, 88.0],\n    }\n)\n\n# Create validator\nvalidator = DataQualityValidator()\n\n# Define checks\nchecks = (\n    validator.create_checks(df)\n    .is_not_null(\"user_id\")\n    .is_between(\"age\", 0, 120)\n    .matches_pattern(\"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n    .is_not_null(\"score\")\n)\n\n# Run validation\nresults = validator.validate(df, checks)\n\n# Display results\nprint(results.summary())\n</code></pre>"},{"location":"quickstart/#understanding-results","title":"Understanding Results","text":"<p>DQX provides detailed validation results:</p> <pre><code># Check if validation passed\nif results.passed:\n    print(\"\u2705 All checks passed!\")\nelse:\n    print(f\"\u274c {results.failed_count} checks failed\")\n\n# Get detailed results\nfor check_result in results.details:\n    print(f\"{check_result.check_name}: {check_result.status}\")\n    if not check_result.passed:\n        print(f\"  Failed rows: {check_result.failed_rows}\")\n</code></pre>"},{"location":"quickstart/#common-data-quality-checks","title":"Common Data Quality Checks","text":""},{"location":"quickstart/#1-null-value-checks","title":"1. Null Value Checks","text":"<pre><code># Check for nulls\nvalidator.create_checks(df).is_not_null(\n    \"column_name\"\n).has_no_nulls()  # Check all columns\n</code></pre>"},{"location":"quickstart/#2-range-validation","title":"2. Range Validation","text":"<pre><code># Numeric ranges\nvalidator.create_checks(df).is_between(\"age\", 0, 120).is_positive(\n    \"amount\"\n).is_greater_than(\"score\", 0)\n</code></pre>"},{"location":"quickstart/#3-pattern-matching","title":"3. Pattern Matching","text":"<pre><code># String patterns\nvalidator.create_checks(df).matches_pattern(\n    \"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\"\n).matches_pattern(\"phone\", r\"^\\d{3}-\\d{3}-\\d{4}$\").has_length(\"zip_code\", 5)\n</code></pre>"},{"location":"quickstart/#4-uniqueness-checks","title":"4. Uniqueness Checks","text":"<pre><code># Unique values\nvalidator.create_checks(df).is_unique(\"user_id\").has_no_duplicates(\n    [\"first_name\", \"last_name\"]\n)\n</code></pre>"},{"location":"quickstart/#5-statistical-checks","title":"5. Statistical Checks","text":"<pre><code># Statistical validation\nvalidator.create_checks(df).mean_between(\"score\", 70, 90).std_dev_less_than(\n    \"price\", 100\n).percentile_between(\"income\", 0.25, 10000, 50000)\n</code></pre>"},{"location":"quickstart/#working-with-different-data-sources","title":"Working with Different Data Sources","text":""},{"location":"quickstart/#sql-databases","title":"SQL Databases","text":"<pre><code>from dqx import SQLDataSource\n\n# Connect to database\ndatasource = SQLDataSource(connection_string=\"postgresql://...\")\n\n# Validate query results\nquery = \"SELECT * FROM users WHERE created_at &gt; '2024-01-01'\"\nresults = validator.validate_query(datasource, query, checks)\n</code></pre>"},{"location":"quickstart/#csv-files","title":"CSV Files","text":"<pre><code># Validate CSV directly\nresults = validator.validate_file(\"data.csv\", checks)\n\n# Or load and validate\ndf = pd.read_csv(\"data.csv\")\nresults = validator.validate(df, checks)\n</code></pre>"},{"location":"quickstart/#parquet-files","title":"Parquet Files","text":"<pre><code># Validate Parquet files\nresults = validator.validate_file(\"data.parquet\", checks)\n</code></pre>"},{"location":"quickstart/#custom-validation-rules","title":"Custom Validation Rules","text":"<p>Create custom validation logic:</p> <pre><code>from dqx import custom_check\n\n\n@custom_check\ndef business_rule_check(df):\n    \"\"\"Custom business rule validation\"\"\"\n    mask = (df[\"status\"] == \"active\") &amp; (df[\"balance\"] &gt; 0)\n    return mask\n\n\n# Use custom check\nvalidator.create_checks(df).add_custom_check(\n    business_rule_check, \"active_positive_balance\"\n)\n</code></pre>"},{"location":"quickstart/#validation-reporting","title":"Validation Reporting","text":""},{"location":"quickstart/#summary-report","title":"Summary Report","text":"<pre><code># Get summary statistics\nsummary = results.summary()\nprint(f\"Total checks: {summary['total']}\")\nprint(f\"Passed: {summary['passed']}\")\nprint(f\"Failed: {summary['failed']}\")\nprint(f\"Pass rate: {summary['pass_rate']:.1%}\")\n</code></pre>"},{"location":"quickstart/#detailed-report","title":"Detailed Report","text":"<pre><code># Generate detailed HTML report\nresults.to_html(\"validation_report.html\")\n\n# Or get DataFrame of results\nresults_df = results.to_dataframe()\n</code></pre>"},{"location":"quickstart/#export-results","title":"Export Results","text":"<pre><code># Export to various formats\nresults.to_json(\"results.json\")\nresults.to_csv(\"results.csv\")\n</code></pre>"},{"location":"quickstart/#error-handling","title":"Error Handling","text":"<p>DQX provides clear error messages:</p> <pre><code>try:\n    results = validator.validate(df, checks)\nexcept ValidationError as e:\n    print(f\"Validation error: {e}\")\nexcept DataSourceError as e:\n    print(f\"Data source error: {e}\")\n</code></pre>"},{"location":"quickstart/#best-practices","title":"Best Practices","text":"<ol> <li>Start Simple: Begin with basic null and range checks</li> <li>Incremental Validation: Add checks gradually</li> <li>Use Descriptive Names: Name your checks clearly</li> <li>Set Appropriate Thresholds: Be realistic with ranges</li> <li>Monitor Trends: Track validation results over time</li> </ol>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the User Guide for advanced features</li> <li>Learn about Plugin System for extending DQX</li> <li>Check API Reference for detailed documentation</li> <li>See Examples for real-world use cases</li> </ul>"},{"location":"quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Full Documentation</li> <li>\ud83d\udcac GitHub Discussions</li> <li>\ud83d\udc1b Report Issues</li> <li>\ud83d\udce7 Contact Support</li> </ul> <p>Ready to dive deeper? Check out the User Guide for comprehensive documentation.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the DQX User Guide! This comprehensive guide covers all aspects of using DQX for data quality validation.</p>"},{"location":"user-guide/#overview","title":"Overview","text":"<p>DQX (Data Quality Excellence) transforms data validation into mathematical expressions, making it easy to find data quality issues before they impact your business.</p>"},{"location":"user-guide/#core-concepts","title":"Core Concepts","text":""},{"location":"user-guide/#1-validators","title":"1. Validators","text":"<p>Validators are the heart of DQX. They orchestrate the validation process:</p> <pre><code>from dqx import DataQualityValidator\n\nvalidator = DataQualityValidator()\n</code></pre>"},{"location":"user-guide/#2-checks","title":"2. Checks","text":"<p>Checks define what to validate. DQX provides many built-in checks:</p> <ul> <li>Completeness: Null checks, missing value detection</li> <li>Consistency: Pattern matching, format validation</li> <li>Accuracy: Range checks, statistical validation</li> <li>Uniqueness: Duplicate detection, key validation</li> </ul>"},{"location":"user-guide/#3-data-sources","title":"3. Data Sources","text":"<p>DQX supports multiple data sources:</p> <ul> <li>Pandas DataFrames</li> <li>SQL databases (PostgreSQL, MySQL, SQLite)</li> <li>CSV, Parquet, JSON files</li> <li>Cloud storage (S3, GCS, Azure)</li> </ul>"},{"location":"user-guide/#4-results","title":"4. Results","text":"<p>Validation results provide detailed insights:</p> <ul> <li>Pass/fail status</li> <li>Row-level details</li> <li>Statistical summaries</li> <li>Trend analysis</li> </ul>"},{"location":"user-guide/#validation-workflow","title":"Validation Workflow","text":"<pre><code>graph LR\n    A[Data Source] --&gt; B[Define Checks]\n    B --&gt; C[Run Validation]\n    C --&gt; D[Analyze Results]\n    D --&gt; E[Take Action]</code></pre>"},{"location":"user-guide/#detailed-features","title":"Detailed Features","text":""},{"location":"user-guide/#completeness-validation","title":"Completeness Validation","text":"<p>Check for missing or null values:</p> <pre><code># Single column\nchecks.is_not_null(\"customer_id\")\n\n# Multiple columns\nchecks.are_not_null([\"name\", \"email\", \"phone\"])\n\n# Completeness threshold\nchecks.has_completeness(\"optional_field\", threshold=0.95)\n</code></pre>"},{"location":"user-guide/#consistency-validation","title":"Consistency Validation","text":"<p>Ensure data follows expected patterns:</p> <pre><code># Email format\nchecks.matches_pattern(\"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n\n# Date format\nchecks.matches_date_format(\"birth_date\", \"%Y-%m-%d\")\n\n# Custom formats\nchecks.matches_format(\"product_code\", \"XXX-####\")\n</code></pre>"},{"location":"user-guide/#accuracy-validation","title":"Accuracy Validation","text":"<p>Validate data accuracy and ranges:</p> <pre><code># Numeric ranges\nchecks.is_between(\"age\", 0, 120)\nchecks.is_positive(\"amount\")\nchecks.is_not_negative(\"balance\")\n\n# Date ranges\nchecks.date_between(\"order_date\", \"2020-01-01\", \"2024-12-31\")\n\n# Statistical checks\nchecks.mean_between(\"score\", 70, 90)\nchecks.std_dev_less_than(\"variance\", 10)\n</code></pre>"},{"location":"user-guide/#uniqueness-validation","title":"Uniqueness Validation","text":"<p>Detect duplicates and ensure uniqueness:</p> <pre><code># Single column uniqueness\nchecks.is_unique(\"user_id\")\n\n# Composite key uniqueness\nchecks.has_unique_combination([\"first_name\", \"last_name\", \"birth_date\"])\n\n# Duplicate detection\nchecks.has_no_duplicates()\nchecks.duplicate_count_less_than(\"email\", 5)\n</code></pre>"},{"location":"user-guide/#cross-column-validation","title":"Cross-Column Validation","text":"<p>Validate relationships between columns:</p> <pre><code># Column comparison\nchecks.column_greater_than(\"end_date\", \"start_date\")\nchecks.columns_match(\"billing_address\", \"shipping_address\")\n\n# Conditional validation\nchecks.when('status == \"active\"').then(\"balance &gt; 0\")\n\n# Complex rules\nchecks.satisfies(lambda df: df[\"price\"] * df[\"quantity\"] == df[\"total\"])\n</code></pre>"},{"location":"user-guide/#advanced-features","title":"Advanced Features","text":""},{"location":"user-guide/#custom-validation-functions","title":"Custom Validation Functions","text":"<p>Create domain-specific validations:</p> <pre><code>@validator.custom_check\ndef validate_business_rule(df):\n    \"\"\"Custom business logic\"\"\"\n    valid_mask = (\n        (df[\"customer_type\"] == \"premium\") &amp; (df[\"credit_limit\"] &gt;= 10000)\n    ) | ((df[\"customer_type\"] == \"standard\") &amp; (df[\"credit_limit\"] &lt;= 5000))\n    return valid_mask\n</code></pre>"},{"location":"user-guide/#validation-pipelines","title":"Validation Pipelines","text":"<p>Chain multiple validations:</p> <pre><code>pipeline = validator.create_pipeline()\n\n# Stage 1: Basic checks\npipeline.add_stage(\"basic\", [checks.is_not_null(\"id\"), checks.is_unique(\"id\")])\n\n# Stage 2: Business rules\npipeline.add_stage(\n    \"business\",\n    [checks.is_positive(\"revenue\"), checks.date_not_future(\"transaction_date\")],\n)\n\n# Run pipeline\nresults = pipeline.run(df)\n</code></pre>"},{"location":"user-guide/#conditional-validation","title":"Conditional Validation","text":"<p>Apply checks based on conditions:</p> <pre><code># Different rules for different segments\nchecks.when('region == \"US\"').then(\n    checks.matches_pattern(\"phone\", r\"^\\d{3}-\\d{3}-\\d{4}$\")\n)\n\nchecks.when('region == \"UK\"').then(checks.matches_pattern(\"phone\", r\"^\\+44\\d{10}$\"))\n</code></pre>"},{"location":"user-guide/#sampling-and-performance","title":"Sampling and Performance","text":"<p>Optimize validation for large datasets:</p> <pre><code># Sample validation\nvalidator.validate_sample(df, sample_size=10000, checks=checks)\n\n# Chunk processing\nvalidator.validate_chunks(df, chunk_size=50000, checks=checks)\n\n# Parallel validation\nvalidator.validate_parallel(df, checks=checks, n_jobs=4)\n</code></pre>"},{"location":"user-guide/#reporting-and-monitoring","title":"Reporting and Monitoring","text":""},{"location":"user-guide/#html-reports","title":"HTML Reports","text":"<p>Generate interactive reports:</p> <pre><code>results.generate_report(\n    \"validation_report.html\", include_charts=True, include_failed_rows=True\n)\n</code></pre>"},{"location":"user-guide/#dashboard-integration","title":"Dashboard Integration","text":"<p>Export metrics for monitoring:</p> <pre><code># Prometheus metrics\nmetrics = results.to_prometheus()\n\n# JSON for APIs\njson_results = results.to_json()\n\n# Time series data\ntime_series = results.to_time_series()\n</code></pre>"},{"location":"user-guide/#alerting","title":"Alerting","text":"<p>Set up alerts for validation failures:</p> <pre><code># Email alerts\nif not results.passed:\n    validator.send_alert(\n        to=[\"data-team@company.com\"], subject=\"Data Quality Alert\", results=results\n    )\n\n# Slack integration\nvalidator.notify_slack(webhook_url=\"https://hooks.slack.com/...\", results=results)\n</code></pre>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/#1-start-with-critical-checks","title":"1. Start with Critical Checks","text":"<p>Begin with the most important validations: - Primary key uniqueness - Not null for required fields - Basic range validations</p>"},{"location":"user-guide/#2-use-descriptive-names","title":"2. Use Descriptive Names","text":"<pre><code># Good\nchecks.is_not_null(\"customer_id\").with_name(\"Customer ID Required\")\n\n# Better\nchecks.is_not_null(\"customer_id\").with_name(\n    \"Customer ID Required\", description=\"Every order must have a valid customer ID\"\n)\n</code></pre>"},{"location":"user-guide/#3-set-appropriate-thresholds","title":"3. Set Appropriate Thresholds","text":"<pre><code># Allow some nulls in optional fields\nchecks.has_completeness(\"middle_name\", threshold=0.8)\n\n# Strict for critical fields\nchecks.has_completeness(\"email\", threshold=1.0)\n</code></pre>"},{"location":"user-guide/#4-group-related-checks","title":"4. Group Related Checks","text":"<pre><code>customer_checks = CheckGroup(\"Customer Validation\")\ncustomer_checks.add(\n    [\n        checks.is_not_null(\"customer_id\"),\n        checks.matches_pattern(\"email\", email_regex),\n        checks.is_between(\"age\", 18, 120),\n    ]\n)\n</code></pre>"},{"location":"user-guide/#5-version-your-validations","title":"5. Version Your Validations","text":"<pre><code># Track validation rules in version control\nvalidator.save_rules(\"validations/v1.0.0/customer_rules.json\")\n\n# Load versioned rules\nvalidator.load_rules(\"validations/v1.0.0/customer_rules.json\")\n</code></pre>"},{"location":"user-guide/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/#with-pandas","title":"With Pandas","text":"<pre><code># Direct DataFrame validation\ndf = pd.read_csv(\"data.csv\")\nresults = validator.validate(df, checks)\n</code></pre>"},{"location":"user-guide/#with-sql-databases","title":"With SQL Databases","text":"<pre><code># PostgreSQL\nconn_string = \"postgresql://user:pass@localhost/db\"\nresults = validator.validate_query(conn_string, \"SELECT * FROM customers\", checks)\n</code></pre>"},{"location":"user-guide/#with-apache-spark","title":"With Apache Spark","text":"<pre><code># Spark DataFrame validation\nspark_df = spark.read.parquet(\"data.parquet\")\nresults = validator.validate_spark(spark_df, checks)\n</code></pre>"},{"location":"user-guide/#with-airflow","title":"With Airflow","text":"<pre><code># DQX Airflow operator\nfrom dqx.airflow import DQXValidationOperator\n\nvalidation_task = DQXValidationOperator(\n    task_id=\"validate_customer_data\",\n    source=\"s3://bucket/data.parquet\",\n    checks=customer_checks,\n    fail_on_error=True,\n)\n</code></pre>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/#common-issues","title":"Common Issues","text":"<ol> <li>Memory errors with large datasets</li> <li>Use sampling or chunk processing</li> <li>Increase available memory</li> <li> <p>Use distributed processing</p> </li> <li> <p>Slow validation performance</p> </li> <li>Create indexes on validated columns</li> <li>Use parallel processing</li> <li> <p>Optimize regex patterns</p> </li> <li> <p>Connection issues</p> </li> <li>Check database credentials</li> <li>Verify network connectivity</li> <li>Check firewall rules</li> </ol>"},{"location":"user-guide/#debug-mode","title":"Debug Mode","text":"<p>Enable detailed logging:</p> <pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\nvalidator = DataQualityValidator(debug=True)\n</code></pre>"},{"location":"user-guide/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the Plugin System to extend DQX</li> <li>Read the API Reference for detailed documentation</li> <li>Check out real-world examples</li> <li>Join the community</li> </ul> <p>Need help? Check our FAQ or open an issue.</p>"}]}